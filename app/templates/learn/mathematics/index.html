{% extends 'base.html' %}
{% block title %}Math - {% endblock %}
{% block content %}


<style>
	.first {
		font-size: 24px;
		line-height: 30px;
		margin: 30px 0 15px;
	}

	.second {
		font-size: 20px;
		line-height: 30px;
		margin: 30px 0 15px;
	}

	p,
	button {
		font-size: 100%;
	}

	#integer1_remove {
		display: none;
	}

	iframe {
		display: block;
		margin: 0 auto;
	}

	.sidebar {
		position: fixed;
		margin-left: -375px;
		border-left: 8px solid #c8dce3;
		background-color: #fff;
		overflow-y: scroll;
	}

	.sidebar {
		width: 350px;
		height: 85vh;
	}

	.core {
		padding: 7px;
		width: 100%;
		background-color: beige;
		font-size: larger;
		margin-top: 15px;
		margin-bottom: 10px;
	}

	.core:first-child {
		margin-top: 0px;
	}

	.topic {
		padding-left: 15px;
	}

	.topic a {
		color: #333333;
	}

	.topic a:hover {
		text-decoration: underline;
	}

	a.anchor {
		display: block;
		position: relative;
		top: -150px;
		visibility: hidden;
	}

	.sidebar::-webkit-scrollbar {
		width: 8px;
		/* width of the entire scrollbar */
	}

	.sidebar::-webkit-scrollbar-track {
		background: beige;
		/* color of the tracking area */
	}

	.sidebar::-webkit-scrollbar-thumb {
		background-color: #c8dce3;
		/* color of the scroll thumb */
		/* roundness of the scroll thumb */
		border: 3px solid #c8dce3;
		/* creates padding around scroll thumb */
	}
</style>

<div class="sidebar">
	<div class="core">Foundations of mathematics</div>
	<div class="topic"><a href="#logic">Logic</a></div>
	<div class="topic"><a href="#language">Language of mathematics</a></div>
	<div class="topic"><a href="#reasoning">Reasoning and proving</a></div>
	<div class="topic"><a href="#sets">Sets, relations, set theory</a></div>
	<div class="core">Arithmetic and number theory</div>
	<div class="topic"><a href="#concept">Pre-numerical stage, concept of numbers</a></div>
	<div class="topic"><a href="#natural">Natural numbers</a></div>
	<div class="topic"><a href="#integer">Integers, rational numbers</a></div>
	<div class="topic"><a href="#real">Real numbers, complex numbers</a></div>
	<div class="topic"><a href="#number">Number theory</a></div>
	<div class="topic"><a href="#measure">Measures and units</a></div>
	<div class="topic"><a href="#ratio">Ratio and proportion, percentages</a></div>
	<div class="topic"><a href="#practical">Real-life mathematics, practical arithmetic</a></div>
	<div class="core">Geometry</div>
	<div class="topic"><a href="#informal_geometry">Informal geometry</a></div>
	<div class="topic"><a href="#area">Area and volume</a></div>
	<div class="topic"><a href="#plane_geometry">Plane and solid geometry</a></div>
	<div class="topic"><a href="#transformation">Transformation geometry</a></div>
	<div class="topic"><a href="#trigonometry">Plane and spherical trigonometry</a></div>
	<div class="topic"><a href="#analytic_geometry">Analytic geometry, vector algebra</a></div>
	<div class="topic"><a href="#descriptive_geometry">Descriptive geometry</a></div>
	<div class="core">Algebra</div>
	<div class="topic"><a href="#elementary">Elementary algebra</a></div>
	<div class="topic"><a href="#equation">Equations and inequalities</a></div>
	<div class="topic"><a href="#group">Groups, rings, fields</a></div>
	<div class="topic"><a href="#ordered">Ordered algebraic structures</a></div>
	<div class="topic"><a href="#linear">Linear algebra</a></div>
	<div class="core">Analysis</div>
	<div class="topic"><a href="#mapping">Mappings and functions</a></div>
	<div class="topic"><a href="#sequences">Sequences and series</a></div>
	<div class="topic"><a href="#differential">Differential calculus</a></div>
	<div class="topic"><a href="#integral">Integral calculus</a></div>
	<div class="topic"><a href="#descriptive_geometry">Functions of several variables</a></div>
	<div class="topic"><a href="#descriptive_geometry">Functional equations</a></div>
	<div class="topic"><a href="#descriptive_geometry">Complex analysis</a></div>
	<div class="core">Combinatorics, graph theory, probability theory, and statistics</div>
	<div class="topic"><a href="#combinatorics">Combinatorics</a></div>
	<div class="topic"><a href="#graph">Graph theory</a></div>
	<div class="topic"><a href="#descriptive">Descriptive statistics</a></div>
	<div class="topic"><a href="#probability">Probability theory</a></div>
	<div class="topic"><a href="#distribution">Distributions and stochastic processes</a></div>
	<div class="topic"><a href="#statistics">Foundations and methodology of statistics</a></div>
	<div class="topic"><a href="#descriptive_geometry">Applied statistics</a></div>
	<div class="core">Mathematical modeling and applications of mathematics</div>
	<div class="topic"><a href="#modeling">Modeling and interdisciplinarity</a></div>
	<div class="topic"><a href="#descriptive_geometry">Financial and insurance mathematics</a></div>
	<div class="topic"><a href="#descriptive_geometry">Operations research, economics</a></div>
	<div class="topic"><a href="#descriptive_geometry">Physics, astronomy, technology, engineering</a></div>
	<div class="topic"><a href="#descriptive_geometry">Biology, chemistry, medicine</a></div>
	<div class="topic"><a href="#descriptive_geometry">Behavioral and social sciences</a></div>
	<div class="topic"><a href="#descriptive_geometry">Arts, music, language, architecture</a></div>
	<div class="core">Numerical mathematics</div>
	<div class="topic"><a href="#rounding">Rounding, estimation, theory of errors</a></div>
	<div class="topic"><a href="#descriptive_geometry">Numerical algebra</a></div>
	<div class="topic"><a href="#descriptive_geometry">Numerical analysis</a></div>
	<div class="topic"><a href="#descriptive_geometry">Interpolation and approximation</a></div>
	<div class="topic"><a href="#descriptive_geometry">Mathematical programming</a></div>
	<div class="topic"><a href="#descriptive_geometry">Discrete mathematics</a></div>
	<div class="topic"><a href="#descriptive_geometry">Mathematical software, computer programs</a></div>
	<div class="core">Computer science</div>
	<div class="topic"><a href="#descriptive_geometry">Theoretical computer science</a></div>
	<div class="topic"><a href="#descriptive_geometry">Systems, databases</a></div>
	<div class="topic"><a href="#descriptive_geometry">Programming languages</a></div>
	<div class="topic"><a href="#descriptive_geometry">Programming techniques</a></div>
	<div class="topic"><a href="#descriptive_geometry">Artificial intelligence</a></div>
</div>
<!--https://zbmath.org/classification/
<h1>Math</h1>
<li>So when it comes to math, I think there is the failure in general education of math in which the order of how
	things
	are taught are somewhat confusing. As we grow to better understand how the brain develops over our lifetime,
	perhaps
	we can better create a structure upon which to build math. The problem with math is that it is the most
	difficult
	thing to learn, and when I mean difficult, I mean that the cognitive patterns required through the study of math
	are
	the most technically challenging for our brains to process, and naturally challenges the capacity of our mind.
	For
	example, the entity "infinity" is not something we can visualize in our brain. The issue is that the foundation
	of
	math is rarely taught, and almost never learned, by most people. So a lot of the times, people won't really
	enjoy
	learning math because they find it difficult to apply math to real world problems. A common example is when
	people
	first learn about probability. When people first hear the words "I flip my coin and it lands on heads AND I flip
	my
	coin and it lands on tails," they don't know how to process the word "AND." Because in most of their life, they
	have
	understood AND as equivalent to addition. "I have five apples AND I have three apples". So in total I have eight
	apples. 5 + 3 = 8. But when they start dealing with probability, that word "AND" now is multiplication. "The
	probability of flipping heads the first time AND the probability of flipping heads the second time", they might
	think... okay. 50% + 50% = 100%. But then they realize this is wrong, and it's actually 50% * 50% = 25%. So then
	people get really confused... they have the same word "AND" but it means different things? Math doesn't make any
	sense!</li>
<li>A key element to one day becoming a neural engineer is the ability to understand the language of math. A lot of
	times, you might be trying to figure a problem out, and you can read a bunch of papers, but none of it really
	makes
	any sense. Because you can't make the connection. It is like looking at a bunch of disjointed letters or words
	on a
	canvas and trying to interpret a sentence or story from it. It is difficult if not impossible.</li>
<li>I have mainly looked at math education under the Mathematics Subject Classification. The goal of studying math
	in
	this case, as well as the study of every other subject, is to solve problems.</li>
<a class="anchor" id="logic"></a>
<h2>Logic</h2>-->
<div class="first">Logic</div><a class="anchor" id="logic"></a>
<div class="second">Propositional logic</div>
<p>Propositional, or zeroth order, logic is the area of logic that deals with propositions. A proposition is a statement
	that is either true or
	false, but not both. The proposition \(P\) is a specific proposition; for example, "I am a human". A
	lower case \(p\) indicates a generalization of any proposition.</p>
<p>Law of excluded middle: for every proposition \(p\), either \(p\) is true or \(p\) is false.</p>
<p>Law of contradiction: for every proposition \(p\), it is not the case that \(p\) is both true and false.</p>
<p>Computer bit operations correspond to logical operations of Boolean variables, which are variables whose value is
	either true or false.</p>
<h4>Basic logical operators</h4>
<p>\(\neg p\) or \(\sim p\) or \(!p\) indicates negation, ie. "I am NOT a human."</p>
<p>Connections between propositions are called connectives. Propositions connected by connectives form compound
	propositions.</p>
<p>\(p \land q\) or \(p \cdot q\) or \(p \& q\) indicates logical conjunction, ie. "I am a human" AND "I eat
	cheese".</p>
<p>\(p \lor q\) or \(p + q\) or \(p \parallel q\) indicates logical disjunction (inclusive "or"), ie. "I am a human" OR
	"I eat cheese" OR both.</p>
<p>Note that the English "or" has two meanings. The exclusive "or" means that exactly one of two propositions is true.
	In math, however, when we say "or" we usually are referring to the inclusive "or" which holds true if either is true
	or if both are true.</p>
<p>\(p \oplus q\) or \(p \veebar q\) or \(p \not\equiv q\) indicates the exclusive "or", ie. "I am a human" OR "I eat
	cheese" but not both.</p>
<p>\(p \implies q\) or \(p \to q\) or \(p \supset q\) indicates implication or material conditional or material
	implication, ie. "If I am a human, then I eat cheese" or "I am a human implies I eat cheese". The
	proposition to the left of the arrow is called the antecedent, and the proposition to the right is called the
	consequent.</p>
<p>\(p \iff q\) or \(p \equiv q\) or \(p \leftrightarrow q\) indicates material equivalence or the biconditional, or
	that the truth value of \(p\) and \(q\) are the same. If both are true,
	then the biconditional is true. If both propositions are false, then the biconditional is also true, ie. "I am a
	human if and only if I eat cheese". The opposite of the biconditional is the exclusive
	"or", since the biconditional is only true if the propositions are the same, and the exclusive "or" is only true if
	the propositions are different.</p>
<p>A compound proposition that is always true is a tautology. A compound proposition that is always false is a
	contradiction. A compound proposition that is neither a tautology nor a contradiction is a contingency.</p>
<p>Compound propositions that always have the same truth value are called logically equivalent (denoted by \(\equiv\)).
</p>
<h4>Laws of propositional logic</h4>
<p>Identity laws:\[p \land T \equiv p\]\[p \lor F \equiv p\]</p>
<p>Domination laws:\[p \lor T \equiv T\]\[p \land F \equiv F\]</p>
<p>Idempotent laws:\[p \lor p \equiv p\]\[p \land p \equiv p\]</p>
<p>Double negation law:\[\neg(\neg p)\equiv p\]</p>
<p>Commutative laws:\[p \lor q \equiv q \lor p\]\[p \land q \equiv q \land p\]</p>
<p>Associative laws:\[(p \lor q) \lor r \equiv p \lor (q \lor r)\]\[(p \land q) \land r \equiv p \land (q \land r)\]</p>
<p>Distributive laws:\[(p \lor q) \land r \equiv (p \lor q) \land (p \lor r)\]\[(p \land q) \lor r \equiv (p \land q)
	\lor (p \land r)\]</p>
<p>De Morgan's laws:\[\neg(p \land q) \equiv \neg p \lor \neg q\]\[\neg(p \lor q) \equiv \neg p \land \neg q\]</p>
<h4>Axioms</h4>
<p>An axiom refers to both "logical axioms," which are statements taken to be true within the system of logic they
	define and are often shown in symbolic form, as well as non-logical axioms, which are actually substantive
	assertions about the elements of the domain of a specific mathematical theory. When used in the latter sense,
	"axiom", "postulate", and "assumption" may be used interchangeably.</p>
<div class="second">Common mathematical symbols</div>
<div class="second">Propositional variables</div>
<div class="second">Logical connectives</div>
<div class="second">Truth tables</div>
<div class="second">Implication</div>
<div class="second">Biconditional</div>
<div class="second">True and false</div>
<div class="second">Operator precedence</div>
<div class="second">Negations</div>
<div class="second">Logical equivalence</div>
<div class="second">De Morgan's laws</div>
<div class="second">Negating implications</div>
<div class="second">Proof by contrapositive</div>
<div class="second">Proof by contradiction</div>
<div class="second">Tautology</div>
<div class="second">Predicate logic</div>
<p>In predicate, or first-order logic, we extend propositional logic slightly. Instead of statements having a
	truth value, we now divide them into two parts: the variable (or subject) and the predicate. A predicate is a verb
	phrase template
	that describes some subject. Combined, the subject and predicate form a statement that does not have a truth value
	until that subject is defined. So an example is, "\(x\) is red." This statement does not have a truth
	value
	until the predicate "is red" (let's call it \(R\)) is given a variable \(x\), and we can represent the statement as
	\(R(x)\).
</p>
<p>Quantifiers allow statements about entire collections of objects rather than having to enumerate the objects by name.
</p>
<p>The universal quantifier or "for all" prefix is symbolized \(\forall\). For example, \(\forall x \text{Tiger}(x)
	\to \text{Mammal}(x)\) means all tigers are mammals.</p>
<p>The existential quantifier or "there exists" prefix is symbolized \(\exists\). For example, \(\exists x
	\text{Tiger}(x) \to
	\text{Man-eater}(x)\) means there exists at least one tiger that is a man-eater.</p>
<p>A variable \(x\) that is introduced into a logical expression by a quantifier is bound to the closest enclosing
	quantifier. For example, \(\exists x (\text{Cat}(x) \land \forall x (\text{Black}(x)))\) implies that cats exist and
	everything is black. A variable is said to be a free variable if it is not bound to a quantifier.</p>
<p>\(\mathbb{D}\) is the domain of discourse, often simply called the domain or the universe, the set over which
	individual elements may be quantified.</p>
<p>Now, I want to reinforce that these comparisons... propositional logic and first-order logic, are about
	facts.
	Propositional logic only discusses facts, facts that can be true or false.. in other words, they can only be
	0
	or 1.
	First-order logic adds on this objects and relations. Meaning one fact can be true for multiple objects, and
	an
	element can have a relationship to another object. There are other languages used to discuss the world
	around
	us,
	which are probability theory and fuzzy logic, which are studies into uncertainty. In probability, there is a
	truth
	value but we look at a chance that truth value is correct. In fuzzy logic, the language we use is uncertain,
	for
	example, if you state, "I am tall." It is difficult to assign a truth value to this statement because it
	depends
	on
	what height we consider tall to be, and so fuzzy logic investigates these scenarios.</p>
<p>The converse of a categorical or implicational statement is the result of reversing its two constituent
	statements.
	For the implication \(P \to Q\), the converse is \(Q \to P\). The truth of the converse is generally independent
	from that
	of
	the
	original statement.</p>
<div class="second">Second order logic</div>
predicates, functions, quantifiers
domain of discourse
predicates, arity
equality
<div class="second">Functions</div>
<div class="second">Quantifiers</div>
<h4>Quantifiers</h4>
<p>The "for all" prefix is the universal quantifier, symbolized \(\forall\).</p>
<p>The "there exists" quantifier is symbolized \(\exists\).</p>
universal, existential quantifier
operator precedence
combining quantifiers
<div class="second">Quantifying over sets</div>
<div class="second">Set theory</div>
union, intersection
<div class="second">Relations</div>
symmetric, antisymmetric, transitive
<div class="second">Negating quantifiers</div>
<div class="second">Negating second-order statements</div>
<div class="second">Analyzing relations</div>
<div class="second">Uniqueness</div>
uniqueness quantifier
<div class="second">SAT solving</div>
<div class="second">Satisfiability</div>
satisfiable, satisfying assignment, tautological, satisfiable, unsatisfiable
boolean satisfiability problem (SAT)
<div class="second">SAT solving</div>
truth table algorithm
<div class="second">Clause-based algorithms</div>
<div class="second">Literals and clauses</div>
literal, clause
<div class="second">Conjunctive normal form</div>
conjunctive normal form (CNF)
<div class="second">A simple backtracking algorithm</div>
<div class="second">Adding heuristics</div>
heuristic, algorithm
<div class="second">Pure literal elimination</div>
pure
<div class="second">Unit propagation</div>
<div class="second">DPLL algorithm</div>
<div class="second">Negation normal form</div>
<div class="second">Equivalence and equisatisfiability</div>
<div class="first">Language of mathematics</div><a class="anchor" id="language"></a>
<h4>Grammars</h4>
<p>Unliek natural languages, a formal language is specified by a well-defined set of rules for syntaxes. The valid
	sentences of a formal language can be described by a grammar with the help of these rules, referred to as production
	rules.</p>
<p>A formal language is a set of finite-length words or strings over some finite alphabet, and a grammar specifies the
	rules for formation of these words or strings. The entire set of words that are valid for a grammar constitutes the
	language for the grammar. Thus, the grammar \(G\) is any compact, precise mathematical definition of a language
	\(L\) as opposed to just a raw listing of all of the language's legal sentences or examples of those sentences.</p>
<p>A grammar implies an algorithm that would generate all legal sentences of the language.</p>
<p>A phrase-structure or Type-0 grammar \(G=(V,T,S,P)\) is a 4-tuple in which \(V\) is the vocabulary (set of words),
	\(T \subseteq V\) is a swet of words called terminals, \(S \in N\) is a special word called the start symbol, and
	\(P\) is the set of production rules for substituting one sentence fragment for another.</p>
<p>There exists another set \(N=V-T\) of words called nonterminals, which represent concepts like "noun." Production
	rules are applied on strings containing nonterminals until no more nonterminal symbols are present in the string.
	The start symbol \(S\) is a nonterminal.</p>
<p>The language generated by a formal grammar \(G\), denoted by \(L(G)\), is the set of all strings over the set of
	alphabets \(V\) that can be generated, starting with the start symbol, by applying production rules until all the
	nonterminal symbols are replaced in the string.</p>
<p>For example, let \(G=(\{S,A,a,b\},\{a,b\},S,\{S\to aA, S\to b, A \to aa\})\). Here, the set of nonterminals are
	\(N=\{S,A\}\). Applying the production rules in all possible ways, the following words may be generated from the
	start symbol:\[S\to aA \to aaa\]\[S \to b\]Noting else can be derived for \(G\). Thus, the language of the grammar
	\(G\) consists of only two words: \(L(G)=\{aaa,b\}\).</p>
<p>Formal grammars can be classified according to the types of productions that are allowed. The Chomsky hierarchy
	describes such a classification scheme. We infer the following on different types of grammars: 1) Every regular
	grammar is a context-free grammar (CFG). 2) Every CFG is a context-sensitive grammar (CSG). 3) Every CSG is a
	phrase-structure grammar.</p>
<p>Context-sensitive grammar: all fragments in the RHS are either longer than the corresponding fragments in the LHS or
	empty, ie. if \(b \to a\), then \(|b| &#60; |a|\) or \(a=\emptyset\). A formal language is context-sensitive if a
	context-sensitive grammar generates it.</p>
<p>Context-free grammar: all fragments in the LHS are of length 1, ie. if \(A \to a\), then \(|A|=1\) for all \(A \in N
	\). The term context-free derives from the fact that \(A\) can always be replaced by \(a\), regardless of the
	context in which it occurs.</p>
<p>A formal language is context-free if a context-free grammar generates it. Context-free languages are the theoretical
	basis for the syntax of most programming languages.</p>
<p>Regular grammar: all fragments in the RHS are either single terminals or a pair built by a terminal and a
	nonterminal, ie. if \(A \to a\), then either \(a \in T\), or \(a=cD\), or \(a=Dc\) for \(c \in T, D \in N\). If
	\(a=cD\), then the grammar is called a right linear grammar (left linear grammar otherwise). Both right linear and
	left linear grammars are regular or Type-3 grammar. The language generated by a regular grammar is called a regular
	language.</p>
<p>A regular expression \(A\) is a string (or pattern) formed from the following six pieces of information: \(a \in S\),
	the set of alphabets, \(e\), \(0\) and the operations, OR (+), PRODUCT (.), CONCATENATION (*). The language of \(G,
	L(G)\) is equal to all those strings that match \(G, L(G)=\{x \in S*|x \text{ matches } G\}\).</p>
<p>For any \(a \in S\), \(L(a)=a\); \(L(e)=\{\epsilon \}\); \(L(0)=0\). \(+\) functions as or, \(L(A+B)=L(A) \cup
	L(B)\). \(.\) creates a product structure, \(L(AB)=L(A).L(B)\). \(*\) denotes concatenation,
	\(L(A*)=\{x_1x_2...x_n|x_i \in L(A)\}\).</p>
<p>For example, the regular expression \((ab)*\) matches the set of strings: {e, ab, abab, ababab, abababab, ...}.</p>
<h4>Commutative, associative</h4>
<p>Commutative means you can write the same thing forwards and backwards (\(a+b=b+a\)), associative means you
	can
	group
	things in
	different combinations (\((a+b)+c=a+(b+c)\)).</p>
+, -, x, division, = sign
<div class="second">Variables</div>
subscript
<div class="second">Greek alphabet</div>
<div class="second">More symbols</div>
superscript, degree symbol, brackets, percentage, square root, 'x bar', recurring decimal sign (dot over digit)

<div class="first">Reasoning and proving</div><a class="anchor" id="reasoning"></a>
<p>A proof is an argument that rigorously establishes the truth of a statement. Statements used in a proof include
	axioms and postulates that are essentially the underlying assumptions about mathematical structures, the hypotheses
	of the theorem to be proved, and previously proved theorems. A theorem is a statement that can be shown to be true.
	A lemma is a simple theorem used in the proof of other theorems. A corollary is a proposition that can be
	established directly from a theorem that has been proved. A conjecture is a statement whose truth value is unknown.
	When a conjecture is proved, the conjecture becomes a theorem.</p>
<p>A direct proof is a technique to establish the implication \(p \to q\) is true by showing that \(q\) must be true
	when \(p\) is true.</p>
<p>For example, to show that if \(n\) is odd then \(n^2-1\) is even, assume \(n\) is odd. In other words, \(n=2k+1\) for
	some integer \(k\). \(\therefore n^2=(2k+1)^2=4k^2+4k+1\). Since the first two terms on the Right Hand Side (RHS)
	are
	even numbers irrespective of the value of \(k\), \(n^2\), the Left Hand Side (LHS) must be an odd number. Thus,
	\(n^2-1\) is even.</p>
<p>A proposition \(p\) is true by contradiction if proved based on the truth of the implication \(\neg p \to q\) where
	\(q\) is a contradiction.</p>
<p>For example, to show that the sum of \(2x+1\) and \(2y-1\) is even, assume that the sum of \(2x+1\) and \(2y-1\) is
	odd. In other words, \(2(x+y)\), which is a multiple of \(2\), is odd. This is a contradiction. Hence, the sum of
	\(2x+1\) and \(2y-1\) is even.</p>
<p>An inference rule is a pattern establishing that if a set of premises are all true, then it can be deduced that a
	certain conclusion statement is true.</p>
<p>Proof by induction is done in two phases. First, the proposition is established to be true for a base case—typically
	for the positive integer \(1\). In the second phase, it is established that if the proposition holds for an
	arbitrary positive integer \(k\), then it must also hold for the next greater integer \(k+1\). In other words, the
	truth of an infinite sequence of propositions \(P(n), \forall n \in [1...\infty]\) is established if \(P(1)\) is
	true, and secondly, \(\forall k \in [2...n]\) if \(P(k) \to P(k+1)\).</p>
<p>For example, let's prove the proposition "The sum of the first \(n\) positive odd integers \(P(n)\) is \(n^2\). The
	basis step: the proposition is true for \(n=1\) as \(P(1)=1^2=1\). The basis step is complete. Inductive step: the
	induction hypothesis (IH) is that the proposition is true for \(n=k\), \(k\) being an arbitrary positive integer
	\(k\). \(\therefore
	1+3+5+...+(2k-1)=k^2\).\[P(k+1)=1+3+5+...+(2k-1)+(2k+1)\]\[=P(k)+(2k+1)\]\[=k^2+(2k+1)\]\[=k^2+2k+1\]\[=(k+1)^2\]Thus,
	it is shown that if the proposition is true for \(n=k\), then it is also true for \(n=k+1\). The basis step together
	iwth the inductive step of the proof show that \(P(1)\) is true and the condition statement \(P(k)\to P(k+1)\) is
	true for all positive integers \(k\). Hence, the proposition is proved.</p>
<p>Let's talk about writing proofs for a sec. I'm no mathematician so this is what I garner from a quick google
	search
	of how to write proofs by Eugenia Cheng. This is because I was dealing with a linear algebra textbook which
	encourages the use of proofs from the start, and I haven't used proofs since 7th grade geometry class. All I
	really
	remember about proofs was... well, not much. That you start with some assumptions, and then some little dots
	that
	mean therefore or something like that.</p>
<p>A proof is a series of statements, each of which follows logically from what has gone before. It starts with
	things
	we are assuming to be true and ends with what we are trying to prove. The beginning discusses what we are
	assuming
	to be true, including definitions of what we're talking about. The middle has statements following logically
	from
	what came before, and the end is what we're trying to prove. We are given the beginning and the end, but we
	have
	to
	fill out the middle. The difficulty in writing a proof is that the order in which we write it is usually not
	the
	order in which we thought it up, and we often think up of a proof backwards. So the first mistake to avoid
	is
	writing the proof in the order in which you thought of it.</p>
<p>Some examples of things we try to prove are \(x=y\), \(x\implies y\) (x implies y), \(x\iff y\) (x is true if
	and
	only if y is true), x is purple, \(\forall x\space p(x)\) is true (all animals of a certain kind x behave in
	a
	certain way
	p(x)), \(\exists x\) (there exists x) such that p(x) is true. Or "suppose that a, b, c, and d are true. Then
	e
	is
	true."</p>
<p>For the general shape of a proof, the beginning will discuss axioms, definitions, and state the given. The
	middle
	will have a series of equations alongside the axioms, definitions, and givens that are used to be able to
	make
	those
	equations valid. Then, at the end you restate what you were trying to prove. The three dots in the shape of
	a
	triangle means "therefore", and Q.E.D. means "quod erat demonstrandum" or "which was to be demonstrated" and
	is
	placed at the end of proofs to indicate the proof is complete.</p>
<p>It's important to remember that you want to end with what you're trying to prove, and not start with it and
	go
	backwards. This is an easier mistake to make than first meets the eye. It's also important to not jump over
	too
	many
	steps without explaining what you're doing. Of course, you don't want to use logic that is just not correct
	(I'll
	try to figure out false logic later). Two classic forms of incorrect logic is negating a statement
	incorrectly
	and
	proving the converse of something instead of the thing itself. Negation is taught alongside
	propositional/first-order logic. If in doubt, justify more than less.</p>
<p>She gives some tips on how to write a proof practically. She mentions that writing a proof is hard and is
	more
	like
	being a poet, and a lot of the time you just need to sit down and stare at what you're trying to prove for a
	long
	time. But she suggests some tips. Write out the beginning very carefully in mathematical language. Write out
	the
	end
	very carefully in mathematical language. Then try and manipulate both the beginning and the end to try and
	make
	them
	look like one another. Take big leaps to see what happens, then make big leaps into smaller leaps
	afterwards.
	See if
	the situation reminds you of any situations you've ever seen before. I like these tips because they are
	pretty
	much
	how I think people should deal with any problem in life logically. Note where you're starting off from, and
	where
	you want to go, then work both ways and see if you can connect the dots!</p>
<p>One method for proofs, which may be familiar for those who work in programming as well, is proof by
	induction. In
	the
	base step we verify that the statement is true for some first instance, and then in the inductive step we
	establish
	an implication, that if the statement is true for all prior cases then it follows for the present case also.
	These
	two steps prove together that the statement for all the steps because the base step is true and everything
	that
	follows is also true.</p>
<p>To prove by mutual set inclusion is to prove that the solution set of a system equals something. This is by
	proving
	that any solution to the system is in the set, and anything in the set is a solution of the system. It's
	easy to
	confuse these two statements so try to visualize it in your head.</p>
<p>She then goes into some examples of styles for typical proof cases but I'll probably learn those along the
	way.
</p>
<div class="first">Sets, relations, set theory</div><a class="anchor" id="sets"></a>
<h4>Sets</h4>
<p>A set \(A\) is a collection of mathematical/everyday elements. e.g. \(A=\{1,2,5,a\}\). The symbol \(\in\)
	means
	that
	an element is in a set. The size or cardinality of
	\(A=|A|\) is the
	number of elements in the set. Sets can be finite or infinite.</p>
<p>Set builder notation: \(\{x|P(x)\}\) refers to the set of all \(x\) such that \(P(x)\) is valid,
	which is also the domain of \(P(x)\).</p>
<p>The universal set \(U\) is the set of all elements, or the universe of discourse in which a predicate can be
	interpreted. The empty set has no elements and is denoted \(\emptyset\).
</p>
<p>Two sets are equal if and only if they have the same elements: \(X=Y\equiv \forall p(p\in X \leftrightarrow
	p\in
	Y)\). (In natural language, for all p, p is in X if and only if p is in Y.)</p>
<p>\(X\) is a subset of \(Y\) if all elements of \(X\) are included in \(Y\). This is denoted \(X \subseteq Y
	\equiv
	\forall p(p\in X \rightarrow p\in Y)\). (In natural language, for all p, if p is in X, then p is in Y.) A
	proper
	subset means a set is a subset but is not equal to the superset,
	denoted \(X \subset Y\).</p>
<p>The opposite of subset is superset, denoted \(Y\supseteq X\) or the proper superset \(Y \supset X\).</p>
<p>The power set is the set of all subsets of a set, represented \(\wp(x)\) (the p symbol is the Weierstrass p).
	For
	example, if \(X=\{a,b,c\}\), then
	\(\wp(X)=\{\emptyset,\{a\},\{b\},\{c\},\{a,b\},\{a,c\},\{b,c\},\{a,b,c\}\}\).
	If
	\(|X|=n\), then \(|\wp(X)|=2^n\).</p>
<p>\(A\cup B=\{x|x\in A \lor x\in B\}\). The union of two sets is all x which is in either sets or is in
	both.
</p>
<p>\(A\cap B=\{x|x\in A \land x\in B\}\). The intersection of two sets is all x which is in both sets.
</p>
<p>\(A^C \text{ or } A'=\{x\in U|x \not\in A\}\). The complement of A is the set that is not in A and is in some
	universal set
	U.
</p>
<p>\(A\setminus B=\{x|x\in A \land x \not\in B\}\). This is the difference in the two sets.</p>
<p>Given two sets \(X\) and \(Y\), their Cartesian product \(X\times Y\) is the set of all ordered pairs
	\((p,q)\)
	such
	that \(p\in X\) and \(q\in Y\).</p>
<p>Two sets are disjoint if they have no elements in common.</p>
<h4>Common number sets</h4>
<p>\(\mathbb{N}\) is the set of natural numbers, which are whole numbers from 0 or 1 upwards.</p>
<p>\(\mathbb{Z}\) is the set
	of integers, which are the negative whole numbers, zero, and positive whole numbers.</p>
<p> \(\mathbb{Q}\) is the set of
	rational numbers, which are numbers you can make by dividing one integer by any integer except zero. Its
	symbol
	is Q
	because it stands for "quotient" since R is used for real numbers. pi, e, square roots, golden ratio are NOT
	rational because their digits go on forever without repeating and they can't be written as a fraction.</p>
<p> \(\mathbb{A}\) is the set of algebraic numbers,
	numbers that are solutions to polynomial equations with rational coefficients.</p>
<p>\(\mathbb{R}\) is the set of real
	numbers, which are any value on the number line. Real numbers can be positive, negative, or zero, rational
	or
	irrational, algebraic or transcendental, and can have infinite digits.</p>
<p>\(\mathbb{I}\) is the set of imaginary numbers,
	that when squared give a negative result.</p>
<p>\(\mathbb{C}\) is the set of complex numbers, combination of a real and an
	imaginary number in the form a + bi, where a and b are real and i is imaginary.</p>
<h4>Properties of sets</h4>
<p>Associative laws:\[X \cup (Y \cup Z)=(X \cup Y) \cup Z\]\[X \cap (Y \cap Z)=(X \cap Y)\cap Z\]</p>
<p>Commutative laws:\[X \cup Y=Y \cup X\]\[X \cap Y=Y\cap X\]</p>
<p>Distributive laws:\[X\cup(Y\cap Z)=(X\cup Y)\cap (X\cup Z)\]\[X\cap(Y\cup Z)=(X\cap Y)\cup (X\cap Z)\]</p>
<p>Identity laws:\[X \cup \emptyset = X\]\[X \cap U = X\]</p>
<p>Complement laws:\[X \cup X' = U\]\[X \cap X' = \emptyset\]</p>
<p>Indempotent laws:\[X \cup X = X\]\[X \cap X = X\]</p>
<p>Bound laws:\[X \cup U = U\]\[X \cap \emptyset = \emptyset\]</p>
<p>Absorption laws: \[X \cup (X \cap Y) = X\]\[X \cap (X \cup Y) = X\]</p>
<p>De Morgan's laws:\[(X \cup Y)'=X' \cap Y'\]\[(X \cap Y)' = X' \cup Y'\]</p>
<h4>Inclusion/exclusion</h4>
<p>\(|A\cup B|=|A|+|B|-|A\cap B|\). The total number of elements in A and B is the sum of each minus the ones
	that
	are in both.</p>
<p>\(|A\cup B \cup C|=|A|+|B|+|C|-|A\cap B|-|B\cap C|-|A\cap C|+|A\cap B \cap C|\). The total number of elements
	in
	A, B, and C are the sum of the elements of each, minus the ones that are in both, plus the ones that are in
	all
	three.</p>
<p>The natural question to this is how do you continue finding the cardinality of the union of more and more
	sets.
	This is the inclusion-exclusion principle within combinatorics. To find the cardinality of the union of n
	sets,
	include the cardinalities of the sets, then exclude the cardinalities of the pairwise intersections, then
	include the cardinalities of the triple-wise intersections, and exclude the cardinalities or the
	quadruple-wise
	intersections, and so on, until the cardinality of the n-tuple-wise intersection is included (if n is odd)
	or
	excluded (if n is even).</p>
\[\left\vert\bigcup_{i=1}^n A_i\right\vert=\sum_{\emptyset\neq J\subseteq
\{1,...,n\}}(-1)^{|J|+1}\left\vert\bigcap_{j\in
J}A_j\right\vert\]
<h4>Partition of a set</h4>
<p>A partition of a set A is a set of subsets \(\{A_1, A_2, ...,A_k\}\) such that the \(A_i\) are all disjoint
	(the
	intersection between any two sets is empty or \(\phi\), aka they do not overlap) and that fill up A.
</p>
<h4>Relations</h4>
<p>A relation is an association between two sets of information. A pairing of elements of one set with the
	elements
	of
	another set can be ordered; in this case, the first set is the domain set and the other set is the range
	set.
</p>
<h4>Functions</h4>
<p>A function is a well-behaved relation which maps every element of the domain set to a single element of the
	range
	set. All functions are relations, but not all relations are functions.</p>
<p>Suppose A and B are sets and \(f: A \rightarrow B\) is a function. Define \(\text{im}(f)=\{b\in
	B|b=f(a)\text{
	for
	some
	}a\in A\}\).
	The image of the function is all the elements of b that comes from A transformed by the function. Define
	\(f^{-1}(b)=\{a\in A | f(a)=b\}\). The inverse is the element in A that goes to b.</p>
<h4>Domain, codomain, range</h4>
<p>In its simplest form the domain is all the values that go into a function, and the range is all the values
	that
	come
	out. A function relates an input to an output. A function is defined by sets (relates each element of a set
	with
	exactly one element of another set). What can go into a function is called the domain. What may possibly
	come
	out of
	a function is called the codomain. What actually comes out of a function is called the range. For example,
	if
	the
	function is f(x) = 2x+1, the domain is what x can be, the codomain is what 2x+1 can be, and the range (or
	image)
	is
	what f(x) can be. We define the domain and the codomain, and these along with the function determine the
	range.
	For
	example, if we set the codomain to be all real numbers, then square root is not a function, but if we define
	it
	to
	be non-negative real numbers, square root IS a function.</p>
<p>\(f:\mathbb{N}\rightarrow \mathbb{N}\) means the function f has the domain N (natural numbers) and a codomain
	of
	N as
	well.</p>
<p>\(f:x\mapsto x^2\) means the function f takes in x and returns x^2.</p>
<p>\(f:x= x^2\) means the function f takes in x and returns x^2 (maps to).</p>
<h4>Injective, surjective and bijective</h4>
<img src="https://www.mathsisfun.com/sets/images/function-mapping.svg">
<p>A function is never one-to-many, tested by the vertical line test, but can be many-to-one. Injective is a
	function in
	which many-to-one is not okay, but you can have values that are not pointed at. Injective is also called
	one-to-one,
	and can be tested with horizontal line test.
	Surjective is every "B" has at least one matching "A", but doesn't have to be one-to-one. Surjective is also
	known
	as "onto." Bijective means both one-to-one and onto, or injective and surjective together. Bijective is also
	known
	as "correspondence." Bijective functions have an inverse.</p>
<h4>Surds</h4>
<p>When a number is a root and irrational, it is a surd. Not all roots are surd if they can be simplified to a
	rational
	number. \(\sqrt{2}\) is a surd, \(\sqrt{4}=2\) is not.</p>
<div class="second">Equivalence relations</div>
<p>An equivalence relation is a binary relation that is reflexive, symmetric and transitive. Reflexive means
	that it
	is
	equivalent to itself, symmetrical is a to b if and only if b to a, and transivity is if a to b and b to c
	then a
	to
	c.</p>
<div class="first">Pre-numerical stage, concept of numbers</div><a class="anchor" id="concept"></a>
<div class="second">Classification</div>
<div class="second">Counting</div>
<div class="second">Synchrony</div>
<div class="second">One-to-one correspondence</div>
<div class="second">Counting systematically</div>
<div class="second">Subitizing</div>
<div class="second">Conservation of numbers</div>
<div class="second">Number value or cardinality</div>
<div class="second">Zero and numbers beyond 10</div>
<div class="first">Natural numbers</div><a class="anchor" id="natural"></a>
<p>The elements of the set of natural numbers:\[\mathbb{N}=\{1,2,3,4,5,...\}\]are the numbers we use for
	counting.
	They
	come equipped with an ordering and also come equipped with the:</p>
<p>Well-ordered axiom: Every set of natural numbers except the empty set has a smallest element.</p>
<h4>Principle of induction</h4>
<p>If \(S\) is a subset of \(\mathbb{N}\), such that (i) \(1\in S\) and (ii) whenever \(n\in S\), the next
	number
	after
	\(n\) is also an element of \(S\), then \(S\) is equal to \(\mathbb{N}\), the set of all natural numbers.
</p>
<h4>Making definitions by induction</h4>
<p>A function \(f\) whose domain is \(\mathbb{N}\) may be defined in two steps: (i) define \(f(1)\) and (ii)
	define
	each \(f(n+1)\), possibly using a previous definition of \(f(n)\). The domain of the function \(f\) is then
	a
	subset
	of \(\mathbb{N}\) that contains \(1\) by (i), and whenever \(n\) is in the domain, then \(n+1\) is also in
	the
	domain by (ii). Therefore the domain of \(f\) is \(\mathbb{N}\), by the principle of induction.</p>
<h4>Primes</h4>
<p>A natural number \(p\) (other than 1) is prime if the only numbers that divide \(p\) are 1 and \(p\) itself.
	The
	primes are the building blocks of the natural numbers much like the elements are the building block of the
	molecules. The factorization of a number into a product of primes is unique. If you are given a very large
	computer,
	there is no known algorithm for factoring it quickly as a product of primes.</p>
<h4>Fundamental theorem of arithmetic</h4>
<p>Every natural number except 1 factors as a product of prime numbers.</p>
<h4>Euclid</h4>
<p>There are infinitely many prime numbers.</p>
<div class="first">Integers, rational numbers</div><a class="anchor" id="integer"></a>
<p>The elements of the set of integers: \[\mathbb{Z}=\{...,-5,-4,-3,-2,-1,0,1,2,3,4,5,...\}\]consist of three
	types
	of
	numbers: (i) the natural numbers, the negative integers, and the number \(0\).</p>
<div class="first">Real numbers, complex numbers</div><a class="anchor" id="real"></a>
<p>The real numbers: \[\mathbb{R}=\{\text{numbers on the number-line}\}\]require some real analysis for a
	"proper"
	definition.</p>
<div class="first">Number theory</div><a class="anchor" id="number"></a>
<p>Number theory, or arithmetic, is a branch of pure mathematics devoted primarily to the study of the integers
	and
	integer-valued functions.</p>
<h4>Divisibility</h4>
<p>Natural numbers are the group of numbers starting at 1 and continues: 1, 2, 3, 4, 5, and so on. Zero is not in this
	group. Whole numbers has all of the natural numbers plus the number 0. Not everyone accepts that natural numbers
	does not include 0. Integers has all whole numbers in it and their negatives. Rational numbers are any numbers that
	can be expressed as a ratio of two integers, and irrational numbers are those that cannot. Together, rational and
	irrational numbers make up real numbers. Imaginary numbers are based on the imaginary number \(i\) which is
	\(\sqrt{-1}\). Complex numbers are combinations of a real number and an imaginary number in the form \(a+bi\).</p>
<p>Elementary number theory involves divisibility among integers. Let \(a,b \in Z\). The expression \(a|b\), ie. a
	divides b, if \(\exists c \in Z:b=ac\), ie. there is an integer \(c\) such that \(c\) times \(a\) equals \(b\). If
	\(a\) divides \(b\), then we say that \(a\) is a factor of \(b\) or \(a\) is a divisor of \(b\), and \(b\) is a
	multiple of \(a\). \(b\) is even if and only if \(2|b\).</p>
<p>Let \(a,d \in Z\) with \(d>1\). Then \(a\) mod \(d\) denotes that the remainder \(r\) from the division algorithm
	with divident \(a\) and divisor \(d\), ie. the remainder when \(a\) is divided by \(d\). We can compute a mod \(d\)
	by: \(a-d*\lfloor a/d \rfloor\), where \(\lfloor a/d \rfloor\) represents the floor of the real number.</p>
<p>Let \(Z^+=\{n \in Z | n > 0\}\) and \(a, b \in Z, m \in Z^+\). Then \(a\) is congruent to \(b\) modulo \(m\), written
	as \(a \equiv b \pmod{m}\), if and only if \(m|a-b\). Alternative, \(a\) is congruent to \(b \pmod{m}\) if and only
	if \((a-b)\pmod{m}=0\).</p>
<h4>Prime number, GCD</h4>
<p>An integer \(p>1\) is prime if and only if it is not the product of any two integers greater than \(1\), ie. \(p\) is
	prime if \(p>1 \land \exists \neg a,b \in N:a>1,b>1,a*b=p\).</p>
<p>The only positive factors of a prime \(p\) are \(1\) and \(p\) itself. Nonprime integers greater than \(1\) are
	called composite numbers.</p>
<p>The greatest common divisor \(\text{gcd}(a,b)\) of integers \(a,b\) is the greatest integer \(d\) that is a divisor
	of both \(a\) and of \(b\), ie.\(d=\text{gcd}(a,b)\) for \(\text{max}(d:d|a \land d|b)\). For example,
	\(\text{gcd}(24,36)=12\).</p>
<p>Integers \(a\) and \(b\) are called relatively prime or coprime if and only if their GCD is 1. For example, 35 nor 6
	are prime but they are coprime as they have no common factors greater than 1, so their GCD is 1. A set of integers
	is relatively prime if all possible pairs drawn from the set are relatively prime.</p>
<div class="first">Measures and units</div><a class="anchor" id="measure"></a>
<div class="first">Ratio and proportion, percentages</div><a class="anchor" id="ratio"></a>
<div class="first">Real-life mathematics, practical arithmetic</div><a class="anchor" id="practical"></a>
<div class="first">Informal geometry</div><a class="anchor" id="informal"></a>
<p>3D rotations are not commutative.</p>
<div class="first">Area and volume</div><a class="anchor" id="area"></a>
<div class="first">Plane and solid geometry</div><a class="anchor" id="plane"></a>
<div class="first">Transformation geometry</div><a class="anchor" id="transformation"></a>
<div class="first">Plane and spherical trigonometry</div><a class="anchor" id="trigonometry"></a>
<h4>Polar coordinates</h4>
<p>For problems involving directions from a fixed origin (or pole) \(O\), it is often convenient to a specify a
	point
	\(P\) by its polar coordinates \((r,\theta)\), where \(r\) is the distance \(OP\) and \(\theta\) is the
	angle
	that
	the direction of \(r\) makes with a given initial line. Given the Cartesian equation for a curve, the polar
	equation
	for the same curve can be obtained by substituting \(r\cos \theta\) and \(r\sin \theta\) for \(x\) and
	\(y\),
	respectively.</p>
<h4>Law of sines</h4>
\[\frac{a}{\sin A}=\frac{b}{\sin B}=\frac{c}{\sin C}\]
<p>Trigonometry, or "measurement of triangles" is the branch of math that studies side lengths and angles of
	triangles. Became more popular due to the demands of navigation and the need for maps of large areas.
</p>
<img src="{{ url_for('static', filename='img/math/trig.png') }}" width=400>
<h4>Law of cosines</h4>
<p>The law of cosines, or cosine formula, or al-Kashi's theorem, relates the lengths of the sides of a
	triangle
	to
	the cosine of one of its angles. It states that, given a triangle with an angle between two side lengths
	a
	and
	b, then \(c^2=a^2+b^2-2ab\cos{\theta}\). This is a generalization of the Pythagorean theorem, and
	reduces to
	the
	Pythagorean them if the angle is a right angle.</p>
<div class="first">Analytic geometry, vector algebra</div><a class="anchor" id="analytic_geometry"></a>
<div class="first">Descriptive geometry</div><a class="anchor" id="descriptive"></a>
<div class="first">Elementary algebra</div><a class="anchor" id="elementary"></a>
<h4>Parabolas</h4>
<p>The graphs of quadratic functions are parabolas. All parabolas are vaguely "U" shaped and will have a highest
	or
	lowest point called the vertex. Parabolas may open up or down and will always have a single y-intercept but
	may
	or
	may not have x-intercepts. Every parabola has an axis of symmetry. In order to sketch a parabola, find the
	vertex,
	then find the y-intercept, then solve \(f(x)=0\) to find the x-intercepts (if they exist). Find another
	point on
	the
	other side of the vertex, and sketch the graph.</p>
<p>The first form of the parabola is \[f(x)=a(x-h)^2+k\]where \(a\) tells us if the parabola opens up (if
	positive)
	or
	down (if negative), and the vertex is the point \((h,k)\).</p>
<p>Most parabolas, however, are in the form:\[f(x)=ax^2+bx+c\]where \(a\) again tells us whether the parabola
	opens
	upwards or downwards, and the vertex is in the form \((-\frac{b}{2a},f(-\frac{b}{2a}))\), and we're given
	the
	y-intercept for free as \((0,c)\).</p>
<p>You can convert from the quadratic form to the first form by completing the square.</p>
\[f(x)=ax^2+bx+c\]\[=a(x^2+\frac{b}{a}x+\frac{c}{a})\]\[=a(x^2+\frac{b}{a}x+(\frac{b}{2a})^2-(\frac{b}{2a})^2+\frac{c}{a})\]\[=a(x+\frac{b}{2a})^2-\frac{b^2}{4a}+c\]
<h4>Ellipses</h4>
<p>The standard form of an ellipse is:\[\frac{(x-h)^2}{a^2}+\frac{(y-k)^2}{b^2}=1\]where the right side MUST be
	\(1\)
	and the point \((h,k)\) is the center of the ellipse.</p>
<p>To sketch the ellipse, you can obtain the right most point at \((h+a,k)\), the left most point at
	\((h-a,k)\),
	the
	top most point at \((h,k+b)\), and the bottom most point at \((h,k-b)\).</p>
<p>Note that circles are a special case of an ellipse where \(a=b\) and so the equation of a circle
	is:\[(x-h)^2+(y-k)^2=a^2\]with a radius \(a\).</p>
<h4>Hyperbolas</h4>
<p>Hyperbolas look like two vaguely parabola shaped piees that open either up and down or right and left.
	Alongside
	them
	are two lines called asymptotes that guide where the hyperbolas travel. The point where the two asymptotes
	cross
	is
	called the center of the hyperbola. The standard form of the hyperbola
	is:\[\frac{(x-h)^2}{a^2}-\frac{(y-k)^2}{b^2}=1\]where the center is \((h,k)\), the hyperbola opens left and
	right,
	the vertices are at \((h+a,k)\) and \((h-a,k)\), the slopes of the asymptotes are \(\pm\frac{b}{a}\) and the
	equations of the asymptotes are \(y=k\pm \frac{b}{a}(x-h)\). The standard form for the hyperbola that opens
	up
	and
	down is the same except swap x and y in the equation and then the vertices are \((h,k+b)\) and \((h,k-b)\).
</p>
<h4>Properties of logarithms</h4>
\[\log_b 1=0\]
\[\log_b b=1\]
\[\log_b b^x=x\]
\[\log_b b^{f(x)}=f(x)\]
\[b^{\log_b x}=x\]
\[b^{\log_b f(x)}=f(x)\]
\[\log_b(xy)=\log_b x+\log_b y\]
\[\log_b(\frac{x}{y})=\log_b x-\log_b y\]
\[\log_b(x^y)=y\log_b x\]
\[\text{If }\log_b(x)=\log_b y, \text{ then }x=y\]
exponent properties, rational exponents, negative exponnets, radicals, polynomials, factoring, rational
expressions,
complex numbers
solving equations and inequalities - linear equations, quadratic equations, completing the square, quadratic
formula,
applications of linear and quadratic equations, reducible to quadratic form, equations with radicals, linear
inequalities, polynomial & rational inequalities, absolute vlaue equations & inequalities
graphing and functions - graphing lines, circles, and picewise functions, function definition, function
notation,
function composition, inverse functions
common graphs - parabolas, ellipses, hyperbolas, absolute value, square root, constant function, rational
functions,
shift, reflections, symmetry
polynomial functions - dividing polynomials, zeroes/roots of polynomials, finding zeroes of polynomials,
graphing
polynomials, partial fractions
exponential functions, logarithm functions, solving exponential functions, solving logarithm functions,
applications
systems of equations, substitution method, elimination method, augmented matrix, nonlinear systems
<li>So let's discuss algebra real quick. The word itself is about the 'reunion of broken parts'... an Arabic
	word.
	It's
	about the study of symbols. You can divide algebra into elementary algebra and abstract algebra. Elementary
	algebra
	is essential for studying any science, whereas abstract algebra is primarily studied by mathematicians.
	Algebra
	is
	concerned with the solving of equations of numbers. Then it extended also into non-numerical objects and
	abstracted
	them into groups, rings, and fields, which we will look at later. Algebra is pretty much foundational to all
	of
	math.</li>
<h4>Fundamental Theorem of Algebra</h4>
<p>Polynomials with complex coefficients factor into linear polynomials with complex coefficients. The
	factorization
	is
	unique.</p>
<h4>Binomial theorem</h4>
<p>The binomial theorem, or binomial expansion, describes the algebraic expansion of powers of a binomial.
	According
	to
	the theorem, it is possible to expand the polynomial \((x+y)^n\) into a sum involving terms of the form
	\(ax^by^c\),
	where the exponents \(b\) and \(c\) are nonnegative integers \(b+c=n\), and the coefficient \(a\) of each
	term
	is a
	specific positive integer depending on \(n\) and \(b\). The coefficient \(a\) is known as the binomial
	coefficient
	\(n \choose b\) or \(n \choose c\) (the two have the same value). These coefficients for varying \(n\) and
	\(b\)
	can
	be arranged to form Pascal's triangle.</p>
\[(x+y)^n={n\choose 0}x^ny^0+{n\choose 1}x^{n-1}y^1+{n\choose 2}x^{n-2}y^2+\ldots+{n\choose
{n-1}}x^1y^{n-1}+{n\choose
n}x^0y^n+\]
<p>In Pascal's triangle, the value of \(n \choose b\) is the \(b\)th value in the \(n\)th row.</p>
<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3a8beb14cd64d7451f9f9e4f965713d3e7e62cbb"
	alt="pascals triangle">
<h4>Factoring Cubic Polynomials</h4>
<p>A cubic polynomial is of the form \(p(x)=a_3x^3+a_2x^2+a_1x+a_0\). The fundamental theorem of algebra
	guarantees
	that
	if \(a_0, a_1, a_2, a_3\) are all real numbers, then we can factor the polynomial into the form
	\(p(x)=a_3(x-b_1)(x^2+b_2 c + b_3)\). In other words, we can always factor the cubic polynomial into the
	product
	of
	a first degree polynomial and a second degree polynomial.</p>
<p>The first method is factoring by grouping but only works in some cases. Consider the polynomial
	\(p(x)=x^3-4x^2+3x-12\). Group the first two terms and the last two terms together:
	\(p(x)=(x^3-4x^2)+(3x-12)\)
	and
	then pull out the common factors: \(p(x)=x^2(x-4)+3(x-4)\). Notice that we now have common factors and can
	now
	factor out: \(p(x)=(x-4)(x^2+3)\).</p>
<p>Otherwise, we can use the rational root theorem if all the coefficients are rational numbers. The rational
	root
	theorem states that the possible roots of a polynomial are the factors of the last term divided by the
	factors
	of
	the first term. Take for example the polynomial \(p(x)=x^3+5x^2-2x-24\). The possible roots are the roots
	are
	the
	factors of 24 over the factors of 1. Therefore, the possible roots are \(\pm 1,2,3,4,6,8,12,24\). We plug
	each
	of
	these numbers into \(p(x)\) until we find a root. This results in finding that 2 is such a root, meaning
	\(x-2\)
	is
	a factor of our polynomial. Do long division and we can now simplify \(p(x)=(x-2)(x^2+7x+12)\). We can
	simplify
	the
	binomial further to get a final factor.</p>
<div class="first">Equations and inequalities</div><a class="anchor" id="equation"></a>
<div class="first">Groups, rings, fields</div><a class="anchor" id="group"></a>
<p>An algebraic structure consists of one or two sets closed under some operations and satisfying a number of axioms,
	including none.</p>
<h4>Groups</h4>
<p>A set \(S\) closed under a binary operation \(\cdot\) forms a group if the binary operation satisfies the following
	four criteria:</p>
<p>Associative: \(\forall a,b,c \in S\), the equation \((a \cdot b) \cdot c=a \cdot (b \cdot c)\) holds.</p>
<p>Identity: there exists an identity element \(I \in S\) such that for all \(a \in S\), \(I \cdot a = a \cdot I = a\).
</p>
<p>Inverse: every element \(a \in S\), has an inverse \(a' \in S\) with respect to the binary operation, ie. \(a \cdot
	a' = I\). For example, the set of integers \(\mathcal{Z}\) with respect to the addition operation is a group. The
	identity element of the set is \(0\) for the addition operation. \(\forall x \in Z\), the inverse of \(x\) would be
	\(-x\), which is also included in \(Z\).</p>
<p>Closure: \(\forall a,b \in S\), the result of the operation \(a \cdot b \in S\).</p>
<p>A group that is commutative, ie. \(a \cdot b = b \cdot a\), is known as a commutative or Abelian group.</p>
<p>The set of natural numbers is not a group, since there is no inverse. However, the set of natural numbers has some
	structure. Sets with an associative operation are called semigroups; if they also have an identity element, then
	they are called monoids. Our set of natural numbers under addition is then an example of a monoid, a structure that
	is not quite a group because it doesn't have an inverse. A monoid is a set \(S\) that is closed under a single
	associative binary operation \(\cdot\) and has an identity element \(I \in S\) such that for all \(a \in S\), \(I
	\cdot a= a \cdot I=a\). A monoid must contain at least one element.</p>
<p>The same set of natural numbers also forms a monoid under multiplication with identity element \(1\).</p>
<p>A subgroup is a group \(H\) contained within a bigger one \(G\) such that the identity element of \(G\) is contained
	in \(H\), and whenever \(h_1\) and \(h_2\) are in \(H\), then so are \(h_1 \cdot h_2\) and \(h_1^{-1}\). Thus, the
	elements of \(H\), equipped with the group operation on \(G\) restricted to \(H\), indeed form a group.</p>
<p>Given any subset \(S\) of a group \(G\), the subgroup generated by \(S\) consists of products of elements of \(S\)
	and their inverses. It is the smallest subgroup of \(G\) containing \(S\).
</p>
<p>For example, let \(G\) be the Abelian group whose elements are \(G=\{0,2,4,6,1,3,5,7\}\) and whose group operation is
	addition modulo 8. This group has a pair of nontrivial subgroups: \(J=\{0,4\}\) and \(H=\{0,2,4,6\}\), where \(J\)
	is also a subgroup of \(H\).</p>
<p>In group theory, a cyclic group is a grou pthat can be generated by a single element, in the sense that the group has
	an element \(a\) (called the generator of the group) such that, when written multiplicatively, every element of the
	group is a power of \(a\). A group \(G\) is cyclic if \(G=\{a^n\text{ for any integer }n\}\). Since any group
	generated by an element in a grou pis a subgroup of that group, showing that the only subgroup of a group \(G\) that
	contains \(a\) is \(G\) itself suffices to show that \(G\) is cyclic.</p>
<h4>Rings</h4>
<p>If we take an Abelian group and define a second operation on it, a new structure is found that is different from just
	a group. If this second operation is associative and is distributive over the first, then we have a ring.</p>
<p>A ring is a triple of the form \(S,+,\cdot)\), where \((S,_)\) is an Abelian group, \(S,\cdot\) is a semigroup, and
	\(\cdot\) is distributive over \(+\), ie. \(a,b,c \in S\), the equation \(a \cdot (b+c)=(a \cdot b) + (a \cdot c)\)
	holds. Further, if \(\cdot\) is commutative, then the ring is said to be commutative. If there is an identity
	element for the \(\cdot\) operation, then the ring is said to have an identity.</p>
<p>For example, \((Z,+,*)\), ie. the set of integers with the usual addition and multiplication operations, is a
	commutative or Abelian ring with an identity element of \(1\).</p>
<p>Note that the second operation may not have an identity element, nor do we need to find an inverse for every element
	with respect ot this second operation.</p>
<p>A field is a ring for which the elements of the set, excluding 0, form an Abelian group with the second operation. A
	simple example of a field is the field of rational numbers \(R,+,*\) with the usual addition and multiplication
	operations. The numbers of the format \(a/b \in R\), where \(a,b\) are integers and \(b\neq 0\). The additive
	inverse of such a fraction is simply \(-a/b\), and the multiplicative inverse is \(b/a\) provided that \(a \neq 0\).
</p>
<div class="first">Ordered algebraic structures</div><a class="anchor" id="ordered"></a>
<div class="first">Linear algebra</div><a class="anchor" id="linear"></a>
<p>Information provided from <a href="https://joshua.smcvt.edu/linearalgebra/" target="_blank">Jim Hefferson's
		Linear
		Algebra book</a> and <a
		href="https://www.youtube.com/watch?v=kjBOesZCoqc&list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B&ab_channel=3Blue1Brown"
		target="_blank">3Brown1Blue's playlist on Essence of Linear Algebra</a>.</p>

<p>Linear algebra discusses how to manipulate linear systems, vector spaces, maps between spaces, determinants,
	and
	similarity.</p>

<h4>Gauss's method</h4>
<p>So what does it mean to have a linear combination? A linear combination is where you have a bunch of
	variables,
	and
	you assign a coefficient to each of those variables. Those coefficients multiplied by their corresponding
	variables
	add up to a constant. A linear combination cannot have any modifications to the variable, so you can't have
	\(\sin{x}\) or \(x^2\).</p>
<p>To find the set of all solutions for the system of combinations is to solve the system. Gauss's method is to
	transform each system by swapping, multiplying, rescaling, etc. such that the system is brought to a form
	that
	can
	easily find the value of each variable. The three valid operations on a linear combination within a system
	is 1)
	swapping with another, 2) multiplying both sides by a nonzero constant, and 3) replacing itself with the sum
	of
	itself and a multiple of another. Note that multiplying by 0 is not allowed, and adding a multiple of a row
	to
	itself
	is not allowed because adding -1 times the row to itself has the effect of multiplying the row by 0.</p>
<p>The first variable with a nonzero coefficient is the row's leading variable. A system is in echelon form if
	each
	leading variable is to the right of the leading variable in the row above it, except for the leading
	variable in
	the
	first row, and any rows with all-zero coefficients are at the bottom.</p>
<p>Gaussian method systematically solves these linear systems by using operations to remove the leading variable
	one
	at
	a time. So the first step is you remove x from all the equations by manipulating each equation to remove x,
	then
	swap lines to get into echelon form, and then using the second equation to manipulate the rest, and so
	forth.
	You
	eventually get the last variable isolated and then back-solve to get the rest of the values.</p>
<p>If there are redundant equations, eventually you will resolve the system so that one line says 0=0,
	indicating a
	redundant equation. If you get something like 0=2, then it means there's an inconsistency and that means the
	system
	has no solutions. If you can't isolate one variable, and are left with something like \(x+y=4\), then your
	system
	has infinite solutions.</p>
<h4>Describing the solution set</h4>
<p>It's best to describe the solution set if there are many solutions in terms of free variables, which are
	variables
	that are not leading in an echelon form linear system. You should rephrase the solution set in terms of
	these
	variables to make it easier to understand. These variables that we use to describe a family of solutions are
	called
	parameters. Free variables and parameters aren't always the same because we can choose not to use a free
	variable as
	a parameter.</p>
<h4>Matrices</h4>
<p>An \(m\times n\) matrix is a rectangular array of numbers with m rows and n columns. Each number in the
	matrix is
	an
	entry. Matrices are usually denoted with an upper case roman letter. A matrix with 2 rows and 3 columns
	would be
	said to be a "two-by-three" matrix, with number of rows always stated first. Matrix entries are named with
	the
	corresponding lower-case letter, then with subscripts of m,n. Writing linear systems in matrix form just
	makes
	things easier so you don't have to write all the variables and signs. Adding a vertical bar separates
	coefficients
	on the left side and constants on the right. With the bar, a matrix becomes an augmented matrix.</p>
<p>You can also write the solution sets in matrix form by turning the x, y, z, w (etc) into column vectors and
	adding
	those vectors together (it's hard to visualize so have to look up at least until I can add it in mathjax). A
	column
	vector or a vector is a matrix with a single column. You can also have a row vector. The entries of a vector
	are
	sometimes called components. A column or row vector whose components are all zeros is a zero vector. Vectors
	are
	usually represented with an arrow above a lower-case letter. Vectors can be summed together (must have the
	same
	number of entries) or scaled by a real number. All linear systems will, with Gauss's method, end up with the
	same
	free variables.</p>
<p>The transpose of a matrix is the matrix whose columns are the rows of the original matrix.</p>
<h4>General = Particular + Homogeneous</h4>
<p>The solution description has two parts, the particular solution (for example (1,2,3)) and the unrestricted
	linear
	combination of vectors for the free variables after Gaussian reduction. A linear equation is homogeneous if
	it
	has a
	constant of zero (all of the variables*coefficients add up to zero). A homogeneous system must always be
	consistent
	because there is always the zero vector as a solution.</p>
<p>We say that the set of vectors is generated by or spanned by the set if the vector can be a linear
	combination of
	the
	vectors in the set.</p>
<p>We call the matrix of the coefficients of a system nonsingular if it is a square matrix with a unique
	solution
	(no
	free variables) in a homogeneous system (setting all the constants to 0), which means there are the same
	number
	of
	echelon form equations as there are variables. A nonsingular coefficient matrix indicates the system only
	has
	one
	unique solution. A coefficient matrix is singular (singular in this case meaning different from expected) if
	its
	homogeneous system has zero or infinite solutions. What this means to me is that you can "solve" a linear
	system
	if
	you have as many VALID equations AFTER Gaussian reduction as unknowns. The idea that you can solve a system
	as
	long
	as you have as many equations as unknowns is often not true.</p>
<h4>Dot product</h4>
<p>The dot product, or inner product, or scalar product, of two n-component real vectors is the linear
	combination
	of
	their components. The dot product is commutative and distributive over vector addition, and associative over
	scalar
	multiplication.</p>
<h4>Linear Geometry</h4>
<p>The solution set of a linear system with \(n\) unknowns is a linear surface in \(\mathbb{R}^n\).
	Specifically, it
	is
	a k-dimensional linear surface, where k is the number of free variables in echelon form version of the
	system.
	For
	instance, if there is just a single equation, then the solution set is an n-1-dimensional hyperplane. The
	solution
	set of the homogenous linear system is a linear surface passing through the origin. We can view the general
	solution
	set of any linear system as being the solution set of its associated homogeneous system offset from the
	origin
	by a
	vector, aka the particular solution.</p>
<p>A vector in its canonical position starts from the origin.</p>
<p>The length of a vector is the square root of the sum of the squares of its components. You can normalize a
	vector
	by
	reducing it to a vector with a magnitude of one. Then, take for example a two-dimensional plane. Put the two
	vectors
	in canonical position, and then take the plane formed by the origin and the endpoints. Consider a triangle
	formed by
	the origin and the endpoints of the two vectors. Applying the Law of Cosines, and taking into account that
	the
	length of a vector is the square root of the sum of its squares, we can get the angle between the two
	vectors to
	be:
	$$\theta=\cos^{-1}(\frac{u_1v_1+u_2v_2+u_3v_3}{|\vec{u}||\vec{v}|})$$</p>
<p>Even in higher-dimensional spaces, lines are straight and planes are flat. For any two points in a linear
	surface,
	the line segment between them is contained in that surface. If the linear surface was not flat, then that
	would
	allow for shortcuts where the shortest path between two vectors would not be the line between them. Linear
	surfaces
	therefore have no bends.</p>
<p>The angle between two nonzero vectors is:</p>
$$\theta=\cos^{-1}(\frac{\vec{u}\cdot\vec{v}}{|\vec{u}||\vec{v}|})$$
<p>Vectors are orthogonal (aka perpendicular) if and only if their dot product is zero. They are parallel if and
	only if
	their dot product equals the product of their lengths.</p>
<h4>Cauchy-Schwarz Inequality</h4>
<p>Cauchy-Schwarz inequality states that \(|\vec{u}\cdot\vec{v}|\leq|\vec{u}||\vec{v}|\) with equality if and
	only
	if one vector is a scalar multiple of the other. What this says is that if you take the dot product of two
	vectors,
	it
	will be less than or equal to the product of the length of the vectors. This allows for the prior equation
	for
	the
	angle between two vectors to be always possible.</p>
<h4>Gauss-Jordan Reduction</h4>
<p>The Gauss-Jordan Reduction is just an extension of Gauss's Method which making all of the leading entries
	into
	1's
	and then uses the leading entries to eliminate all other entries in each column by combining upwards. Using
	one
	entry to clear out the rest of a column is called pivoting on that entry. The resulting matrix is in reduced
	echelon
	form, in which each leading entry is a 1 and is the only nonzero entry in its column. The only advantage of
	reduced
	echelon form to normal echelon form is you can read out the description of the solution set from the matrix.
	Any
	two
	matrices that are interreducible by elementary row operations are row equivalent. Any matrix can only be
	reduced
	down to one reduced echelon form: there are not multiple variants.</p>
<p>It is not the set of parameters that is unique, it is the set of fre variables that is unique.</p>
<p>"The idea here is that one way to understand a mathematical situation is
	by being able to classify the cases that can happen. This is a theme in this book and we have seen this
	several
	times already. We classified solution sets of linear systems into the no-elements, one-element, and
	infinitely-many
	elements cases. We also classified linear systems with the same number of equations as unknowns into the
	nonsingular
	and singular cases."</p>
<li>You need matrix algebra to help solve systems of equations encountered in electrical circuit analysis.</li>
<h4>SageMath</h4>
<p>Sage is a math software you can use on Windows subsystem for linux (WSL) to help solve math problems.</p>
<h4>Input-Output analysis</h4>
<p>Mathematical models can get complicated/confusing very fast. Sensitivity analysis is seeing how sensitive the
	predictions of our model are to the accuracy of the assumptions. A single model does not suit every case and
	assuring that the assumptions underlying a model are reasonable for a particular prediction requires the
	judgments
	of experts.</p>
<h4>Vector space</h4>
<p>A vector space is a set of vectors for which all vectors within the space and scalars satisfy that the set is
	closed
	under vector addition, vector addition is commutative, associative, there is a zero vector, each vector has
	an
	additive inverse which sums to 0, scalar multiplication distributes over scalar addition and vector
	addition,
	scalar
	multiplication associates, and multiplication by the scalar 1 gives the identity operation. Particularly
	important
	are the closure conditions, which specify that addition and scalar multiplication operations are always
	defined
	for
	every pair of vectors and every scalar and vector, and the result of the operation is a member of the set.
</p>
<p>A one-element vector space is a trivial space.</p>
<img src="{{ url_for('static', filename='img/math/vector.png') }}">
<h4>Subspaces and Spanning Sets</h4>
<p>For any vector space, a subspace is a subset that is itself a vector space, under the inherited operations.
	Any
	subspace that is not the entire space itself is a proper subspace. A subset is a subspace if and only if it
	is
	closed under linear combinations. The span (or linear closure) of a nonempty subset S of a vector space is
	the
	set
	of all linear combinations of vectors from S. The span is also a subspace of the vector space.</p>
<h4>Span</h4>
<p>The span, or linear closure, or linear span, or linear hull, of a set is the smallest linear subspace that
	contains
	the set. It is the set of linear combinations of elements of S. The span of a set is a vector space, so you
	can
	use
	the phrases: set S spans vector space V; S generates V; V is spanned by S; V is generated by S; S is a
	spanning
	set
	of V; S is a generating set of V.</p>
<h4>Linear Independence</h4>
<p>In any vector space, a set of vectors is linearly independent if none of its elements is a linear combination
	of
	the
	others from the set. Otherwise the set is linearly dependent. A spanning set is minimal if and only if it is
	linearly independent. Subset preserves independence and superset preserves dependence.</p>
<p>Sets are collections with two properties: (i) order does not matter, and (ii) duplicates collapse. A
	collection
	where
	order does not matter and duplicates don't collapse is a multiset. So technically if we have a duplicate
	vector
	in
	our set it's not technically a set.</p>
<p>A set S is linearly independent if and only if for any vector v in S, its removal shrinks the span
	\([S-\{v\}]\not\subset[S]\) (not a subset of). In a vector space, any finite set has a linearly independent
	subset
	with the same span. Any set with the zero vector is linearly dependent.</p>
<h4>Linear combinations</h4>
<p>A linear combination is an expression constructed from a set of terms by multiplying each term by a constant
	and
	adding the results. So linear combinations are constructed from sets.</p>
<h4>Real coordinate space</h4>
<p>Real coordinate space of dimension n, denoted \(\mathbb{R}^n\), is the set of the n-tuples of real numbers,
	that
	is
	the set of all sequences of n real numbers. It is a real vector space, and its elements are called
	coordinate
	vectors. \(\mathbb{R}^n\) has an element \((x_1, x_2, ..., x_n)\).</p>
<h4>Minimal/maximal sets</h4>
<p>A minimal spanning set is one with the lowest number of vectors that spans the space. A maximal spanning set
	is
	the
	one with the highest number of vectors, and therefore IS the space. A minimal spanning set is linearly
	independent.
	A linearly independent set that is maximal spans the entire space.</p>
<h4>Basis</h4>
<p>A basis for a vector space is a sequence of vectors that is linearly independent and that spans the space.
	Because a
	basis is a sequence, order matters and it is denoted with angle brackets \(\langle \vec{\beta}_1,
	\vec{\beta}_2,
	...\rangle\). For any \(\mathbb{R}^n\), the standard or natural basis is the vectors that have 1 in their
	respective
	components and 0 in everything else. For example, R2 natural basis is (1,0) and (0,1). The trivial space has
	only
	one basis, that is the empty one. We have seen bases before, by finding the solution set by parametrizing
	certain
	free variables. The vectors in the solution set is the basis and the solutions spanned by the basis is the
	solution
	set and the vector space of solutions.</p>
<p>You can represent any vector in the vector space using the basis by using a column vector of the coefficients
	of
	a
	linear combination of the basis vectors. This requires the basis to be in sequence.</p>
$$\text{Rep}_B(\vec{v})=[\vec{v}]_B=\begin{pmatrix}c_1\\c_2\\ \vdots\\c_n\end{pmatrix}_B$$
<h4>Dimension</h4>
<p>A vector space is finite-dimensional if it has a basis with only finitely many vectors. The Exchange Lemma
	states
	that
	if you have a basis, then you make a linear combination of the vectors in the basis and switch that vector
	with
	one
	its constituents, then that new sequence with the vector is also a basis of the same space. In any
	finite-dimensional vector space, all bases have the same number of elements. The dimension of a vector space
	is
	the
	number of vectors in any of its bases. No linearly independent set can have a size greater than the
	dimension of
	the
	enclosing space. Basically, if you have a basis which is the size of the space, then this basis spans that
	space.
	You can have linearly independent sets within that basis that do not span the space, but you can turn those
	sets
	into a basis to eventually span the space.</p>
<h4>Vector spaces</h4>
<p>The row space of a matrix is the span of the set of its rows. The row rank is the dimension of this space,
	the
	number
	of linearly independent rows. If two matrices are related by a row operation, then their row spaces are
	equal.
	Gaussian reduction works by eliminating linear dependences among rows, leaving the span unchanged, until no
	nontrivial linear relationships remain among the nonzero rows. In short, Gauss's method produces a basis for
	the
	row
	space. The column space of a matrix is the span of the set of its columns. The column rank is the dimension
	of
	the
	column space, the number of linearly independent columns.</p>
<p>The tranpose of a matrix is the result of interchanging its rows and columns. To find the basis for the
	column
	space,
	transpose the matrix, reduce by Gauss's method, and then transpose back.</p>
<p>For any matrix, the row rank and column rank are equal. The rank of a matrix is its row rank or column rank.
	If a
	linear system has at least one particular solution for the set of solutions, the number of parameters equals
	\(n-r\),
	the number of variables minus the rank of the matrix of coefficients.</p>
<img src="{{ url_for('static', filename='img/math/rank.png') }}">
<h4>Head canon summary</h4>
<p>After reading the first couple of chapters of Linear Algebra book, my head started getting confused and I
	needed
	to
	review. This is how I ended up visualizing all these different parts in my head. Imagine a piece of paper as
	the
	whole vector space, cut up into a bunch of squares. There's a line across the middle (x-axis location)
	indicating
	zero. Grab a bunch of these squares/spots on the vector space, and you have a set, which is a collection of
	vectors.
	If you extend each square/vector vertically up and down infinitely, that will represent linear closure of
	the
	vector. Each vector will span a subspace (the line up and down) of the whole vector space. If you have a set
	of
	vectors, then the set will span all those areas up and down. If you have more than one vector vertially
	aligned
	with
	each other, then they are linearly dependent, meaning you can make up one vector from the other. A basis of
	a
	vector
	space is if you take one vector/square from each x-coordinate, so that the span of the set of vectors you
	chose
	makes up the whole vector space. The natural basis is if you take each square from the x-axis. Gauss's
	method
	basically takes a set of vectors, finds the vectors that are vertically aligned with others, and removes
	them
	and
	boils them down to just one square per subspace (vertical span).</p>
<img src="{{ url_for('static', filename='img/math/headcanon.png') }}">
<img src="{{ url_for('static', filename='img/math/headcanon2.png') }}">
<h4>Fields</h4>
<p>A field is a set on which addition, subtraction, multiplication, and division are defined and behave as the
	corresponding operations on rational and real numbers do. A field is a fundamental algebraic structure. The
	best
	known fields are the field of rational numbers, the field of real numbers and the field of complex numbers.
	The
	classic definition, referred as the field axioms, are:</p>
<ul>
	<li>Associativity of addition and multiplication: \(a+(b+c)=(a+b)+c\) and \(a\cdot(b\cdot c)=(a\cdot b)\cdot
		c\)
	</li>
	<li>Commutativity of addition and multiplication: \(a+b=b+a\) and \(a\cdot b = b \cdot a\)</li>
	<li>Additive and multiplicative identity: there exist two different elements 0 and 1 in F such that
		\(a+0=a\)
		and \(a+(-a)=0\)</li>
	<li>Additive inverses: for every a in F, there exists an element in F, denoted -a, called the additive
		inverse
		of a such that \(a+ (-a) = 0\)</li>
	<li>Multiplicative inverses: for every \(a\neq 0\) in F, there exists an element in F, denoted by
		\(a^{-1}\),
		called the multiplicative inverse of a such that \(a\cdot a^{-1}=1\)</li>
	<li>Distributivity of multiplication over addition, such that \(a\cdot (b+c)=(a\cdot b)+(a\cdot c)\)</li>
</ul>
<p>An example of a field is the ste of rational numbers with its usual addition and multiplication operations.
	An
	example of an algebraic structure that is not a field is the ingers, because it fails the condition that
	there
	is no multiplicative inverse. (5 is an integer but 1/5 is not.)</p>
<h4>Dimensional analysis and Buckingham's theorem</h4>
<p>In order to standardize across different unit systems, we should add units to all numerical values. To fix an
	equation that we have already, we can add a dimensional constant to any constants that we use to convert
	between
	units. Those equations that use dimensional constants (all values have units attached) are considered
	complete.
	The dimensional formula of some variable is its units, for example velocity is length over time. If all of
	the
	terms that we add or subtract in our equation have the same dimensional formula, then our equation is
	dimensionally homogeneous. If a term has no dimensions then it is dimensionless.</p>
<p>So we know that you can construct a dimensionally homogeneous expression by either multiplying dimensionless
	quantities or by adding dimensionless terms. If we assign any dimensionless product to be \(\prod_1,
	\prod_2,
	...\), then there has to be some function f (either adding or subtracting the products) that results in 0.
</p>
<p>Buckingham's theorem is a formalization of Rayleigh's method of dimensional analysis. Loosely, it states that
	if
	there is a physically meaningful equation involving a certain number n of physical variables, then the
	original
	equation can be rewritten in terms of a set of p=n-k dimensionless parameters constructed from the original
	variables. Buckingham's theorem states that any complete relationship among quantities with dimensional
	formulas
	can be
	algebraically manipulated into a form where there is some function f such that \(f(\prod_1,...,\prod_n)=0\)
	for
	a complete set \({\prod_1,...,\prod_n}\) of dimensionless products.</p>
<a href="https://www.youtube.com/embed/aOeHiK85xCc">link to vid</a>
<h4>Isomorphism</h4>
<p>An isomorphism between two vector spaces V and W is a map V -> W such that 1) it is a correspondence
	(one-to-one
	and onto) and 2) preserves structure (if you add two vectors or scale a vector you'll get the corresponding
	vector in the map). To show that something is onto, you must show that any member of one
	domain is the image of some member of the other. In essence, each vector in vector space 1 must map onto a
	vector in vector space 2. If this is possible, then the two vector spaces are isomorphs. Isomorphs have the
	same
	number of dimensions.</p>
<img
	src="https://shared.ontariotechu.ca/shared/department/student-life/student-learning-centre/nool/images/math/one-to-one-functions.JPG">
<img
	src="https://shared.ontariotechu.ca/shared/department/student-life/student-learning-centre/nool/images/math/onto-functions.JPG">
<p>An automorphism is an isomorphism of a space with itself. A dilation map that multiplies all vectors by a
	nonzero
	scalar s is an automorphism. Another automorphism is a rotation or turning map. A third type of automoprhism
	is
	one that flips or reflects all vectors over a line through the origin.</p>
<p>The rotation of a vector counterclockwise by \(\theta\) is \(\begin{pmatrix}\cos{\theta} && -\sin{\theta} \\
	\sin{\theta} && \cos{\theta}\end{pmatrix}\).</p>
<h4>Homomorphism</h4>
<p>A function between vector spaces that preserves addition and scalar multiplication is a homomorphism or
	linear
	map. Unlike isomorphisms, homomorphisms do not need to be onto or one-to-one. Therefore, under a
	homomorphism,
	the
	image of any subspace of the domain is also a subspace of the codomain. The image of the entire space, the
	range
	of
	the homomorphism, is a subspace of the codomain. The range space of a homomorphism is denoted h(V), and the
	dimension of the range space is the map's rank. In generalizing from isomorphisms to homomorphisms by
	dropping
	the
	one-to-one condition, we lose the property that, intuitively, the domain is "the same" as the range. We
	retain
	that
	a homomorphism describes how the domain is "analogous to" or "like" the range. We think of \(\mathbb{R}^3\)
	as
	like
	\(\mathbb{R}^2\) except that vectors have an extra component. We think of the vector with components x, y,
	and z
	as
	like the vector with components x and y. Defining the projection map makes precise which members of the
	domain
	we
	are thinking of as related to which members of the codomain. The idea that a homomorphism between two spaces
	expresses how the domain's vectors fall into classes that act like the range's vectors is a good way to view
	homomorphisms.</p>
<p>The null space or kernel of a linear map \(h:V\rightarrow W\) is the inverse image of \(\vec{0}_W\). The
	dimension of
	the
	null space is the map's nullity. A linear map's rank plus its nullity equals the dimension of its domain.
</p>
<img src="{{ url_for('static', filename='img/math/nullity.png') }}">
<p>So the range space is all the values that the map can create, so it can create (a, 0, b, 0), where a and b
	can be
	anything. The inverse of (0, 0, 0, 0) would mean that x and y have to be 0, but z can be anything since z is
	not
	accounted for in the image, so the null space is (0, 0, z). The dimension of (a 0 b 0) is how many vectors
	are
	in a
	basis (for example (1 0 0 0) and (0 0 1 0) is one basis), so the dimension of the range space (aka the rank
	of
	the
	linear map) is 2. The dimension of (0 0 z) is 1, and so the nullity is 1. 2 + 1 = 3, which is the dimension
	of
	the
	domain (x y z) has a natural basis (1 0 0), (0 1 0), (0 0 1).</p>
<p>For a homomorphism to exist, the dimension of the range must be less than or equal to the dimension of the
	domain.
	Under a homomorphism, independence may be lost. In contrast, dependence stays. Under a linear map, the image
	of
	a
	linearly dependent set is linearly dependent.</p>
<img src="{{ url_for('static', filename='img/math/nullity2.png') }}">
<h4>Matrix representation of linear maps</h4>
<img src="{{ url_for('static', filename='img/math/matrix_representation.png') }}">
<img src="{{ url_for('static', filename='img/math/matrix_representation_example.png') }}">
<p>To give a matrix representing a map, first fix some bases. Then, for each vector in the domain's basis, find
	its
	image under the map. Then find the representation of each image with respect to the codomain's basis.
	Finally,
	adjoin these representations to give the representing matrix.</p>
<p>The matrix-vector product of a mxn matrix and a nx1 vector is if you add up each term in each row in the
	matrix
	with
	the values in the vector, each of these sums makes up the new matrix-vector product. Briefly, application of
	a
	linear map is represented by the matrix-vector product of the map's representative and the vector's
	representative.
	A good way to view matrix-vector product is that it is formed from the dot products of the rows of the
	matrix
	with
	the column vector.
</p>
<img src="{{ url_for('static', filename='img/math/matrix_product.png') }}">
<p>The application of a linear map is represented by the matrix-vector product of the map's representative and
	the
	vector's representative.</p>
<a href="https://www.youtube.com/embed/RAGuqGDpauY">link to vid</a>
<h4>Matrices as Linear Maps</h4>
<p>Any matrix also defines a map. The dimension of the map's domain is the number of columns in the matrix and
	the
	dimension of the codomain is the number of rows. Any matrix represents a homomorphism between vector spaces
	of
	appropriate dimensions, with respect to any pair of bases. The rank of a matrix equals the rank of any map
	that
	it
	represents. A linear map is onto if the rank of its matrix representation equals the number of its rows, and
	a
	linear map is one-to-one if and only if the rank of its matrix representation equals the number of its
	columns.
	A
	linear map that is one-to-one and onto is nonsingular, otherwise it is singular. That is, a linear map is
	nonsingular if and only if it is an isomorphism. A nonsingular linear map is represented by a square matrix.
	A
	square matrix represents nonsingular maps if and only if it is a nonsingular matrix. Thus, a matrix
	represents
	isomorphisms if and only if it is square and nonsingular. By fixing spaces and bases we get a correspondence
	between
	maps and matrices.</p>
<h4>Matrix Operations</h4>
<p>The scalar multiple of a matrix is the result of entry-by-entry scalar multiplication. The sum of two
	same-sized
	matrices is their entry-by-entry sum. Any map scaled by 0 is the zero homomorphism and for any matrix
	multiplication
	by 0 is the matrix with all entries zero. A zero matrix has all entries 0, written as \(Z_{n\times m}\) or
	just
	0.
	The matrix-multiplicative product is shown below:
</p>
<img src="{{ url_for('static', filename='img/math/matrix_multiplicative.png') }}">
<p>The number of columns in the first matrix must equal the number of rows in the second. The i, j entry of the
	matrix
	product is the dot product of row i of the left matrix with column j of the right one. The composition of
	linear
	maps
	is represented by the matrix product of the representatives. Matrix products are associative and distributes
	over
	matrix addition. The matrix with all zeros except for 1s from the top left to bottom right is the identity
	matrix,
	such that IH=H. A matrix with all 0s except for a 1 in the i,j entry is an i,j unit matrix (or matrix unit).
	The
	main diagonal (or principal diagonal or simply diagonal) of a square matrix goes form the upper left to the
	lower
	right. A diagonal matrix is square and has 0's off the main diagonal. A permutation matrix is square and is
	all
	0s
	except for a single 1 in each row and column. The elementary reduction matrices (or just elementary
	matrices)
	result
	from applying a single Gaussian operation to an identity matrix.</p>
<p>If the elementary reduction matrix comes first, then it acts on the rows; if it's second, then it acts on the
	columns.</p>
<h4>Inverses</h4>
<p>A matrix G is a left inverse matrix of the matrix H if GH is the identity matrix. It is a right inverse if HG
	is
	the
	identity. A matrix H with a two-sided inverse is an invertible matrix. That two-sided inverse is denoted
	\(H^{-1}\).
	A matrix is invertible if and only if it is nonsingular. A product of invertible matrices is invertible. A
	matrix H
	is invertible if and only if it can be written as the product of elementary reduction matrices. We can
	compute
	the
	inverse by applying to the identity matrix the same row steps, in the same order, that Gauss-Jordan reduce
	H.
</p>
<img src="{{ url_for('static', filename='img/math/2by2_inverse.png') }}">
<img src="{{ url_for('static', filename='img/math/inverse.png') }}">
<h4>Change of Basis</h4>
<p>The change of basis matrix for bases B, D within V is the presentation of the identity map id: V -> V with
	respect to those bases. A better name would be 'change of representation matrix' but the above name is
	standard. If left-multiplication by a matrix changes the representation of the vecotr from one basis to
	another, then M is the change of basis matrix. A matrix changes bases if and only if it is nonsingular. A
	matrix
	is
	nonsingular if and only if it represents the identity map with respect to some pair of bases.</p>
<h4>Changing Map Representations</h4>
<p>To convert from the matrix H representing a map h with respect to B, D, to the matrix \(\hat{H}\)
	representing it
	wit
	hrespect to \(\hat{B}\), \(\hat{D}\) use this formula.</p>
\[\hat{H}=\text{Rep}_{D,\hat{D}}(\text{id})\cdot H \cdot \text{Rep}_{\hat{B},B}(\text{id})\]
<p>Naturally we usually prefer representations that are easier to understand. We say that a map or matrix has
	been
	diagonalized when we find a basis B such that the representation is diagonal with respect to B, B, that is,
	with
	respect to the same starting basis as ending basis. Same-sized matrices H and \(\hat{H}\) are matrix
	equivalent
	if
	there are nonsingular matrices P and Q such that \(\hat{H}=PHQ\). Matrix equivalent matrices represent the
	same
	map,
	with respect to appropriate pairs of bases. Matrix equivalence is an equivalence relation. If matrices are
	row
	equivalent then they are also matrix equivalent, but the converse is not always true. Any mxn matrix of rank
	k
	is
	matrix equivalent to the mxn matrix that is all zeros except that the first k diagonal entries are ones.
	This is
	a
	block partial-identity form. This is the canonical representative of the matrix equivalence class. Matrix
	equivalence classes are characterized by rank: two same-sized matrices are
	matrix equivalent if and only if they have the same rank.</p>
<h4>Projection</h4>
<p>The orthogonal projection of a vector v onto the line spanned by a nonzero vector s is:</p>
\[\text{proj}_{[\vec{s}]}(\vec{v})=\frac{\vec{v}\cdot \vec{s}}{\vec{s}\cdot \vec{s}}\vec{s}\]
<h4>Gram-Schmidt Orthogonalization</h4>
<p>Vectors are mutually orthogonal when any two are orthogonal. If the vectors in a set are mutually orthogonal
	and
	nonzero than that set is linearly indepdent. If the vectors in a size k subset of a k dimensional space are
	mutually
	orthogonal and nonzero than that set is a basis for the space. The converse does not necessarily hold.
	However,
	we
	can get the partial converse that for every subspace there is at least one basis consisting of mutually
	orthogonal
	vectors. An orthogonal basis for a vector space is a basis of mutually orthogonal vectors.</p>
<img src="{{ url_for('static', filename='img/math/orthogonalization.png') }}">
<p>In addition, we can arrange each vector have length one by dividing each by its own length (normalizing the
	lengths),
	producing an orthonormal basis.
</p>
<h4>Projection onto a subspace</h4>
<p>For any direct sum \(V=M\oplus N\) and any \(\vec{v}\in V\), the projection of \(\vec{v}\) onto \(M\) along
	\(N\)
	is \[\text{proj}_{M,N}(\vec{v})=\vec{m}\] where \(\vec{v}=\vec{m}+\vec{n}\) with \(\vec{m}\in M, \vec{n}\in
	N\).
</p>
<p>The
	orthogonal complement of a subspace \(M\) of \(\mathbb{R}^n\) is \[M^\perp = \{\vec{v}\in
	\mathbb{R}^n|\vec{v}\text{ is perpendicular to all vectors in M}\}\] (read "M perp"). The orthogonal
	projection
	\(\text{proj}_M(\vec{v})\) of a vector is its projection onto \(M\) along \(M^\perp\).</p>
<h4>Direct sum</h4>
<p>The direct sum is an operation in abstract algebra. The direct sum \(\mathbb{R}\oplus\mathbb{R}\) is the
	Cartesian
	plane \(\mathbb{R}^2\).</p>
<h4>Abelian group</h4>
<p>An abelian group, also called a commutative group, is a group in which the result of applying the group
	operation
	of
	two group elements does not depend on the order in which they are written. That is, the group operation is
	commutative.</p>
<h4>Line of Best Fit</h4>
<p>Scientists are often presented with a system that has no solution but they must find an answer anyway. For
	example,
	let's say you flip a coin and try to find the probability of it being heads. You flip the coin 30 times and
	you
	get
	16 heads, 60 times and you get 34 heads, and 90 times and get 51 heads. The solution to this system to find
	the
	probability doesn't work. That is, the vector of data that we collected is not in the subspace where ideally
	it
	would be. However, we can create an orthogonal projection of the data vector into the line subspace that
	gives
	us a
	best guess, the vector in the subspace closest to the data vector. This will give us a line of best fit.
	Minimizing
	the distance between the given vector and the vector used as the right-hand side minimizes the total of
	these
	vertical legnths and so we say that the line comes from fitting by least-squares.</p>
<h4>Geometry of Linear Maps</h4>
<p>You can think of any linear transformation is as a composition of dilations (scaling components by a number),
	reflections (swapping components), skews (scaling a component relative to another component), and
	projections
	(partial identity matrix). A linear transformation is one that maintains even spaces and lines. We can think
	of
	calculus as studying the local effect of a map. For example, representation of the rotation by (2pi/3)
	counterclockwise is shown below:</p>
<img src="{{ url_for('static', filename='img/math/rotation.png') }}" width="60%">
<h4>Markov chains</h4>
<p>Say you have a game where you win a dollar if you get heads on a coin flip and you lose a dollar on tails.
	You
	start
	with $3 and you stop playing if you reach $0 or $5. What is the chance the game takes at least five flips?
	You
	can
	define each dollar amount you can have as a state \(s_0, s_1,...,s_5\). A player in state \(s3\) has a 0.5
	chance to
	go to s2 or s4. Once you hit the boundary (s0 or s5), the state no longer changes (this is called an
	absorbing
	state). If you know what the probability of someone being in a certain state, say s1, after n flips
	(\(p_1(n)\)
	then
	you can say that the probability of the person being at any state is denoted as \(\begin{pmatrix}0.5 && 0 &&
	0.5
	&&
	0 && 0 && 0\end{pmatrix}\). Adjoin all
	these
	vectors together and you get the following:</p>
<img src="{{ url_for('static', filename='img/math/markov1.png') }}">
<p>Now if you assume the player starts with three dollars, you set the probability vector at n=0 to be
	\(\begin{pmatrix}0 && 0 && 0 &&
	1 && 0 && 0\end{pmatrix}\), and you can calculate step by step the probability of reaching any state after a
	certain
	number of steps. Each vector of p (such as the initial one we just listed) is a probability vector and the
	matrix
	shown above is the transition matrix. Markov chain models are notable in that they are historyless such that
	the
	next state depends only on the current state.</p>
<h4>Orthonormal Matrices</h4>
<p>Euclid considered two figures to be thes ame if they have the same size and shape, stating that they are
	congruent by
	imagining that if we picked the plane up, slid it over and rotated it, but didn't warp or stretch it, and
	then
	put
	it back down, we could superimpose the first figure on the second. In modern terminology, picking the plane
	up
	means
	considering a map from the plane to itself. Accordingly, we consider a map to be distance-preserving or a
	rigid
	motion or an isometry if all points remain equidistant from each other. We also define a plane figure to be
	a
	set of
	points in the plane and that two figures are congruent if there is a distance-preserving map from the plane
	to
	itself that carries on eifugre onto the other.</p>
<p>Not all distance-preserving maps are linear (if it shifts it away from the origin). However, a map t that is
	distance-preserving and sends the zero vector to itself is linear. Thus, any distance-preserving
	\(f:\mathbb{R}^2
	\rightarrow \mathbb{R}^2\) can be written \(f(\vec{v})=t(\vec{v})+\vec{v}_0\) for some constant vector
	\(\vec{v}_0\)
	and a linear map \(t\) that is distance-preserving. In addition, not every linear map is distance-preserving
	(for
	example, scaling by 2 does not preserve distance).</p>
<p>Matrices for which when the columns are written as vectors then they are of length one and are mutually
	orthogonal
	are called orthonormal or orthogonal matrices.</p>
<p>A distance-preserving map is direct if it preserves orientations and opposite if it reverses orientation.
	Another
	idea, besides congruence of figures, is that figures are similar if they are congruent after a change of
	scale.
	We
	have that figures are similar if there is an orthonormal matrix \(T\) such that the points \(\vec{q}\) on
	one
	are
	derived from the points \(\vec{p}\) by \(\vec{q}=(kT)\vec{v}+\vec{p}_0\) for some nonzero real number \(k\)
	and
	a
	constant vector \(\vec{p}_0\).</p>
<h4>Determinants</h4>
<p>If a 1x1 matrix has a value that is not 0, then it is nonsingular. A 2x2 matrix is
	nonsingular if \(ad-bc\neq 0\). A 3x3 matrix is nonsingular if \(aei+bfg+cdh+hfa-idb-gec \neq 0\). These
	formulas
	define a determinant function \(\text{det}_{n\times n}:\mathcal{M}_{n\times n} \rightarrow \mathbb{R}\) such
	that
	the
	matrix is nonsingular if and only if the determinant is not 0.</p>
<p>The determinant can be determined by Gauss reduction and multiplying the values on the diagonal (product down
	its
	diagonal). If there is an
	addition of a scalar multiple of a row, the determinant stays the same. If there is a row swap, the
	determinant
	switches signs (switches to negative or back). If there is a scalar multiple of a row, the determinant
	scales
	with
	that scalar. An identity matrix has a determinant of 1. A matrix with two identical rows has a determinant
	of
	zero.
	A matrix with a zero row has a determinant of zero. For each n, if there is an nxn determinant function then
	it
	is
	unique.</p>
<h4>Determinants as Size Functions</h4>
<p>The box formed by two vectors is a box or parallelepiped. The determinant of a transformation matrix is how
	much
	area
	is covered by
	the
	basis vectors (in the parallelepiped) after transforming by that matrix
	relative to the starting area. Scaling one of the vectors leads to a scaling of this area, whereas addition
	of a
	multiple of one vector onto another doesn't change the area. Swapping vectors changes the sign of the
	determinant,
	reflecting the orientation or sense of the box. The volume of a box is the absolute value of the determinant
	of
	a
	matrix with those vectors as columns. The determinant of a product is the product of the determinants
	\(|TS|=|T|\cdot |S|\). If a matrix is invertible then the determinant of its inverse is the inverse of its
	determinant \(|T^{-1}|=1/|T|\).</p>
<img src="{{ url_for('static', filename='img/math/parallel.png') }}">
<img src="{{ url_for('static', filename='img/math/parallel2.png') }}">
<h4>Projective Geometry</h4>
<p>If we look at three random points from a distance and describe it in a painting, we are projecting a
	collection
	of
	three-dimensional points onto a common two dimensional image. This is a central projection from a single
	point
	(from
	our eyes). The operation of central projection preserves some geometric properties, for instance lines
	project
	to
	lines. But it fails to preserve some others, such as equal length segments in 3D space can project to
	segments
	of
	unequal length. The study of these effects is projective geometry.</p>
<p>If we look at parallel lines vanishing into the
	horizon as a painter might paint lines, we call these points vanishing points, where the source has parallel
	lines
	that never intersect but the image does.</p>
<p>The first case of central projection is projection done by a movie projector. We can think of each source
	point
	as
	being pushed from the domain plane S outward to the image plane I. The second case of projection is that of
	the
	artist pulling the source back to a canvas. A third example is if a pinhole shines an image of a solar
	eclipse
	onto
	a paper. In each of these situations, the source (S), point (P), and image (I) are positioned differently.
</p>
<img src="{{ url_for('static', filename='img/math/projector.png') }}">
<img src="{{ url_for('static', filename='img/math/projector2.png') }}">
<img src="{{ url_for('static', filename='img/math/projector3.png') }}">
<p>We can describe each by saying that each is a central projection by P of S to I. If we position P such that
	it is
	parallel to the planes S and I, we can create an environment where we can get all three cases visualized
	similarly.
	In the first image, P acts as a movie projector pushing points out from S to I. In the second image, P acts
	as a
	painter, pulling the image from S onto I. And in the third, P acts as a pinhole, where the source projects
	an
	image
	through P onto I.
</p>
<img src="{{ url_for('static', filename='img/math/projector4.png') }}">
<p>Next, consider another model using a hemispheric dome where the projector P is at the origin and any source
	can
	be
	behind or in front of the
	projector, or behind the image. For any nonzero vector, let the associated point v in the projective plane
	be
	the
	set of nonzero vectors lying on the same line through the origin as the vector v. To describe a projective
	point
	we
	can give any representative member of the line. Each of these is a homogeneous coordinate vector for the
	point
	\(\ell\).
</p>
<img src="{{ url_for('static', filename='img/math/projector5.png') }}">
<p>Finally, reduce this model further by considering a sphere centered at the origin. Any line through the
	origin
	intersects the sphere in two spots, said to be antipodal. In this case, any point in the projective plane
	can be
	drawn as a pair of antipodal spots o nthe sphere. They are not two different points but a pair of spots that
	together make one projective point.</p>
<p>Just as we did with each projective point, we can describe a projective line with a triple of reals. The
	reason
	this
	description as a triple is convenient is that in the projective plane a point v and a line L are incident if
	and
	only if a dot product of their representatives is zero.</p>
<h4>Projective plane</h4>
<p>A projective plane is a geometric structure that extends the concept of aplane. In an ordinary Euclidean
	plane,
	two
	lines intersect in a single point, but there are some pairs of lines (parallel lines) that do not intersect.
	A
	projective plane can be thought of as an ordinary plane equipped with additional "points at infinity" where
	parallel
	lines intersect. A projective plane consists of a set of lines, a set of points, and a relation between
	points
	adn
	lies called incidence having the properties such that 1) given any two distinct points, there is exactly one
	line
	incident with both of them, 2) given any two distinct lines, there is exactly one point incident with both
	of
	them,
	and 3) there are four points such that no line is incident with more than two of them.</p>
<h4>Polynomial Factoring and Complex Numbers</h4>
<p>A polynomial has the form \(p(x)=c_n x^n + ... + c_1x + c0\) with leading coefficient \(c_n \neq 0\). The
	degree
	of
	this polynomial is \(n\). If \(n=0\) then \(p\) is a constant polynomial \(p(x)=c_0\). Constant polynomials
	that
	are
	not the zero polynomial have degree zero. The zero polynomial has the degree \(-\infty\).</p>
<h4>Division Theorem for Polynomials</h4>
<p>Let \(p(x)\) be a polynomial. If \(d(x)\) is a non-zero polynomial then there are quotient and remainder
	polynomials
	\(q(x)\) and \(r(x)\) such that \[p(x)=d(x) \cdot q(x)+r(x)\] where the degree of \(r(x)\) is strictly less
	than
	the
	degree of \(d(x)\).</p>
<p>The remainder when \(p(x)\) is divided by \(x-\lambda\) is the constant polynomial \(r(x)=p(\lambda)\). If
	\(\lambda\) is a root of the polynomia \(p(x)\) then \(x-\lambda\) divides \(p(x)\) evenly, that is,
	\(x-\lambda\)
	is a factor of \(p(x)\).</p>
<p>A repeated root of a polynomial is a number \(\lambda\) such that the polynomial is evenly divisible by
	\((x-\lambda)^n\) for some power larger than one. The largest such power is called the multiplicity of
	\(\lambda\).
</p>
<p>For second degree polynomials we have the quadratic formula. If the discriminant \(b^2-4ac\) is negative then
	the
	polynomial has no real number roots. A polynomial that cannot be factored into two lower-degree polynomials
	with
	real number coefficients is said to be irreducible over the reals.</p>
\[\lambda=\frac{-b\pm\sqrt{b^2-4ac}}{2a}\]
<p>Any constant or linear polynomial is irreducible over the reals. A quadratic polynomial is irreducible over
	the
	reals
	if and only if its discriminant is negative. No cubic or higher-degree polynomial is irredubiel over the
	reals.
	Any
	polynomial with real coefficients factors into a product of linear and irreducible quadratic polynomials
	with
	real
	coefficients. That factorization is unique; any two factorizations have the same factors raised to the same
	powers.
</p>
<h4>Similarity</h4>
<p>We considered matrices to be matrix equivalent if you can convert the matrix to the other with nonsingular
	matrices.
	Now, for similarity, we consider a special case of this, such that the codomain equals the domain, and so
	the
	codomain's basis equals the domain's basis.</p>
<p>The matrices \(T\) and \(S\) are similar if there is a nonsingular \(P\) such that \(T=PSP^{-1}\). The only
	matrix
	similar to the zero matrix is itself. The only matrix similar to the identity matrix is itself. All similar
	matrices
	are matrix equivalent but not all matrix equivalent matrices are similar. We can understand similarity
	classes
	by
	finding a canonical form for representatives, called Jordan form. We can decide if two matrices are similar
	by
	checking whether they reduce to the same representative.</p>
<h4>Diagonizability</h4>
<p>A transformation is diagonalizable if it has a diagonal representation with respect to the same basis for the
	codomain as for the domain. A diagonizable matrix is one that is similar to a diagonal matrix: \(T\) is
	diagonalizable if there is a nonsingular \(P\) such that \(PTP^{-1}\) is diagonal. A transformation \(t\) is
	diagonalizable if and only if there is a basis \(B=\langle\vec{\beta}_1,...,\vec{\beta}_n\rangle\) and
	scalars
	\(\lambda_1,...,\lambda_n\) such that \(t(\vec{\beta}_i)=\lambda_i \vec{\beta}_i\) for each \(i\).</p>
<h4>Eigenvalues and Eigenvectors</h4>
<p>A transformation \(t:V\rightarrow V\) has a scalar eigenvalue \(\lambda\) if there is a nonzero
	eigenvector \(\vec{\zeta} \in V\) such that \(t(\vec{\zeta})=\lambda \cdot \vec{\zeta}\). "Eigen" is
	German for "characteristic of," and can be called characteristic values and vectors. A square matrix \(T\)
	has a scalar eigenvalue \(\lambda\) associated with the nonzero eigenvector \(\vec{\zeta}\) if
	\(T\vec{\zeta}=\lambda \cdot \vec{\zeta}\). Similar matrices have the same eigenvalues but need not have
	the same eigenvectors.</p>
<p>You can think of eigenvectors as those vectors which, if transformed, remain on the same line as it
	originally
	was,
	except scaled by some scalar. These vectors are considered the eigenvectors of that transformation, and the
	scalar
	to which the vector is scaled by that transformation is the eigenvalue. By finding the eigenvectors and
	eigenvalues,
	you can better get to the heart of what a linear transformation actually does.</p>
\[A\vec{v}=\lambda\vec{v}\]
<p>Applying a transformation on an eigenvector is the same as scaling that eigenvector. Scaling a vector by
	\(\lambda\)
	can be rewritten as taking the product of \(\lambda I \vec{v}\) since multiplying by the identity matrix
	scaled
	by
	the scalar does the same thing as scaling the vector.</p>
\[A\vec{v}-\lambda I\vec{v}=0\]
\[(A-\lambda I)\vec{v}=0\]
<p>Now, if \(\vec{v}=0\), then any matrix would work, but we want to find a nonzero eigenvector. So we want to
	find
	a
	matrix \(A-\lambda I\) such that a nonzero vector becomes zero, and that is only possible if this
	transformation
	squishes space into a lower dimension, which is only possible if the determinant is 0. Using this
	\(\text{det}(A-\lambda I)=0\), you can solve for \(\lambda\), thereby giving you the eigenvalue.</p>
<p>Take, for example, you have the transformation \(A=\begin{bmatrix}3 && 1 \\ 0 && 2\end{bmatrix}\). Subtract
	the
	identity matrix scaled by a scalar from this matrix, and set the value of the determinant of your resulting
	matrix
	to 0: \(\text{det}(A-\lambda I)=\text{det}(\begin{bmatrix}3-\lambda && 1 \\ 0 &&
	2-\lambda\end{bmatrix})=(3-\lambda)(2-\lambda)=0\), so \(\lambda=2\text{ or } 3\), so the possible
	eigenvalues
	are 2
	and 3.</p>
<p>To solve for which eigenvectors these eigenvalues correspond to, plug in \(\lambda\) and solve for the
	vectors
	that
	the corresponding transformation sends to zero:</p>
\[\begin{bmatrix}{3-2} && 1 \\ 0 && {2-2}\end{bmatrix}\begin{bmatrix}x \\ y\end{bmatrix}=\begin{bmatrix}0 \\
0\end{bmatrix}\]
\[\begin{pmatrix}x \\ -x \end{pmatrix}\]
\[\begin{bmatrix}{3-3} && 1 \\ 0 && {2-3}\end{bmatrix}\begin{bmatrix}x \\ y\end{bmatrix}=\begin{bmatrix}0 \\
0\end{bmatrix}\]
\[\begin{pmatrix}x \\ 0\end{pmatrix}\]
<p>So the eigenvectors that correspond to eigenvalue of 2 for our matrix is any on the diagonal from top left to
	bottom
	right, and any eigenvectors that correspond to eigenvalue of 3 is on the x-axis.</p>
<p>Not all transformations have eigenvectors (for example rotation around the origin). If you try to find the
	eigenvalues of such a transformation, you will find there are no real answers... the only answers will be
	complex. A
	shear transformation keeps all vectors on the x-axis the same, and so its only eigenvectors are on the
	x-axis
	and
	eigenvalue is 1.</p>
<p>If your basis vectors happen to be eigenvectors, then they are eigenbases. This only occurs when your
	transformation
	is diagonal, which means all entries are 0 except on the diagonal (top left to bottom right). Each column is
	an
	eigenvector with the value on the diagonal as its eigenvalue.</p>
<p>To simplify transformations to more readily work with them, you want to change its representation into that
	of
	eigenbases, so that your transformation can be diagonal. An example of when this might be useful is if you
	are
	taking a matrix to the 100th power.</p>
<p>The characteristic polynomial of a square matrix \(T\) is the determinant \(|T-xI|\) where \(x\) is a
	variable.
	The
	characteristic equation is \(|T-xI|=0\). The characteristic polynomial of a transformation \(t\) is the
	characteristic polynomial of any matrix representation \(\text{Rep}_{B,B}(t)\).</p>
<p>A linear transformation of a nontrivial vector space has at least one eigenvalue.</p>
<p>The eigenspace of a transformation \(t\) associated with the eigenvalue \(\lambda\) is
	\(V_\lambda=\{\vec{\zeta}|t(\vec{\zeta})=\lambda\vec{\zeta}\}\). The eigenspace of a matrix is analogous. An
	eigenspace is a subspace. It is a nontrivial subspace.</p>
<p>Where a characteristic polynomial factors into \((x-\lambda_1)^{m_1}\ldots (x-\lambda_k)^{m_k}\) then the
	eigenvalue
	\(\lambda_i\) has algebraic multiplicity \(m_i\). Its geometric multiplicity is the dimension of the
	associated
	eigenspace \(V_{\lambda_i}\).</p>
<p>For any set of distinct eigenvalues of a map or matrix, a set of associated eigenvectors, one per eigenvalue,
	is
	linearly independent. An \(n\times n\) matrix with \(n\) distinct eigenvalues is diagonalizable.</p>
<a href="https://www.youtube.com/embed/IOaAzKo4Fdg">link to vid</a>
<h4>Nilpotence</h4>
<p>For any transformation \(t:V\rightarrow V\), the range spaces of the powers form a descending chain \[V
	\supseteq
	\mathscr{R}(t) \supseteq \mathscr{R}(t^2) \supseteq \ldots\] and the null spaces form an ascending chain.
	\[\{\vec{0}\}\subseteq \mathscr{N}(t) \subseteq \mathscr{N}(t^2) \subseteq \ldots\]</p>
<p>Further, there is a \(k>0\)
	such that for powers less than \(k\) the subsets are proper: if \(j&lt;k\) then \(\mathscr{R}(t^j)\supset
	\mathscr{R}(t^{j+1})\) and \(\mathscr{N}(t^j) \subset \mathscr{N}^{j+1})\), while if \(j\geq k\) then
	\(\mathscr{R}(t^j)=
	\mathscr{R}(t^{j+1})\) and \(\mathscr{N}(t^j) = \mathscr{N}^{j+1})\).</p>
<p>Let \(t\) be a transformation on an n-dimensional space. The generalized range space (or closure of the range
	space)
	is \(\mathscr{R}_\infty(t)=\mathscr{R}(t^n)\). The generalized null space (or closure of the null space) is
	\(\mathscr{N}_\infty(t)=\mathscr{N}(t^n)\).</p>
<div class="first">Mappings and functions</div><a class="anchor" id="mapping"></a>
<div class="first">Sequences and series</div><a class="anchor" id="sequence"></a>
<h4>Sequences</h4>
<p>A sequence is a function from a subset of the set of integers to a set \(S\). We use the notation \(a_n\) to
	denote
	the image of the integer \(n\) and call this a term of the sequence. For example, \(a_n=n^2\) gives the
	elements
	\(1,4,9,16,26,...\).</p>
<h4>Arithmetic progression</h4>
<p>An arithmetic progression is a sequence of the form \(a, a+d, a+2d, ...,a+nd\) where \(a\) is the intiial
	term
	and \(d\) is common difference, such that both belong to \(\mathcal{R}\). For example, \(s_n=-1+4n\) gives
	the
	members
	\(-1,3,7,11,...\).</p>
<h4>Geometric progression</h4>
<p>A geometric progression is a sequence of the form \(a, ar, ar^2, ...,ar^k\) where \(a\) is the initial term
	and
	\(r\)
	is the common ratio, both of which belong to \(\mathcal{R}\). For example, \(a_n=(\frac{1}{2})^n\) gives the
	members
	\(1, \frac{1}{2},\frac{1}{4},\frac{1}{8},...\).</p>
<h4>Recursively defined sequences</h4>
<p>A sequence can be defined recursively by stating the n-th term in terms of previous elements of the sequence
	and
	the
	initial elements of the sequence. An example is the Fibonacci sequence, where \(a_0=0,a_1=1\) and
	\(a_n=a_{n-1}+a_{n-2}\).</p>
<h4>Summations</h4>
<p>A summation has a variable \(j\) referred to as the index of summation, a lower limit \(m\) and an upper
	limit
	\(n\).
	\[\sum_{j=m}^na_j=a_m+a_{m+1}+...+a_n\].</p>
<p>You can factor a constant out of a sum. \[\sum ca_k=c\sum a_k\]</p>
<p>The sum of a sum is the sum of the sums.\[\sum(a_k+b_k)=\sum a_k \sum b_k\]</p>
<h4>Arithmetic series</h4>
<p>The sum of the terms of the arithmetic progression is called an arithmetic series.</p>
\[S=\sum_{j=1}^n(a+jd)=na+d\sum_{j=1}^nj=na+d\frac{n(n+1)}{2}\]
<p>The crux in the proof is being able to see that:\[\sum_{j=1}^nj=1+2+3+4+...+(n-2)+(n-1)+n\] Combine the first
	and
	last terms, then second and second-to last terms, and you will get the sum to be \(\frac{n}{2}(n+1)\).</p>
<p>If your series does not start from 1, you can just find the series from 1 to m and from 1 to n and then find
	the
	difference.</p>
<h4>Geometric series</h4>
<p>The sum of the terms of a geometric progression is called a geometric series.
	\[S=\sum_{j=0}^n(ar^j)=a\sum_{j=0}^nr^j=a\frac{r^{n+1}-1}{r-1}\]To prove this, multiply the series by r, and
	then
	subtract \(rS-S\).</p>
<h4>Infinite geometric series</h4>
<p>Infinite geometric series can be computed in the closed form for
	\(x&#60;1\).
	\[\sum_{n=0}^\infty x^n =\lim_{k\to\infty}\sum_{n=0}^k x^n
	=\lim_{k\to\infty}\frac{x^{k+1}-1}{x-1}=-\frac{1}{x-1}=\frac{1}{1-x}\]
</p>
<h4>Power series</h4>
<p>A power series is an infinite series in the form, where \(a_n\) represents the coefficient of the terms and
	\(c\)
	is
	a constant: \[\sum_{n=0}^\infty a_n(x-c)^n=a_0+a_1(x-c)+a_2(x-c)^2+...\]They are present in mathematical
	analysis,
	where they arise as Taylor series of infinitely differentiable functions, combinatorics as generating
	functions,
	and
	in electronic engineering under the name of Z-transform.</p>
<h4>Taylor series</h4>
<p>The Taylor series of a function is an infinite sum of terms that are expressed in terms of the function's
	derivatives
	at a single point. For most common functions, the function and the sum of its Taylor series are equal near
	this
	point.</p>
<p>\[\sum_{n=0}^\infty \frac{f^{(n)}(a)}{n!}(x-a)^n\]where \(f^{(n)}(a)\) denotes the nth derivative of f
	evaluated
	at
	the point a. When \(a=0\), the series is also called a Maclaurin series.</p>
<div class="first">Differential calculus</div><a class="anchor" id="differential"></a>
<h4>Limits</h4>
<p>Sometimes we can't work something out directly, but we can see what it should be as we get closer and closer.
	For
	example, \(\frac{x^2-1}{x-1}\) cannot be evaluated at \(x=1\). However, if we plug in 0.99999, we'll find
	that
	it
	gives us 1.99999, and so we say that the limit of the term as x approaches 1 is 2.</p>
\[\lim_{x \to 1}\frac{x^2-1}{x-1}=2\]
<h4>Infinity</h4>
<p>Infinity is impossible to reach but we can work out the value of functions that have infinity in them. We
	can't
	say
	\(\frac{1}{\infty}\) is 0, but we can say that the limit of \(\frac{1}{x}\) as x approaches infinity is 0.
</p>
<h3>Derivatives</h3>
<h4>Definition of the derivative</h4>
<p>The derivative of \(f(x)\) with respect to x is the function \(f'(x)\) and is defined as:</p>
$$f'(x)=\lim_{h \to 0} \frac{f(x+h)-f(x)}{h}$$
<p>h is the change in x. The top part of the fraction is the change in y, while the bottom of the fraction is
	the
	change
	in x. So the equation is just the slope. The slope of what? The slope in f(x) as the h, or change in x,
	approaches
	0. Therefore, it is the instantaneous slope at point x.</p>
<p>If the limit is different from the left vs the right, then the ordinary limit does not exist. However, there
	can
	be a
	left-hand limit and a right-hand limit.</p>
<p>Given \(y=f(x)\):</p>
$$f'(x)=y'=\frac{df}{dx}=\frac{dy}{dx}$$
<h4>Properties of the derivative</h4>
<p>The derivative of the sum of two functions is the sum of the individual derivatives of the separate
	functions.
</p>
$$(f(x)+g(x))'=f'(x)+g'(x)$$
<p>You can factor a multiplicative constant out of a derivative.</p>
$$(cf(x))'=cf'(x)$$
<p>The derivative of a constant is 0.</p>
$$\frac{d}{dx}(c)=0$$
<p>The power rule: if x has an numerical exponent, its derivative brings it down to the left and the new
	exponent is
	1
	less: if \(f(x)=x^n\) then \(f'(x)=nx^{n-1}\).</p>
<p>Product rule: if two functions are differentiable, then:</p>
$$(fg)'=f'g+fg'$$
<p>Quotient rule: if two functions are differentiable, then:</p>
$$(\frac{f}{g})'=\frac{f'g-fg'}{g^2}$$
<p>The six trig derivatives:</p>
$$\frac{d}{dx}(\sin(x))=\cos(x)$$
$$\frac{d}{dx}(\cos(x))=-\sin(x)$$
$$\frac{d}{dx}(\tan(x))=\sec^2(x)$$
$$\frac{d}{dx}(\cot(x))=-\csc^2(x)$$
$$\frac{d}{dx}(\sec(x))=\sec(x)\tan(x)$$
$$\frac{d}{dx}(\csc(x))=-\csc(x)\cot(x)$$
<p>The derivatives of exponential and logarithmic functions are as follows:</p>
$$\frac{d}{dx}(e^x)=e^x$$
$$\frac{d}{dx}(a^x)=a^x\ln{a}$$
$$\frac{d}{dx}(\ln{x})=\frac{1}{x}$$
$$\frac{d}{dx}(\log_a{x})=\frac{1}{x\ln{a}}$$
<p>The derivatives of the inverse trig functions:</p>
$$\frac{d}{dx}(\sin^{-1}(x))=\frac{1}{\sqrt{1-x^2}}$$
$$\frac{d}{dx}(\cos^{-1}(x))=-\frac{1}{\sqrt{1-x^2}}$$
$$\frac{d}{dx}(\tan^{-1}(x))=\frac{1}{1+x^2}$$
$$\frac{d}{dx}(\cot^{-1}(x))=-\frac{1}{1+x^2}$$
$$\frac{d}{dx}(\sec^{-1}(x))=\frac{1}{|x|\sqrt{1-x^2}}$$
$$\frac{d}{dx}(\csc^{-1}(x))=-\frac{1}{|x|\sqrt{1-x^2}}$$
<p>The analog to the trig functions are the hyperbolic functions:</p>
$$\sinh{x}=\frac{e^x-e^{-x}}{2}$$
$$\cosh{x}=\frac{e^x+e^{-x}}{2}$$
<p>The derivatives to the hyperbolic functions are as follows:</p>
$$\frac{d}{dx}(\sinh{x})=\cosh{x}$$
$$\frac{d}{dx}(\cosh{x})=\sinh{x}$$
$$\frac{d}{dx}(\tanh{x})=\operatorname{sech}^2{x}$$
$$\frac{d}{dx}(\coth{x})=-\operatorname{csch}^2{x}$$
$$\frac{d}{dx}(\operatorname{sech}x)=-\operatorname{sech}{x}\tanh{x}$$
$$\frac{d}{dx}(\operatorname{csch}{x})=-\operatorname{csch}{x}\coth{x}$$
<h4>Chain rule</h4>
<p>If we have two functions and they are both differentiable, then the derivative of the composite of the two
	\((f\circ
	g)(x)\):</p>
$$f'(g(x))g'(x)$$
<p>Similarly, if we have \(y=f(u)\) and \(u=g(x)\), then the derivative of y is:</p>
$$\frac{dy}{dx}=\frac{dy}{du}\frac{du}{dx}$$
<p>So, for example, if you have the function \(R(z)=\sqrt{5z-8}\):</p>
$$f(z)=\sqrt{z}$$
$$g(z)=5z-8$$
$$R'(z)=f'(g(z))g'(z)$$
$$=f'(5z-8)g'(z)$$
$$=(5)*(1/2)(5z-8)^{-1/2}$$
<h4>Implicit differentiation</h4>
<p>So what if you want to find the derivative of a function that is not in the form \(y=f(x)\)?</p>
$$xy=xy(x)=1$$
$$\frac{d}{dx}(xy(x))=\frac{d}{dx}(1)$$
<p>Use the product rule:</p>
$$(1)y(x)+x\frac{d}{dx}(y(x))=0$$
$$y+xy'=0$$
<p>(Note that the y(x) were converted to y... they are the same. This is not multiplication but just a reminder
	that
	y
	is function of x.)</p>
$$y'=-y/x$$
<p>Go back to the start and recognize we can solve for y.</p>
$$y=1/x$$
$$y'=-1/x^2$$
<h4>Differentials</h4>
<p>Given a function \(y=f(x)\) we call \(dy\) and \(dx\) differentials, and the relationship between them is
	given
	by
	\(dy=df=f'(x)dx\).</p>
<h4>Differential equations</h4>
<p>A differential equation is an equation with a function and one or more of its derivatives. Ordinary
	Differential
	Equations (ODEs) have a single independent variable, whereas partial differential equations (PDEs) have two
	or
	more
	indepedent variables. The Order is the highest derivative. The degree is the exponent of the highest
	derivative.
	When the variable has no exponent or other function put on it, it is linear.</p>
<div class="first">Integral calculus</div><a class="anchor" id="integral"></a>

<h4>Indefinite Integrals</h4>
<p>Now that we've gone through derivatives, let's now do it backwards. The question is... what function did
	we
	differentiate to get \(f(x)\)?</p>
<p>Let's say our function is \(f(x)=x^4+3x-9\).</p>
<p>If you think about how a derivative works, in order to get \(x^4\), we need to take the derivative of
	\(x^5\).
	But if we take the derivative of that, we will get \(5x^4\). So the antiderivative of \(x^4\) should
	actually be
	\(\frac{1}{5}x^5\).</p>
<p>So if you extend this for the rest of the terms, the antiderivative is \((1/5)x^5+(3/2)x^2-9x\). And then
	you
	think we would be done. But remember that the derivative of any constant is 0, so we still need to add
	on
	the
	antiderivative of 0 (a constant c), making our final antiderivative:</p>
$$(1/5)x^5+(3/2)x^2-9x+c$$
<p>If \(F(x)\) is any anti-derivative of \(f(x)\) then the most general anti-derivative of \(f(x)\) is
	called an
	indefinite integral and is denoted:</p>
$$\int{f(x)dx}=F(x)+c$$
<p>Now you might wonder about this dx (the differential) added after the function. You can think of dx as
	the
	end of
	the integral, where the integral (S-like) symbol is the left parentheses and the dx is the right
	parentheses.
</p>
<p>The dx also defines what variable we are integrating with respect to. For example, \(\int{2tdx}=2tx+c\),
	NOT
	\(x^2+c\).</p>
<h4>Properties of the Indefinite Integral</h4>
<p>We can factor multiplicative constants out of indefinite integrals, just like in derivatives.</p>
<p>The integral of a sum of two functions is the sum of their individual integrals (just like derivatives).
</p>
<h4>Computing Indefinite Integrals</h4>
<p>Let's start wit the integral of a power of x, which we've kind of worked through already.</p>
$$\int{x^ndx}=\frac{x^{n+1}}{n+1}+c, n\neq-1$$
<p>Then there's a simple one, which is just a constant, but seems to be trip people up pretty frequently.
</p>
$$\int{kdx}=kx+c$$
<p>Then we can take a look at trig functions.</p>
$$\int{\sin{x}dx}=-\cos{x}+c$$
$$\int{\cos{x}dx}=\sin{x}+c$$
$$\int{\sec^2{x}dx}=\tan{x}+c$$
$$\int{\sec{x}\tan{x}dx}=\sec{x}+c$$
$$\int{\csc^2{x}dx}=-\cot{x}+c$$
$$\int{\csc{x}\cot{x}dx}=-\csc{x}+c$$
<p>Now let's go through exponential and logarithmic functions.</p>
$$\int{e^xdx}=e^x+c$$
$$\int{a^xdx}=\frac{a^x}{\ln{a}}+c$$
$$\int{\frac{1}{x}dx}=\ln{|x|}+c$$
<h4>Substitution Rule for Indefinite Integrals</h4>
$$\int{f(g(x))g'(x)dx}=\int{f(u)du}, \text{where } u=g(x)$$
<h4>Definition of the Definite Integral</h4>
<p>Given a function \(f(x)\) that is continuous on the interval \([a,b]\), we divide the interval into \(n\)
	subintervals of equal width \(\Delta{x}\), and from each interval choose a point, \(x_i^*\). Then the
	definite
	integral of \(f(x)\) from \(a\) to \(b\) is:</p>
$$\int_a^b{f(x)dx}=\lim_{n\to\infty}\sum_{i=1}^n{f(x_i^*)\Delta{x}}$$
<p>Imagine you graph a function and you want to find the area under the curve from x=a to x=b. "a" is called
	the
	lower limit and "b" is the upper limit and from a to b is the interval of integration. How would you
	find
	that
	area? What you could do is take an approximate area by getting the height at each point of the curve,
	and
	then
	multiplying the height by some width, to get a rectangle, and add all of those rectangles together. To
	get a
	more and more accurate approximation, you can keep making these rectangles smaller and smaller until you
	have an
	infinite number of infinitely narrow rectangles. This is what the definition of the definite integral
	does.
</p>
<h4>Properties of the Definite Integral</h4>
<ol>
	<li>You can switch the limits on the integral as long as you add on a minus sign.</li>
	<li>If the limits are the same, the integral is zero.</li>
	<li>You can factor out any constant.</li>
	<li>You can break up sums of integrals.</li>
	<li>You can add up break up an integral into parts.</li>
	$$\int_a^b{f(x)dx}=\int_a^c{f(x)dx}+\int_c^b{f(x)dx}$$
	<li>As long as the function and limits are the same, the actual variable of integration doesn't really
		matter.
	</li>
</ol>
<h4>Net Change Theorem</h4>
<p>We have already discussed one interpretation of the integral: the area under the curve of a function.
	Another
	interpretation is the net change in the quantity of the function. For example, imagine your x axis is
	time
	and
	your y axis is speed (distance over time). Then the integral gives you the total distance travelled over
	that
	period of time. Another example is inductors in circuits. The voltage is dependent on the inductance and
	change
	in current. So if you integrate the change in current over time, you get the total current. Which means,
	since
	the voltage depends on the change in current, you can also get the total current from integrating the
	voltage.
	On the other hand, for a capacitor, the voltage builds up on the parallel plates due to injection of
	charge,
	which would be the total current sent to the capacitor. So you can find the voltage as an integration of
	the
	current over time.</p>
<h4>Fundamental Theorem of Calculus, Part 1</h4>
<p>If \(f(x)\) is continuous on \([a,b]\), then \(g(x)=\int_a^x{f(t)dt}\) is continuous on \([a,b]\) and it
	is
	differentiable on \((a,b)\) and that \(g'(x)=f(x)\).</p>
<p>In essence, the fundamental theorem of calculus connects derivatives and integrals. Let's say you want to
	look at
	some property... let's say distance, denoted by "y". This could be volume, energy... whatever. Let's say
	I
	get
	in a car and I start driving forward. I know I need to travel 100 miles north and dig at a location to
	find
	a
	treasure chest, but I don't have a GPS to tell me exactly where I am. All I have in the car is the meter
	which
	tells me how fast I'm moving. This meter is essentially telling me the derivative of distance with
	respect
	to
	time, or dy/dt. In order to find the distance where I am at any point, I need to integrate this
	derivative,
	aka
	my speed, from my starting timepoint "a" (in this case 0) to whatever time "x", and that will give me
	the
	total
	distance y I have traveled from time a to x.</p>
<p>Let's look at an example.</p>
$$\frac{d}{dx}\int_{x^2}^1{\frac{t^4+1}{t^2+1}dt}$$
<p>Let's start from what we know. Say that we know the speed of our car is equal to
	\(f(t)=\frac{t^4+1}{t^2+1}\).
	When we integrate from \(x^2\) to 1, we're saying, from timepoint \(x^2\) all the way to timepoint 1,
	what
	is
	the total distance I have traveled? Then, with the differentiation, we're asking, how fast is our total
	distance
	changing as a function of x?</p>
<p>So the first thing we can do is simplify things a bit. Instead of thinking about things backwards, going
	from
	\(x^2\) to 1, let's just swap the limits around, and ask, if we start at 1 second, and go to x^2
	seconds,
	how
	far have I traveled? So we add a negative sign to the integral.</p>
$$-\frac{d}{dx}\int_1^{x^2}{\frac{t^4+1}{t^2+1}dt}$$
<p>Next, this pesky x^2 is pretty annoying. How can we change this to just x? We can use the chain rule of
	differentiation, which basically means we'll replace x^2 with x, and then multiply the derivative of x^2
	in
	afterwards. As a reminder, the chain rule is as follows:</p>
$$\frac{d}{dx}(g(u))=\frac{d}{du}(g(u))\frac{du}{dx}\;\text{where }u=f(x)$$
<p>Again, the chain rule simply means... if you have a function inside another function, you can derive the
	outside
	function and then multiply it by the derivative of the inside function. So for our question, if we set
	\(u=x^2\)...</p>
$$-\frac{d}{du}\int_1^{u}{\frac{t^4+1}{t^2+1}dt}\frac{du}{dt}$$
<p>Now, we can use the Fundamental Theorem of Calculus, and derive the integral.</p>
$$-\frac{u^4+1}{u^2+1}(2x)$$
$$-2x\frac{x^8+1}{x^4+1}$$
<p>So what really have we done here? What we've done is pretty simple. We found the speed at which we're
	traveling
	at a specific timepoint. But you might ask, didn't we already know the speed at any timepoint? Yes, we
	did,
	which is why this problem doesn't make for a great application example. But imagine that you want to
	know
	what
	speed you're traveling in seconds, but your clock runs in units of seconds^2. We had to convert those
	units
	into
	seconds first. And that's kind of what we've done. (Unfinished, will need to think about more.)</p>
<div class="first">Functions of several variables</div><a class="anchor" id="function"></a>
<div class="first">Functional equations</div><a class="anchor" id="functional"></a>
<div class="first">Complex analysis</div><a class="anchor" id="complex"></a>
<div class="first">Combinatorics</div><a class="anchor" id="combinatorics"></a>
<p>The sum rule states that if a task \(t_1\) can be done in \(n_1\) ways and a second task \(t_2\) can be done
	in
	\(n_2\) ways, and if these tasks cannot be done at the same time, then there are \(n_1 + n_2\) ways to do
	either
	task.</p>
<p>This corresponds to the statement that if \(A\) and \(B\) are disjoint sets, then \(|A \cup B|=|A|+|B|\), and
	this
	extends to multiple sets.</p>
<p>The product rule states that if a task \(t_1\) can be done in \(n_1\) ways and a second task \(t_2\) can be
	done
	in
	\(n_2\) ways after the first task has been done, then there are \(n_1 * n_2\) ways to do the procedure.</p>
<p>This corresponds to the statement if \(A\) and \(B\) are disjoint sets, then \(|A \times B|=|A| * |B|\),
	extending to
	multiple sets.</p>
<p>The principle of inclusion-exclusion states that if a task \(t_1\) can be done in \(n_1\) ways and a second
	task
	\(t_2\) can be done in \(n_2\) ways at the same time with t\(1\), then to find the total number of ways the
	two
	tasks can be done, subtract the number of ways to do both tasks from \(n_1+n_2\).</p>
<p>This corresponds to the inclusion/exclusion rule of sets. (link there)</p>
<p>Recursion is the general practice of defining an object in terms of itself. A recursive function is a
	function
	that
	calls itself. For example, \(f(n)=3 * f(n-1)\) is a recursive function. An algorithm is recursive if it
	solves a
	problem by reducing it to an instance of the same problem with a smaller input.</p>
<h4>Permutations and combinations</h4>
<a href="https://www.youtube.com/embed/ohsRp6kZ6-0">link to vid</a>
<p>Permutations and combinations, as taught in middle/high school, are about figuring out how many ways you
	can
	select items from a set. I think this is often a confusing thing to learn because it's taught
	disjointedly
	from
	other subjects, and involves fairly fundamental aspects of math that are not taught in elementary math,
	and
	requires a different way of thinking. It's not really algebra, but is about combinators, or counting. So
	fundamentally we have to go back away from the fancy symbols we have been using, and just focus on
	counting
	things. In addition, it applies some stuff from probability with independent/dependent events. However,
	it
	has
	very obvious application which makes it interesting to teach. For example, if you technically enter all
	permutations of characters into a password field, you should be able to hack every online account ever
	created.
	However, with a quick understanding of permutations, you realize that is not likely.</p>
<p>The first thing we can talk about is permutations with repetitions. How many ways can you order a set of
	numbers?
	If your set of numbers is {a, b, c}, then you can arrange them {a, a, a}, {b, b, b}, {c, c, c}, {a, a,
	b}...
	and
	so forth. I think about it this way. If you look at the first "slot", how many options do you have
	there?
	You
	have 3... a, b, or c. Now, if you pick a, then think about how many options you have for the second
	slot,
	you
	have 3 again... a, b, or c. So then for every option for the 1st slot, we have 3 options for the second
	slot. So
	in total, we have 3*3=9 options for the first two slots. Then, for each option in the first two slots,
	we
	have 3
	options for the 3rd slot, so then we have 3*3*3=27 total possibilities. This is the equation for
	permutations
	with repetitions: \(n^r\). n here is the total size of the original set we are picking from {a, b, c}.
	If
	our
	initial set was all the letters of the alphabet, n here would be 26. If our initial set was a deck of
	playing
	cards without jokers, it would be 52. r here is how many we are putting in order. So if we said, how
	many
	ways
	can you arrange 2 numbers from {a, b, c, d}, then it would be \(n^r=4^2=16\).</p>
<p>So then let's look at permutations without repetitions. This time, if we pick "a" for our first option,
	we
	can't
	pick it again for our second slot. In the case of choosing 3 out of {a, b, c}, you can arrange them {a,
	b,
	c},
	{a, c, b}, {b, a, c}, {b, c, a}, {c, a, b}, {c, b, a}. This is kind of the more natural answer to the
	question,
	how many ways can you arrange a bunch of items? In total, there are 6 possible ways to arrange these
	numbers. So
	let's think about this in terms of slots again. In the first slot, we can choose any option. Then, in
	the
	second
	slot, you have one fewer option, so you now have n-1 options. Then in the third slot, you have n-2
	options
	because you have taken 2 out already, and so forth... So as we go on, we realize the answer to how many
	options
	is \(n*(n-1)*(n-2)*...\). This is also termed \(n!\), or n-factorial. But that's not our answer quite
	yet.
	Let's
	say we only want to arrange 2 items from a set of 4. In this case, we are just doing 4 * (4-1). We don't
	care
	about the (4-2) and (4-3) because we're stopping after 2. What we notice here is (4-2) and (4-3) can be
	written
	as \(2*1 = 2!\). So we take n, subtract r, and that gives us the factorial that we need to remove
	because we
	don't care about them. So our ending equation for permutations without repetitions is \(n!/(n-r)!\). This is
	also
	known as nPr (n permute r).</p>
<p>Now we will discuss combinations without repetition. The difference between combination and permutation
	is
	that
	for combinations, we don't care about the order. So whereas before with permutations, {a, b, c} was
	different
	from {c, b, a}, we now consider these to just be one option. So from our list of permutations without
	repetition, all we need to do is remove the ones which are simply permutations of each unique
	combination.
	Good
	news, though, is that we just did that! The number of ways we can arrange r numbers is just \(r!\). So
	the
	equation for combinations without repetitions is just the equation for permutations without repetitions
	divided
	by \(r!\), aka \(\frac{n!}{r!(n-r)!}\). This is also called a binomial coefficient \(\binom{n}{r}\) or nCr
	(n
	choose
	r). Note that this can also be described as finding how many subsets of size r you can get from a set of n
	elements.
</p>
<p>Finally, we get to combinations with repetitions. In this case, we don't care about the order, but we can
	repeat
	getting one number more than once. Imagine this: you are at an ice cream parlor, and there are 4
	different
	ice
	cream flavors you can choose from... {a, b, c, d}, and you get 3 scoops total for your ice cream cone.
	Now
	imagine there is a robot behind ice cream "a", and your job is to tell him whether to scoop up ice cream
	or
	move
	over to the right to the next ice cream flavor. We will imagine "O" means scoop up ice cream, and ">"
	means
	to
	move over to the right. How would we scoop up 3 scoops of "a"? It would just be OOO>>>. The robot would
	take
	3
	scoops of "a", and then move over all the way to the right. What if we wanted one scoop of "a" and 2
	scoops
	of
	"d"? Then it would be O>>>OO. What you'll realize is that for each set of instructions, we will get a
	different
	combinations (with repetitions) of ice cream flavors. If OOO>>> means three scoops of "a", there is no
	other
	set
	of instructions we can give that will also give us three scoops of "a". Therefore, all we need to do to
	find
	the
	combinations with repetitions is to find how many ways we can position the "O"s throughout our
	instructions
	OOO>>>. But wait! We already know how to do that! There are 6 positions total. And we need to pick 3 of
	those
	positions. The order doesn't matter, because they're all "O," but we can't repeat a single position more
	than
	once. So this is just combinations without repetitions, and we have that equation above...
	\(\frac{6!}{3!(6-3)!}\), and that will be our answer. Now, the number of positions we have in total will
	always
	be \(n+r-1\), because we are taking r scoops and moving n-1 times to get to the end. And r stays the
	same.
	So
	our end equation for combinations with repetitions is
	\(\frac{(n+r-1)!}{r!(n+r-1-r)!}=\frac{(n+r-1)!}{r!(n-1)!}\).</p>
<p>So you can see here that working with combinatorics takes a bit more out of the box thinking, and
	requires a
	lot
	of visualization and imagining multiple iterations of similar things, which makes it inherently
	difficult.
	But
	also makes it super interesting!</p>
<div class="first">Graph theory</div><a class="anchor" id="graph"></a>
<p>A graph \(G=(V,E)\) where \(V\) is the set of vertices (nodes) and \(E\) is the set of edges, also referred
	to as
	arcs or links. \(F\) is a function that maps the set of edges \(E\) to a set of ordered or unordered pairs
	of
	elements \(V\). A simple graph consists of a set of vertices or nodes and a set of edges connecting
	unordered
	pairs.
	The edges in simple graphs are undirected. Such graphs are referred to as undirected graphs. In a
	multigraph,
	more
	than one edge may connect the same two vertices, reflecting multiple associations between the same two
	vertices.
	Such edges are called parallel or multiple edges. In a pseudograph, edges connecting a node to itself are
	allowed.
	Such edges are called loops. A directed graph contain a set of edges that are ordered pairs of vertices. In
	a
	weighted graph, each edge has a weight associated with it, typically representing the numeric value
	associated
	with
	the relationship between the corresponding two vertices.</p>
<p>Let \(G=(V,E)\) be an undirected graph with edge set \(E\). Then, for an edge \(e \in E\) where
	\(e=\{u,v\}\),
	the
	following terminologies are often used: \(u,v\) are said to be adjacent or neighbors or connected. Edge
	\(e\) is
	incident with vertices \(u,v\). Edge \(e\) connects \(u,v\). Vertices \(u,v\) are endpoints for edge \(e\).
</p>
<p>If vertev \(v \in V\), the set of vertices in the undirected graph \(G(V,E)\), then the degree of \(v\),
	\(\text{deg}(v)\) is its number of incident edges, except that any self-loops are counted twice. A vertex
	with
	degree 0 is called an isolated vertex, and a vertex of degree 1 is called a pendant vertex.</p>
<p>If the graph is directed, then the following terminologies are often used: \(u\) is adjacent to \(v\), and
	\(v\)
	is
	adjacent from \(u\). \(e\) comes from \(u\) and goes to \(v\). \(e\) connects \(u\) to \(v\), or \(e\) goes
	from
	\(u\) to \(v\). The initial vertex of \(e\) is \(u\). The terminal vertex of \(e\) is \(v\).</p>
<p>If vertex \(v\) is in the set of vertices for the directed graph, then in-degree of \(v\),
	\(\text{deg}^{-}(v)\)
	is
	the number of edges going to \(v\). Out-degree of \(v\) or \(\text{deg}^{+}(v)\) is the number of edges
	coming
	from
	\(v\). The degree of \(v\) is the sum of in-degree and out-degree. A loop at a vertex contributes 1 to both
	in-degree and out-degree of this vertex.</p>
<p>Note that the degree of a node is unchanged whether we consider its edges to be directed or undirected.</p>
<p>In an undirected graph, a path of length \(n\) from \(u\) to \(v\) is a sequence of \(n\) adjacent edges from
	vertex
	\(u\) to vertex \(v\). A path is a circuit if \(u=v\). A path traverses the vertices along it. A path is
	simple
	if
	it contains no edge more than once.</p>
<p>A cycle on \(n\) vertices \(C_n\) for any \(n \geq 3\) is a simple graph where \(V=\{v_1,v_2,...,v_n\}\) and
	\(E=\{\{v_1,v_2\},\{v_2,v_3\},...,\{v_{n-1},v_n\},\{v_n,v_1\}\}\).</p>
<p>An adjacency list is a table with one row per vertex, listing its adjacent vertices. The adjacency listing
	for a
	directed graph maintains a listing of the terminal nodes for each of the vertices in the graph.</p>
<h4>Trees</h4>
<p>A tree \(T(N,E)\) is a hierarchical data structure of \(n=|N|\) nodes with a specially designed root node
	\(R\)
	while
	the remaining \(n-1\) nodes form subtrees under the root node \(R\). The number of edges \(|E|\) in a tree
	would
	always be equal to \(|N|-1\).</p>
<p>The subtree at node \(X\) is the subgraph of the tree consisting of node \(X\) and its descendants and all
	edges
	incident to those descendants. A tree may also be defined as a connected undirected graph with no simple
	circuits.
</p>
<p>A tree is strictly hierarchical in nature as compared to a graph, which is flat. An ordered pair is built
	into
	trees
	between two nodes as parent and child. An undirected graph is a tree if and only if there is a unique simple
	path
	between any two of its vertices.</p>
<p>The parent of a nonroot node \(v\) is the unique node \(u\) with a directed edge from \(u\) to \(v\). Each
	node
	in
	the tree has a unique parent node except the root of the tree.</p>
<p>A node that has children is called an internal node. The degree of a node in a tree is the same as its number
	of
	children. THe distance of a node from the root node in terms of number of hops is called its level. The root
	node is
	level 0. Alternately, the level of a node \(X\) is the length of the unique path form the root of the tree
	to
	node
	\(X\). The height of a tree is the maximum of the levels of nodes in the tree. A node is called a leaf if it
	has
	no
	children. The degree of a leaf node is 0. The ancestors or predecessors of a nonroot node \(X\) are all the
	nodes in
	the path from root to node \(X\). The successors or descendents of a node \(X\) are all the nodes that have
	\(X\) as
	its ancestor. Two or more nodes sharing the same parent node are called sibling nodes.</p>
<p>A tree is called an ordered tree if the relative position of occurrences of children nodes is significant.
	For
	example, a family tree is an ordered tree if, as a rule, the name of an elder sibling appears always before
	(on
	the
	left of) the younger sibling.</p>
<p>A binary tree is formed with zero or more nodes where there is a root node \(R\) and all the remaining nodes
	form
	a
	pair of ordered subtrees under the root node. In a binary tree, no internal node can have more than two
	children. A
	binary tree is always ordered. If you swap the positions of left and right subtrees, then a new tree is
	derived.
	A
	binary tree is called full if every internal node has exactly two children. A full binary tree is also
	referred
	to
	as a strictly binary tree. A complete binary tree has all its levels, except possibly the last one, filled
	up to
	capacity, and in case the last level of a complete binary tree is not full, nodes occur from the leftmost
	positions
	available.</p>
<img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ8Jx_JxUYGTAhVvtyc_JASJANKzXRXkNNQrQ&usqp=CAU"
	alt="complete binary tree">
<p>A binary tree of height \(H\) is balanced if all its leaf nodes occur at levels \(H\) or \(H-1\). There are
	at
	most
	\(2^H\) leaves in a binary tree of height \(H\). In other words, if a binary tree with \(L\) leaves is full
	and
	balanced, then its height is \(H=\log_2 L\).</p>
<p>A binary search tree (BST) is a special kind of binary tree in which each node contains a distinct key value,
	and
	the
	key value of each node in the tree is less than every key value in its right subtree and greater than every
	key
	value in its left subtree. A traversal algorithm is a procedure for systematically visiting every node of a
	binary
	tree. Tree traversals may be defined recursively.</p>
<p>If \(T\) is a binary tree with root \(R\) and the remaining nodes form an ordered pair of nonnull left
	subtree
	\(T_L\) and nonnull right subtree \(T_R\) below \(R\), then the traversal functions
	are:\[\text{PreOrder}(T)=R,\text{PreOrder}(T_L),\text{PreOrder}(T_R)\]\[\text{InOrder}(T)=\text{InOrder}(T_L),R,\text{InOrder}(T_R)\]\[\text{PostOrder}(T)=\text{PostOrder}(T_L),\text{PostOrder}(T_R),R\]
</p>
<div class="first">Descriptive statistics</div><a class="anchor" id="descriptive"></a>
<h4>Student's t-test</h4>
<p>William Sealy Gosset was working at Guiness brewery and developed a test to determine the difference for
	things,
	say, barley growth. He wanted to publish the test but the company was nervous that he would reveal
	secrets,
	so
	he published under the pseudonym "Student."</p>
<p>Imagine you have two fields of barley. If you sample one field, you can get the height of each piece of
	barley
	and you can make a distribution of the heights. Do the same for the other. We could compare the means of
	the
	two
	distributions, but that only tells us so much. The means could be super far apart, but the variability
	of
	each
	sample could be so big that there isn't actually a real difference between the two fields. So we create
	the
	t-value, which is a ratio of signal to noise.</p>
$$\frac{\text{signal}}{\text{noise}}=\frac{\text{difference between group means}}{\text{variability of
groups}}=\frac{|\overline{x_1}-\overline{x_2}|}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}$$
<p>Once you get the t-value, you can use a t-table to find the value of t that gives you p=0.05 (inferential
	statistic) for the specific degree of freedom \(df=n_1+n_2-2\).</p>
<p>The aforementioned example is an independent (unpaired) t-test. But you can also do a paired t-test if,
	for
	example, you're sampling the same population twice, so that each datapoint has a corresponding datapoint
	in
	the
	other sample. A two-tailed t-test splits the 0.05 into both tails making each side 0.025.</p>
<p>Assumptions require normal distribution, similar variance in the two samples, and there should be the
	same
	number
	of datapoints in each sample, and there should be 20-30 samples.</p>
<h4>ANOVA</h4>
<p>ANOVA can be used for measurements of more than two groups. The general linear model framework is \(data
	=
	model
	+ error\). ANOVA means ANalysis Of Variance. Sums of squares total (SST) is the number of datapoints
	times
	the
	variance. \(Variance = \frac{SST}{N}\)</p>
<div class="first">Probability theory</div><a class="anchor" id="probability"></a>

<h4>Probability and odds</h4>
<p>Probability is the mathemtaical description of randomness. The probability is the number of ways to reach a
	certain
	outcome \(O\) out of all possibilities. The
	probability
	is
	\(0\leq
	p \leq 1\).</p>
<p>Negation rule states that if the probability of O is p, then the probability of not O is \(1-p\).</p>
<p>Multiplication rule states that if \(O_1,O_2\) are independent outcomes (knowing one doesn't influence the
	other),
	then \(P(O_1 \text{ and }O_2)=P(O_1)\times P(O_2)\).</p>
<p>Addition rule states that if the outcome O can occur in two or
	more distinct possible ways, then the probability of O is the sum of the individual probabilities.</p>
<p>For example, if you roll a die five times, what is the probability you land exactly two 3s? A couple ways to
	think
	about this. You can rewrite the question as, what is the chance I get 3s on the 1st and 4th roll? Then it's
	\((\frac{1}{6})(\frac{5}{6})^2(\frac{1}{6})(\frac{5}{6})=(\frac{1}{6})^2(\frac{5}{6})^3\). Then, you have to
	repeat
	this for, what is the chance I get 3s on the 1st and 2nd roll, 2nd and 3rd roll, 2nd and 4th roll and so
	forth...
	All the ways I can choose 2 to get (3s) from 5 rolls is \(5\choose 2\). So the answer is
	\((\frac{1}{6})^2(\frac{5}{6})^3{5 \choose 2}\). This form of probability is called Bernoulli probability.
</p>
<p>Another way to think about this, is you have \(6^3\) total
	possibilities on what you can roll. Then you have \(5 \choose 2\) ways you can roll 3 exactly twice, and for
	each of
	those ways, the rest of the numbers can be any number 1,2,4,5,6 that's not 3, so 5 possibilities for each
	extra
	digit (in this case there are 3 extra digits) for each time you roll 3 exactly twice. So the outcomes you're
	looking
	for over total possibilities is \({5 \choose 2}\cdot 5^3/6^3\) gives the same answer. </p>
<h4>Bernoulli distribution</h4>
<p>The Bernoulli distribution, named after Swiss mathematician Jacob Bernoulli, is the discrete probability
	distribution
	of a random variable which takes the value 1 with probability p and the value 0 with probability \(q=1-p\).
	Less
	formally, it can be thought of as a model for the set of possible outcomes of a single experiment that asks
	a
	yes-no
	question. The Bernoulli distribution is the special case of the binomial distribution where a single trial
	is
	conducted.</p>
<p>What's the probability of getting at least one pair from a 5 card hand (out of 52 cards)? A good way to think
	about
	this is to find the negation of getting at least one pair, which is to get all unique numbers. Think about
	drawing
	the cards. For the first one, it doesn't matter what you get, so you're at 1. For the next card, you can get
	48/51
	cards (avoiding the other 3 that are the same as the first card). Then, for the third card, it has to be
	different
	from both your first and second cards, so your probability there is 44/50. And so forth, leading to the
	answer
	being
	\(1-(1\times\frac{48}{51}\times \frac{44}{50}\times \frac{40}{49} \times \frac{36}{48})\simeq 0.4929\)</p>
<h4>Odds</h4>
<p>Odds are slightly different in that there's a monetary aspect. If the probability of an event is p, then the
	odds
	(against) are \(1-p:p\). For example, if you're betting on a roll of the dice landing on a 3, then a
	bookkeeper
	might say the odds are 5:1 (5 times it WON'T land on 3 versus 1 times it will). So he might offer you $50 if
	it
	doesn't land on 3, and you offer $10 if it does. (Of course, in actual scenarios the bookkeeper wouldn't
	offer
	such
	equitable odds).</p>
<h4>Probability spaces</h4>
<p>A sample space is the set of possible outcomes to an experiment.</p>
<p>A probability measure \(P\) on a sample space \(S\) is a rule that assigns to each outcome \(s\in S\) a
	probability
	\(P(s) \geq 0\) satisfying \[\sum_{s\in S}P(s)=1\].</p>
<p>A probability space is a sample space \(S\) with a particular probability measure \(P\): \((S,P)\).</p>
<h4>Events</h4>
<p>An event \(E\) is a subset of a sample space \(S\) (aka \(E\subseteq S\)). If \((S,P)\) is a probability
	space,
	then
	the
	probability of the event \(E\) is \[P(E)=\sum_{s\in E}P(s)\]</p>
<p>If \(E\subseteq S\) is an event, the complement to the event \(E\) is \(E^C=\{s\in S | s \not\in E\}\), and
	so
	\(P(E^C)=1-P(E)\).</p>
<p>You can apply inclusion/exclusion to probabilities: \(P(A\cup B)=P(A)+P(B)-P(A\cap B)\).</p>
<h4>Indepedent events</h4>
<p>\(A\) and \(B\) are independent events if knowing one gives no information about the probability of the
	other. If
	\(A,B\subseteq(S,P)\) are two events then \(A,B \text{ are indepenent}\iff P(A\cap B)=P(A)P(B)\).
	Conceptually,
	if
	we know we're A, it doesn't tell us anything about the probability that we're B, so the probability of B in
	A is
	just the same as the probability in S, so we just take the chance we're in A (\(P(A)\)) and multiply it by
	the
	general population's probability of being in B (\(P(B)\)).</p>
<p>If \(A,B\) are independent events from a probability space \((S,P)\) then i) \(A,B^C\) are independent, as
	are
	\(A^C,B\), and ii) \(A^C, B^C\) are also indepedent.</p>
<p>We can extend this to more than two subsets. So if \(A, B, C\subseteq S\) and they are all mutually
	independent,
	then
	they are independent to each other, and the intersection is the multiple of all their individual
	probabilities:
	\(p(A\cap B \cap B)=P(A)P(B)P(C)\).</p>
<h4>Conditional probabilities</h4>
<p>If \(A,B\) are events from a probability space \((S,P)\), then the conditional probability of \(A\) given
	\(B\)
	is
	\[P(A|B)=\frac{P(A\cap B)}{P(B)}\]</p>
<h4>Total probability rule</h4>
<p>Suppose \(\{A_1, A_2, ..., A_n\}\) is a partition of \(S\), and \(B\) is an event in \(S\). Then
	\[P(B)=\sum_{i=1}^nP(B|A_i)P(A_i)\]. In other words, the total probability of B is the probability of B in
	each
	element in the partition.</p>
<h4>Bayes' rule</h4>
<p>Recall \(P(A|B)\) is not symmetric ie. \(P(A|B) \neq P(B|A)\). If \(\{A_1,A_2,...,A_n\}\) is a partition of
	\(S\),
	and \(B\subseteq S\) is an event, then for any \(j\),
	\[p(A_j|B)=\frac{P(B|A_j)P(A_j)}{P(B)}\]\[=\frac{P(B|A_j)P(A_j)}{\sum_{i=1}^nP(B|A_i)P(A_i)}\]</p>
<a href="https://www.youtube.com/embed/pd4tHt2Hi3s">link to vid</a>
<div class="first">Distributions and stochastic processes</div><a class="anchor" id="distribution"></a>
<h4>Random variables, probability distribution, mean, variance</h4>
<p>A random variable \(X\) is a function on a probability space \((S,P)\) i.e. \(X:S\rightarrow \mathbb{R}\). To
	every
	random variable \(X\) on a probability space \(S,P\), there are 3 important numbers: the mean \(\mu\),
	variance
	\(\sigma^2\), and standard deviation \(\sigma\). These are also associated to a probability distribution
	connected
	to \(X\). To think about the probability distribution, looking at the figure below, it's the plotting of all
	the
	results of \(X(s)\) onto a number line.</p>
<img src="{{ url_for('static', filename='img/math/prob_dist.svg') }}">
<p>Suppose \(X:S\rightarrow \mathbb{Q}\) takes on values \(x_1, x_2, ..., x_k\). For each value \(x_i\), we can
	define
	\(X^{-1}(x_i)\subseteq S\) (all the events that lead to \(x_i\)). To each such event, we know it has a
	certain
	probability. Therefore, we can define \(p_i\equiv P(X^{-1}(x_i))\). So for each value \(x_i\) of \(X\),
	there is
	a
	probability \(p_i\).</p>
<p>The expected value/mean \(E(X)=\mu\) is: \[E(X)=\sum_i x_ip_i\]</p>
<p>You can also think of the expected value or mean as the place where the probability distribution is balanced,
	also
	can see as the center of mass. The variance measures how spread out from this center the values are. The
	differences
	are squared to make the values easier to work with (and removes any negatives).
	\(\text{Var}(X)=\sigma^2\) measures how spread out from \(\mu=E(X)\) the values are
	\[\text{Var}(X)=\sum_i(x_i-\mu)^2p_i=\sum_i(x_i^2p_i-\mu^2)\]\[=E(X^2)-\mu^2\]</p>
<p>The standard deviation \(\sigma\) is the square root of the variance.</p>
<h4>Binomial distribution</h4>
<p>Say you have the question, if we toss a coin \(n\) times, what is the probably of getting
	\(k\)
	heads? The total possibilities is \(n^2\) and the total ways we can get \(k\) heads is \(n \choose k\), so
	the
	probability is \({n\choose k}/2^n\). When you have such a function, we state that this defines a binomial
	distribution: values \(x_i=0,1,2,...,n\) with probabilities \[p_k=P(k)=\frac{n \choose k}{2^n},
	k=0,1,...,n\]
</p>
<p>Using a 50% heads, 50% tails example, creating probabilities for getting \(k\) heads after flipping a coin
	\(n\)
	times gives the following \(B(10,0.5)\) binomial distribution.</p>
<img src="{{ url_for('static', filename='img/math/binom10.png') }}">
<p>However, binomial distributions also apply if the probabily of yes and no is not 50-50. In that case, we
	describe
	the
	binomial distribution as \(B(n,p)\) where (notice if we plug in 1/2 for p here we get the same thing as
	above):
	\[p_k={n \choose
	k}p^k(1-p)^{n-k}\]</p>
<p>Here's the binomial distribution for \(B(10,0.2)\):</p>
<img src="{{ url_for('static', filename='img/math/binom10_2.png') }}">
<p>For a binomial distribution, the mean and variance can be found: \[\mu=np\]\[\sigma^2=np(1-p)=npq\]</p>
<h4>Probability generating functions</h4>
<p>Suppose our probability distribution has positive integer values \(x_k=k,k=0,1,2,3,...\). Our probability
	generating
	function is as follows:\[g(t)\equiv p_0+p_1t+p_2t^2+\ldots\]Note here that \(g(1)=1\), since that's just the
	sum
	of
	all the probabilities which must add up to 1. We can find the mean and variance with the
	following:\[\mu=g'(1)\]\[\sigma^2=g''(1)+g'(1)-g'(1)^2\]</p>
<p>For the proof of the mean, notice:\[g'(1)=p_1+2p_2+3p_3+\ldots=\sum_{k=0}^\infty x_kp_k=\mu\]</p>
<p>For the proof of the variance, you'll need to understand the product rule for derivatives, and
	notice (some steps are left out):\[g'(1)+g''(1)-g'(1)^2=(tg')'(1)-\mu^2=\sum_{k=0}^\infty
	k^2p_k-\mu^2=\sigma^2\]
</p>
<p>This probability generating function now allows us to calculate the mean and variance for any binomial
	distribution
	\(B(n,p)\). Recall that the probability for any positive integer \(p_k={n\choose k}p^kq^{n-k}\). This gives
	the
	generating function: \[{n \choose 0}q^n+{n\choose 1}pq^{n-1}t+{n\choose 2}p^2q^{n-2}t^2+\ldots+{n\choose
	n}p^nt^n\]\[=(pt+q)^n\]Note the use of binomial theorem here.</p>
<p>Now we can find the mean after application of chain rule (the vertical bar means evaluated
	at):\[\mu=g'(1)=\left. n(pt+q)^{n-1}p\right|_{t=1}=np\]</p>
\[\sigma^2=np(1-p)\]
<p>An example of the use of the binomial distribution is, say you usually win 60% of your tennis matches. You
	hire a
	new
	coach and you win 12 out of 15 of your next matches. Is the coach helping or not? The probability of winning
	12
	or
	more matches out of 15 if your usual probability is 60% is the probability of you winning 12 + probability
	of
	you
	winning 13, and so on. \[p_{12}+p_{13}+p_{14}+p_{15}=\sum_{k=12}^15{15\choose k}(0.6)^k(0.4)^{15-k}\approx
	0.091\]
</p>
<h4>Geometric distributions</h4>
<p>Now suppose we toss a p-biased coin continually until we get a head. We define our random variable \(X(s)=k\)
	if
	the
	first head appears in the \(k\)th position. So an element in the sample space might be
	\(s=\text{TTTHHTH}\ldots\)
	and so \(X(s)=4\). The probability \(p_k=q^{k-1}p\) because everything before k must be tails (which means
	it
	has a
	probabilty of q). This gives a generating function (note the use of infinite geometric
	series):\[g(t)=pt+pqt^2+pq^2t^3+pq^3t^4+\ldots=pt(1+qt+q^2t^2+\ldots)=\frac{pt}{1-qt}\]</p>
<p>This gives:\[\mu=\frac{1}{p}\]\[\sigma^2=\frac{q}{p^2}\]</p>
<p>This is a pretty normal thing to think about if you play video games for loot drops. If the chance to get a
	drop
	is,
	say, one out of
	500, then on average, you need to kill the monster 500 times to get the drop.</p>
<h4>Continuous probability distributions</h4>
<p>The previous distributions dealt with random variables that take on discrete values (eg. number of heads or
	tails
	or
	number of flips). But many random variables do not take on an integer, and so for these continuous
	distributions, we
	will need to switch over from sums to integrals. We define the probability of the random variable to take on
	any
	continuous value to be determined by the probability density function or probability distribution function
	\(p(x)\),
	and the integration of all of these
	values is \(\int_{-\infty}^\infty p(x)dx=1\) and the probability for the random variable to take on any
	value in
	an
	interval a to b to be \(p(x\in[a,b])=\int_a^bp(x)dx\).</p>
<p>Therefore, the expected value or mean of a continuous distribution is a integral instead of summation of each
	random
	variable and its probability:\[E(X)=\mu=\int_{-\infty}^\infty xp(x)dx\]This is also how you would calculate
	the
	center of mass of a rod, where the rod balances, with density instead of probability.</p>
\[\text{Var}(X)=\sigma^2=\int_{-\infty}^\infty (x-\mu)^2p(x)dx\]
<h4>Uniform distribution</h4>
<p>A uniform distribution has that the probability of the random variable taking on a value is constant between
	two
	values. The value must be \(\frac{1}{b-a}\) because the total area under the curve must be equal to 1. Thus,
	the
	probability of the random variable taking on a value between \(c\) and \(d\) if
	\(p(x\in[c,d])=a&#60;c&#60;d&#60;b\)
	is
	\(\frac{d-c}{b-a}\).</p>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Uniform_Distribution_PDF_SVG.svg/1200px-Uniform_Distribution_PDF_SVG.svg.png"
	width="30%">
<h4>Transformation formulas</h4>
<p>We can transform a random variable \(X\) into say \(Y=aX+b\). In this case, note that the variance doesn't
	change
	if
	we add a constant.
	\[E(X+b)=E(X)+b\]\[E(aX)=aE(X)\]\[\text{Var}(X+b)=\text{Var}(X)\]\[\text{Var}(aX)=a^2\text{Var}(X)\]
	\[\text{SD}(X+b)=\text{SD}(X)\]\[\text{SD}(aX)=a\text{SD}(X)\]</p>
<h4>Poisson</h4>
<h4>Normal distributions</h4>
<p>The normal distribution has the probability density function with a special label \(\phi\) instead of \(p\):
	\[\phi(x)=\frac{1}{\sqrt{2\pi}}e^{-x^2/2}\]</p>
<p>The mean \(\mu=0\) and the variance and standard deviation are both \(\sigma^2=1=\sigma\).</p>
<img src="https://miro.medium.com/max/1200/1*IdGgdrY_n_9_YfkaCh-dag.png" alt="normal_distribution" width="70%">
<p>This is usually considered the standard normal \(N(0,1)\) with 0 as the mean and the variance as 1.</p>
\[P(z\in[a,b])=\int_a^b\phi(x)dx\]
\[P(z\in[-\frac{2}{3},\frac{2}{3}])=0.5\]
\[P(z\in[-1,1])=0.683\]
\[P(z\in[-2,2])=0.956\]
\[P(z\in[-3,3])=0.997\]
\[P(z\in[-1.96,1.96])=0.950\]
<p>You can have a more general normal distribution where the mean is not at 0, so \(N(\mu,\sigma^2)\), with the
	probability density function (shifting by the mean and dilating by a factor of
	\(sigma\):\[p(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-(x-\mu)^2/(2\sigma^2)}\]</p>
<p>Note that this probability density function does not use \(\phi\) or \(z\). So if we take the random variable
	representing \(N(\mu,\sigma^2)\) and translate it such that the new random variable
	\(z=\frac{x-\mu}{\sigma}\),
	then
	this is now the standard normal \(N(0,1)\).</p>
<h4>Cumulative distribution function</h4>
<p>If \(p(x)\) is any probability distribution (discrete or continuous), then the cumulative distribution
	function
	is
	the integral from negative infinity to x:\[F(x)\equiv \int_{-\infty}^xp(t)dt\]</p>
<p>The standard normal distribution has a cumulative distribution function which has been tabulated.</p>
<h4>Central limit theorem</h4>
<p>If we sample any distribution \(n\) times and take an average, then as \(n\to \infty\) the sampling
	distribution
	of
	averages approaches a
	normal distribution.</p>
<h4>Finite-state machines</h4>
<p>A computer system may be abstracted as a mapping from state to state driven by inputs. In other words, a
	system
	may
	be considered as a transition function \(T:S \times I \to S \times O\), where \(S\) is the set of states and
	\(I,O\)
	are the input and output functions. If the state set \(S\) is finite, the system is called a finite state
	machine
	(FSM). Alternately, a finite state machine is a mathematical abstraction composed of a finite number of
	states
	and
	transitions between those states. If the domain \(S \times I\) is reasonably small, then one can specify
	\(T\)
	explicitly using diagrams similar to a flow graph to illustrate the way logic flows for different inputs.
	The
	operation of an FSM begins from a start state, goes through transitions depending on input to different
	states,
	and
	can end in any valid state. However, only a few of all the states mark a successful flow of operation,
	called
	accept
	states.</p>
<p>The information capacity of an FSM is \(C=\log |S|\). Thus, if we represent a machine having an information
	capacity
	of \(C\) bits as an FSM, then its state transition graph will have \(|S|=2^C\) nodes.</p>
<p>A finite state machine is formally defined as \(M=(S,I,O,f,g,s_0)\) where \(S\) is the state set, \(I\) is
	the
	set up
	of input symbols, \(O\) is the set of output symbols, \(f\) is the state transition function, \(g\) is the
	output
	function, and \(s_0\) is the initial state.</p>
<p>Given an input \(x \in I\) on state \(S_k\), the FSM makes a transition to state \(S_h\) following state
	transition
	function \(f\) and produces an output \(y \in O\) using the output function \(g\).</p>
<p>The state transition and output values for different inputs on different states may be represented using a
	state
	table.</p>
<div class="first">Foundations and methodology of statistics</div><a class="anchor" id="statistics"></a>
<div class="first">Applied statistics</div><a class="anchor" id="applied"></a>
<div class="first">Natural</div><a class="anchor" id="natural"></a>
<div class="first">Natural</div><a class="anchor" id="natural"></a>
<div class="first">Natural</div><a class="anchor" id="natural"></a>
<div class="first">Natural</div><a class="anchor" id="natural"></a>
<div class="first">Natural</div><a class="anchor" id="natural"></a>
{% endblock %}