{% extends 'base.html' %}

{% block content %}


<style>
	p,
	button {
		font-size: 100%;
	}

	#integer1_remove {
		display: none;
	}
</style>

https://zbmath.org/classification/
<h1>Math</h1>
<li>So when it comes to math, I think there is the failure in general education of math in which the order of how
	things
	are taught are somewhat confusing. As we grow to better understand how the brain develops over our lifetime,
	perhaps
	we can better create a structure upon which to build math. The problem with math is that it is the most
	difficult
	thing to learn, and when I mean difficult, I mean that the cognitive patterns required through the study of math
	are
	the most technically challenging for our brains to process, and naturally challenges the capacity of our mind.
	For
	example, the entity "infinity" is not something we can visualize in our brain. The issue is that the foundation
	of
	math is rarely taught, and almost never learned, by most people. So a lot of the times, people won't really
	enjoy
	learning math because they find it difficult to apply math to real world problems. A common example is when
	people
	first learn about probability. When people first hear the words "I flip my coin and it lands on heads AND I flip
	my
	coin and it lands on tails," they don't know how to process the word "AND." Because in most of their life, they
	have
	understood AND as equivalent to addition. "I have five apples AND I have three apples". So in total I have eight
	apples. 5 + 3 = 8. But when they start dealing with probability, that word "AND" now is multiplication. "The
	probability of flipping heads the first time AND the probability of flipping heads the second time", they might
	think... okay. 50% + 50% = 100%. But then they realize this is wrong, and it's actually 50% * 50% = 25%. So then
	people get really confused... they have the same word "AND" but it means different things? Math doesn't make any
	sense!</li>
<li>A key element to one day becoming a neural engineer is the ability to understand the language of math. A lot of
	times, you might be trying to figure a problem out, and you can read a bunch of papers, but none of it really
	makes
	any sense. Because you can't make the connection. It is like looking at a bunch of disjointed letters or words
	on a
	canvas and trying to interpret a sentence or story from it. It is difficult if not impossible.</li>
<li>I have mainly looked at math education under the Mathematics Subject Classification. The goal of studying math
	in
	this case, as well as the study of every other subject, is to solve problems.</li>
<li>Propositional logic</li>
<p>Propositional logic, or zeroth order logic, is a language for math. The first set of symbols we need to learn is
	about propositional logic. A proposition in this case is a statement which can take on two values: true or
	false.
	The proposition P is a specific proposition, for example, "I am a human," which can be true or false. If I use a
	lower case p, then this a generalization of any proposition, which is useful when we talk about propositions in
	general. The negation of a proposition, eg. "I am NOT a human" is symbolized as ¬P. Now, let's talk about
	connectives. In English, you have conjunctions, typically things like "and", "or", "but", etc. In math, we call
	these connections "connectives", and the word "conjunction" has a specific meaning. The word "conjunction" means
	"and" is translated into the symbol ∧. So if we have two propositions, eg. "I am a human" and "I am fat", then P
	∧ Q
	means "I am a human AND I am fat," indicating that both propositions have the value of true. Now, flip that
	symbol
	upside down, and we get a disjunction, which means "or." P ∨ Q in this case will mean "I am a human OR I am
	fat."
	However, the English "or" has two meanings. The exclusive "or" means that exactly one of two propositions is
	true.
	The inclusive "or" means AT LEAST one of the discussed propositions is true. In math, when we say "or" we're
	usually
	referring to the INCLUSIVE "or", which means P ∨ Q holds true if P is true, Q is true, or if P and Q are both
	true.
	After disjunction, we have the material conditional, which is written P → Q. This means "if P then Q". The
	proposition to the left of the arrow is called the antecedent, and the proposition to the right is called the
	consequent. So in my example, P → Q means "If I am a human, then I am fat." The biconditional, written P ↔ Q,
	means
	that the truth value of P and Q are the same. Which means that if both P and Q are true, then P ↔ Q is true, and
	if
	both P and Q are false, then P ↔ Q is also true. The opposite of this is the aforementioned exclusive or,
	written P
	⊕ Q, which is only true when P and Q are different.</p>
<li>First order logic</li>
<li>In first order logic, or predicate logic, we extend propositional logic slightly. Instead of statements having a
	truth value, we now divide them into two parts: the subject and the predicate. The predicate is a statement that
	has
	a variable which does not have a truth value until that variable is defined. The subject is that variable that
	needs
	to be defined. So an example is, "I am x meters tall." This statement does not have a truth value until I define
	what x is.</li>
<p>Now, I want to reinforce that these comparisons... propositional logic and first-order logic, are about facts.
	Propositional logic only discusses facts, facts that can be true or false.. in other words, they can only be 0
	or 1.
	First-order logic adds on this objects and relations. Meaning one fact can be true for multiple objects, and an
	element can have a relationship to another object. There are other languages used to discuss the world around
	us,
	which are probability theory and fuzzy logic, which are studies into uncertainty. In probability, there is a
	truth
	value but we look at a chance that truth value is correct. In fuzzy logic, the language we use is uncertain, for
	example, if you state, "I am tall." It is difficult to assign a truth value to this statement because it depends
	on
	what height we consider tall to be, and so fuzzy logic investigates these scenarios.</p>
<p>The converse of a categorical or implicational statement is the result of reversing its two constituent statements.
	For the implication P->Q, the converse is Q->P. The truth of the converse is generally independent from that of the
	original statement.</p>
<li>Proof theory and constructive mathematics</li>
<p>Let's talk about writing proofs for a sec. I'm no mathematician so this is what I garner from a quick google search
	of how to write proofs by Eugenia Cheng. This is because I was dealing with a linear algebra textbook which
	encourages the use of proofs from the start, and I haven't used proofs since 7th grade geometry class. All I really
	remember about proofs was... well, not much. That you start with some assumptions, and then some little dots that
	mean therefore or something like that.</p>
<p>A proof is a series of statements, each of which follows logically from what has gone before. It starts with things
	we are assuming to be true and ends with what we are trying to prove. The beginning discusses what we are assuming
	to be true, including definitions of what we're talking about. The middle has statements following logically from
	what came before, adn the end is what we're trying to prove. We are given the beginning and the end, but we have to
	fill out the middle. The difficulty in writing a proof is that the order in which we write it is usually not the
	order in which we thought it up, and we often think up of a proof backwards. So the first mistake to avoid is
	writing the proof in the order in which you thought of it.</p>
<p>Some examples of things we try to prove are \(x=y\), \(x\implies y\) (x implies y), \(x\iff y\) (x is true if and
	only if y is true), x is purple, \(\forall x\space p(x)\) is true (all animals of a certain kind x behave in a
	certain way
	p(x)), \(\exists x\) (there exists x) such that p(x) is true. Or "suppose that a, b, c, and d are true. Then e is
	true."</p>
<p>For the general shape of a proof, the beginning will discuss axioms, definitions, and state the given. The middle
	will have a series of equations alongside the axioms, definitions, and givens that are used to be able to make those
	equations valid. Then, at the end you restate what you were trying to prove. The three dots in the shape of a
	triangle means "therefore", and Q.E.D. means "quod erat demonstrandum" or "which was to be demonstrated" and is
	placed at the end of proofs to indicate the proof is complete.</p>
<p>It's important to remember that you want to end with what you're trying to prove, and not start with it and go
	backwards. This is an easier mistake to make than first meets the eye. It's also important to not jump over too many
	steps without explaining what you're doing. Of course, you don't want to use logic that is just not correct (I'll
	try to figure out false logic later). Two classic forms of incorrect logic is negating a statement incorrectly and
	proving the converse of something instead of the thing itself. Negation is taught alongside
	propositional/first-order logic. If in doubt, justify more than less.</p>
<p>She gives some tips on how to write a proof practically. She mentions that writing a proof is hard and is more like
	being a poet, and a lot of the time you just need to sit down and stare at what you're trying to prove for a long
	time. But she suggests some tips. Write out the beginning very carefully in mathematical language. Write out the end
	very carefully in mathematical language. Then try and manipulate both the beginning and the end to try and make them
	look like one another. Take big leaps to see what happens, then make big leaps into smaller leaps afterwards. See if
	the situation reminds you of any situations you've ever seen before. I like these tips because they are pretty much
	how I think people should deal with any problem in life logically. Note where you're starting off from, and where
	you want to go, then work both ways and see if you can connect the dots!</p>
<p>One method for proofs, which may be familiar for those who work in programming as well, is proof by induction. In the
	base step we verify that the statement is true for some first instance, and then in the inductive step we establish
	an implication, that if the statement is true for all prior cases then it follows for the present case also. These
	two steps prove together that the statement for all the steps because the base step is true and everything that
	follows is also true.</p>
<p>To prove by mutual set inclusion is to prove that the solution set of a system equals something. This is by proving
	that any solution to the system is in the set, and anything in the set is a solution of the system. It's easy to
	confuse these two statements so try to visualize it in your head.</p>
<p>She then goes into some examples of styles for typical proof cases but I'll probably learn those along the way.</p>
<h4>Equivalence relations</h4>
<p>An equivalence relation is a binary relation that is reflexive, symmetric and transitive. Reflexive means that it is
	equivalent to itself, symmetrical is a to b if and only if b to a, and transivity is if a to b and b to c then a to
	c.</p>
<h4>Commutative, associative</h4>
<p>Commutative means you can write the same thing forwards and backwards (\(a+b=b+a\)), associative means you can group
	things in
	different combinations (\((a+b)+c=a+(b+c)\)).</p>
<h4> Union, Intersection, and Complement</h4>
<p>The union of two sets contains all elements contained in both sets, and is denoted \(A\cup B\). The intersection of
	two sets contains only the elements that are in both sets, and is denoted \(A \cap B\). The complement of a
	set A contains everything that is not in the set A, denoted \(A'\).</p>
<li>Arithmetic and number theory</li>
<pre>
	-pre-numerical stage, concept of numbers
	-natural numbers
	-integers, rational numbers
	-real numbers, complex numbers
	-number theory
	-measures and units
	-ratio and proportion, percentages
	-real life mathematics, practical arithmetic
</pre>
<li>Algebra</li>
<li>So let's discuss algebra real quick. The word itself is about the 'reunion of broken parts'... an Arabic word.
	It's
	about the study of symbols. You can divide algebra into elementary algebra and abstract algebra. Elementary
	algebra
	is essential for studying any science, whereas abstract algebra is primarily studied by mathematicians. Algebra
	is
	concerned with the solving of equations of numbers. Then it extended also into non-numerical objects and
	abstracted
	them into groups, rings, and fields, which we will look at later. Algebra is pretty much foundational to all of
	math.</li>
<pre>
	-elementary algebra
	-equations and inequalities
	-groups, rings, fields
	-ordered algebraic structures
	-linear algebra
</pre>
<h2>Linear Algebra</h2>

<p>Linear algebra discusses how to manipulate linear systems, vector spaces, maps between spaces, determinants, and
	similarity.</p>

<h4>Gauss's method</h4>
<p>So what does it mean to have a linear combination? A linear combination is where you have a bunch of variables,
	and
	you assign a coefficient to each of those variables. Those coefficients multiplied by their corresponding
	variables
	add up to a constant. A linear combination cannot have any modifications to the variable, so you can't have
	\(\sin{x}\) or \(x^2\).</p>
<p>To find the set of all solutions for the system of combinations is to solve the system. Gauss's method is to
	transform each system by swapping, multiplying, rescaling, etc. such that the system is brought to a form that
	can
	easily find the value of each variable. The three valid operations on a linear combination within a system is 1)
	swapping with another, 2) multiplying both sides by a nonzero constant, and 3) replacing itself with the sum of
	itself and a multiple of another. Note that multiplying by 0 is not allowed, and adding a multiple of a row to
	itself
	is not allowed because adding -1 times the row to itself has the effect of multiplying the row by 0.</p>
<p>The first variable with a nonzero coefficient is the row's leading variable. A system is in echelon form if each
	leading variable is to the right of the leading variable in the row above it, except for the leading variable in
	the
	first row, and any rows with all-zero coefficients are at the bottom.</p>
<p>Gaussian method systematically solves these linear systems by using operations to remove the leading variable one
	at
	a time. So the first step is you remove x from all the equations by manipulating each equation to remove x, then
	swap lines to get into echelon form, and then using the second equation to manipulate the rest, and so forth.
	You
	eventually get the last variable isolated and then back-solve to get the rest of the values.</p>
<p>If there are redundant equations, eventually you will resolve the system so that one line says 0=0, indicating a
	redundant equation. If you get something like 0=2, then it means there's an inconsistency and that means the
	system
	has no solutions. If you can't isolate one variable, and are left with something like \(x+y=4\), then your
	system
	has infinite solutions.</p>
<h4>Describing the solution set</h4>
<p>It's best to describe the solution set if there are many solutions in terms of free variables, which are
	variables
	that are not leading in an echelon form linear system. You should rephrase the solution set in terms of these
	variables to make it easier to understand. These variables that we use to describe a family of solutions are
	called
	parameters. Free variables and parameters aren't always the same because we can choose not to use a free
	variable as
	a parameter.</p>
<h4>Matrices</h4>
<p>An \(m\times n\) matrix is a rectangular array of numbers with m rows and n columns. Each number in the matrix is
	an
	entry. Matrices are usually denoted with an upper case roman letter. A matrix with 2 rows and 3 columns would be
	said to be a "two-by-three" matrix, with number of rows always stated first. Matrix entries are named with the
	corresponding lower-case letter, then with subscripts of m,n. Writing linear systems in matrix form just makes
	things easier so you don't have to write all the variables and signs. Adding a vertical bar separates
	coefficients
	on the left side and constants on the right. With the bar, a matrix becomes an augmented matrix.</p>
<p>You can also write the solution sets in matrix form by turning the x, y, z, w (etc) into column vectors and
	adding
	those vectors together (it's hard to visualize so have to look up at least until I can add it in mathjax). A
	column
	vector or a vector is a matrix with a single column. You can also have a row vector. The entries of a vector are
	sometimes called components. A column or row vector whose components are all zeros is a zero vector. Vectors are
	usually represented with an arrow above a lower-case letter. Vectors can be summed together (must have the same
	number of entries) or scaled by a real number. All linear systems will, with Gauss's method, end up with the
	same
	free variables.</p>
<p>The transpose of a matrix is the matrix whose columns are the rows of the original matrix.</p>
<h4>General = Particular + Homogeneous</h4>
<p>The solution description has two parts, the particular solution (for example (1,2,3)) and the unrestricted linear
	combination of vectors for the free variables after Gaussian reduction. A linear equation is homogeneous if it
	has a
	constant of zero (all of the variables*coefficients add up to zero). A homogeneous system must always be
	consistent
	because there is always the zero vector as a solution.</p>
<p>We say that the set of vectors is generated by or spanned by the set if the vector can be a linear combination of
	the
	vectors in the set.</p>
<p>We call the matrix of the coefficients of a system nonsingular if it is a square matrix with a unique solution
	(no
	free variables) in a homogeneous system (setting all the constants to 0), which means there are the same number
	of
	echelon form equations as there are variables. A nonsingular coefficient matrix indicates the system only has
	one
	unique solution. A coefficient matrix is singular (singular in this case meaning different from expected) if its
	homogeneous system has zero or infinite solutions. What this means to me is that you can "solve" a linear system
	if
	you have as many VALID equations AFTER Gaussian reduction as unknowns. The idea that you can solve a system as
	long
	as you have as many equations as unknowns is often not true.</p>
<h4>Dot product</h4>
<p>The dot product, or inner product, or scalar product, of two n-component real vectors is the linear combination
	of
	their components.</p>
<h4>Linear Geometry</h4>
<p>The solution set of a linear system with \(n\) unknowns is a linear surface in \(\mathbb{R}^n\). Specifically, it
	is
	a k-dimensional linear surface, where k is the number of free variables in echelon form version of the system.
	For
	instance, if there is just a single equation, then the solution set is an n-1-dimensional hyperplane. The
	solution
	set of the homogenous linear system is a linear surface passing through the origin. We can view the general
	solution
	set of any linear system as being the solution set of its associated homogeneous system offset from the origin
	by a
	vector, aka the particular solution.</p>
<p>A vector in its canonical position starts from the origin.</p>
<p>The length of a vector is the square root of the sum of the squares of its components. You can normalize a vector
	by
	reducing it to a vector with a magnitude of one. Then, take for example a two-dimensional plane. Put the two
	vectors
	in canonical position, and then take the plane formed by the origin and the endpoints. Consider a triangle
	formed by
	the origin and the endpoints of the two vectors. Applying the Law of Cosines, and taking into account that the
	length of a vector is the square root of the sum of its squares, we can get the angle between the two vectors to
	be:
	$$\theta=\cos^{-1}(\frac{u_1v_1+u_2v_2+u_3v_3}{|\vec{u}||\vec{v}|})$$</p>
<p>Even in higher-dimensional spaces, lines are straight and planes are flat. For any two points in a linear
	surface,
	the line segment between them is contained in that surface. If the linear surface was not flat, then that would
	allow for shortcuts where the shortest path between two vectors would not be the line between them. Linear
	surfaces
	therefore have no bends.</p>
<p>The angle between two nonzero vectors is:</p>
$$\theta=\cos^{-1}(\frac{\vec{u}\cdot\vec{v}}{|\vec{u}||\vec{v}|})$$
<p>Vectors are orthogonal (aka perpendicular) if and only if their dot product is zero. They are parallel if and
	only if
	their dot product equals the product of their lengths.</p>
<h4>Cauchy-Schwarz Inequality</h4>
<p>Cauchy-Schwarz inequality states that \(|\vec{u}\cdot\vec{v}|\leq|\vec{u}||\vec{v}|\) with equality if and only
	if one vector is a scalar multiple of the other. What this says is that if you take the dot product of two
	vectors,
	it
	will be less than or equal to the product of the length of the vectors. This allows for the prior equation for
	the
	angle between two vectors to be always possible.</p>
<h4>Gauss-Jordan Reduction</h4>
<p>The Gauss-Jordan Reduction is just an extension of Gauss's Method which making all of the leading entries into
	1's
	and then uses the leading entries to eliminate all other entries in each column by combining upwards. Using one
	entry to clear out the rest of a column is called pivoting on that entry. The resulting matrix is in reduced
	echelon
	form, in which each leading entry is a 1 and is the only nonzero entry in its column. The only advantage of
	reduced
	echelon form to normal echelon form is you can read out the description of the solution set from the matrix. Any two
	matrices that are interreducible by elementary row operations are row equivalent. Any matrix can only be reduced
	down to one reduced echelon form: there are not multiple variants.</p>
<p>It is not the set of parameters that is unique, it is the set of fre variables that is unique.</p>
<p>"The idea here is that one way to understand a mathematical situation is
	by being able to classify the cases that can happen. This is a theme in this book and we have seen this several
	times already. We classified solution sets of linear systems into the no-elements, one-element, and infinitely-many
	elements cases. We also classified linear systems with the same number of equations as unknowns into the nonsingular
	and singular cases."</p>
<li>You need matrix algebra to help solve systems of equations encountered in electrical circuit analysis.</li>
<h4>SageMath</h4>
<p>Sage is a math software you can use on Windows subsystem for linux (WSL) to help solve math problems.</p>
<h4>Input-Output analysis</h4>
<p>Mathematical models can get complicated/confusing very fast. Sensitivity analysis is seeing how sensitive the
	predictions of our model are to the accuracy of the assumptions. A single model does not suit every case and
	assuring that the assumptions underlying a model are reasonable for a particular prediction requires the judgments
	of experts.</p>
<h4>Vector space</h4>
<p>A vector space is a set of vectors for which all vectors within the space and scalars satisfy that the set is closed
	under vector addition, vector addition is commutative, associative, there is a zero vector, each vector has an
	additive inverse which sums to 0, scalar multiplication distributes over scalar addition and vector addition, scalar
	multiplication associates, and multiplication by the scalar 1 gives the identity operation. Particularly important
	are the closure conditions, which specify that addition and scalar multiplication operations are always defined for
	every pair of vectors and every scalar and vector, and the result of the operation is a member of the set.</p>
<p>A one-element vector space is a trivial space.</p>
<img src="{{ url_for('static', filename='img/math/vector.png') }}">
<h4>Subspaces and Spanning Sets</h4>
<p>For any vector space, a subspace is a subset that is itself a vector space, under the inherited operations. Any
	subspace that is not the entire space itself is a proper substance. A subset is a subspace if and only if it is
	closed under linear combinations. The span (or linear closure) of a nonempty subset S of a vector space is the set
	of all linear combinations of vectors from S. The span is also a subspace of the vector space.</p>
<h4>Span</h4>
<p>The span, or linear closure, or linear span, or linear hull, of a set is the smallest linear subspace that contains
	the set. It is the set of linear combinations of elements of S. The span of a set is a vector space, so you can use
	the phrases: set S spans vector space V; S generates V; V is spanned by S; V is generated by S; S is a spanning set
	of V; S is a generating set of V.</p>
<h4>Linear Independence</h4>
<p>In any vector space, a set of vectors is linearly independent if none of its elements is a linear combination of
	the
	others from the set. Otherwise the set is linearly dependent. A spanning set is minimal if and only if it is
	linearly independent. Subset preserves independence and superset preserves dependence.</p>
<p>Sets are collections with two properties: (i) order does not matter, and (ii) duplicates collapse. A collection
	where
	order does not matter and duplicates don't collapse is a multiset. So technically if we have a duplicate vector
	in
	our set it's not technically a set.</p>
<p>A set S is linearly independent if and only if for any vector v in S, its removal shrinks the span
	\([S-\{v\}]\not\subset[S]\) (not a subset of). In a vector space, any finite set has a linearly independent
	subset
	with the same span. Any set with the zero vector is linearly dependent.</p>
<h4>Linear combinations</h4>
<p>A linear combination is an expression constructed from a set of terms by multiplying each term by a constant and
	adding the results. So linear combinations are constructed from sets.</p>
<h4>Real coordinate space</h4>
<p>Real coordinate space of dimension n, denoted \(\mathbb{R}^n\), is the set of the n-tuples of real numbers, that is
	the set of all sequences of n real numbers. It is a real vector space, and its elements are called coordinate
	vectors. \(\mathbb{R}^n\) has an element \((x_1, x_2, ..., x_n)\).</p>
<h4>Minimal/maximal sets</h4>
<p>A minimal spanning set is one with the lowest number of vectors that spans the space. A maximal spanning set is the
	one with the highest number of vectors, and therefore IS the space. A minimal spanning set is linearly independent.
	A linearly independent set that is maximal spans the entire space.</p>
<h4>Basis</h4>
<p>A basis for a vector space is a sequence of vectors that is linearly independent and that spans the space. Because a
	basis is a sequence, order matters and it is denoted with angle brackets \(\langle \vec{\beta}_1, \vec{\beta}_2,
	...\rangle\). For any \(\mathbb{R}^n\), the standard or natural basis is the vectors that have 1 in their respective
	components and 0 in everything else. For example, R2 natural basis is (1,0) and (0,1). The trivial space has only
	one basis, that is the empty one. We have seen bases before, by finding the solution set by parametrizing certain
	free variables. The vectors in the solution set is the basis and the solutions spanned by the basis is the solution
	set and the vector space of solutions.</p>
<p>You can represent any vector in the vector space using the basis by using a column vector of the coefficients of a
	linaer combination of the basis vectors. This requires the basis to be in sequence.</p>
$$\text{Rep}_B(\vec{v})=[\vec{v}]_B=\begin{pmatrix}c_1\\c_2\\ \vdots\\c_n\end{pmatrix}_B$$

<li>Geometry</li>
<pre>
	-informal geometry
	-area and volume
	-plane and solid geometry
	-transformation geometry
	-plane and spherical trigonometry
	-analytic geometry, vector algebra
	-descriptive geometry
</pre>
<p>Before the 16th century, mathematics was divided only into arithmetic and geometry.</p>
<li>Analysis</li>
<pre>
	-mappings and functions
	-sequences and series
	-differential calculus - differential and integral calculus is important for understanding the derivation of the Nernst equation, which describes the membrane potential, need derivatives for everything (calculating inductors)
	-integral calculus
	-functions of several variables
	-functional equations
	-complex analysis
</pre>
<h2>Calculus</h2>
<h3>Derivatives</h3>
<h4>Definition of the derivative</h4>
<p>The derivative of \(f(x)\) with respect to x is the function \(f'(x)\) and is defined as:</p>
$$f'(x)=\lim_{h \to 0} \frac{f(x+h)-f(x)}{h}$$
<p>h is the change in x. The top part of the fraction is the change in y, while the bottom of the fraction is the
	change
	in x. So the equation is just the slope. The slope of what? The slope in f(x) as the h, or change in x,
	approaches
	0. Therefore, it is the instantaneous slope at point x.</p>
<p>Given \(y=f(x)\):</p>
$$f'(x)=y'=\frac{df}{dx}=\frac{dy}{dx}$$
<h4>Properties of the derivative</h4>
<p>The derivative of the sum of two functions is the sum of the individual derivatives of the separate functions.
</p>
$$(f(x)+g(x))'=f'(x)+g'(x)$$
<p>You can factor a multiplicative constant out of a derivative.</p>
$$(cf(x))'=cf'(x)$$
<p>The derivative of a constant is 0.</p>
$$\frac{d}{dx}(c)=0$$
<p>The power rule: if x has an numerical exponent, its derivative brings it down to the left and the new exponent is
	1
	less: if \(f(x)=x^n\) then \(f'(x)=nx^{n-1}\).</p>
<p>Product rule: if two functions are differentiable, then:</p>
$$(fg)'=f'g+fg'$$
<p>Quotient rule: if two functions are differentiable, then:</p>
$$(\frac{f}{g})'=\frac{f'g-fg'}{g^2}$$
<p>The six trig derivatives:</p>
$$\frac{d}{dx}(\sin(x))=\cos(x)$$
$$\frac{d}{dx}(\cos(x))=-\sin(x)$$
$$\frac{d}{dx}(\tan(x))=\sec^2(x)$$
$$\frac{d}{dx}(\cot(x))=-\csc^2(x)$$
$$\frac{d}{dx}(\sec(x))=\sec(x)\tan(x)$$
$$\frac{d}{dx}(\csc(x))=-\csc(x)\cot(x)$$
<p>The derivatives of exponential and logarithmic functions are as follows:</p>
$$\frac{d}{dx}(e^x)=e^x$$
$$\frac{d}{dx}(a^x)=a^x\ln{a}$$
$$\frac{d}{dx}(\ln{x})=\frac{1}{x}$$
$$\frac{d}{dx}(\log_a{x})=\frac{1}{x\ln{a}}$$
<p>The derivatives of the inverse trig functions:</p>
$$\frac{d}{dx}(\sin^{-1}(x))=\frac{1}{\sqrt{1-x^2}}$$
$$\frac{d}{dx}(\cos^{-1}(x))=-\frac{1}{\sqrt{1-x^2}}$$
$$\frac{d}{dx}(\tan^{-1}(x))=\frac{1}{1+x^2}$$
$$\frac{d}{dx}(\cot^{-1}(x))=-\frac{1}{1+x^2}$$
$$\frac{d}{dx}(\sec^{-1}(x))=\frac{1}{|x|\sqrt{1-x^2}}$$
$$\frac{d}{dx}(\csc^{-1}(x))=-\frac{1}{|x|\sqrt{1-x^2}}$$
<p>The analog to the trig functions are the hyperbolic functions:</p>
$$\sinh{x}=\frac{e^x-e^{-x}}{2}$$
$$\cosh{x}=\frac{e^x+e^{-x}}{2}$$
<p>The derivatives to the hyperbolic functions are as follows:</p>
$$\frac{d}{dx}(\sinh{x})=\cosh{x}$$
$$\frac{d}{dx}(\cosh{x})=\sinh{x}$$
$$\frac{d}{dx}(\tanh{x})=\sech^2{x}$$
$$\frac{d}{dx}(\coth{x})=-\csch^2{x}$$
$$\frac{d}{dx}(\sech{x})=-\sech{x}\tanh{x}$$
$$\frac{d}{dx}(\csch{x})=-\csch{x}\coth{x}$$
<h4>Chain rule</h4>
<p>If we have two functions and they are both differentiable, then the derivative of the composite of the two
	\((f\circ
	g)(x)\):</p>
$$f'(g(x))g'(x)$$
<p>Similarly, if we have \(y=f(u)\) and \(u=g(x)\), then the derivative of y is:</p>
$$\frac{dy}{dx}=\frac{dy}{du}\frac{du}{dx}$$
<p>So, for example, if you have the function \(R(z)=\sqrt{5z-8}\):</p>
$$f(z)=\sqrt{z}$$
$$g(z)=5z-8$$
$$R'(z)=f'(g(z))g'(z)$$
$$=f'(5z-8)g'(z)$$
$$=(5)*(1/2)(5z-8)^{-1/2}$$
<h4>Implicit differentiation</h4>
<p>So what if you want to find the derivative of a function that is not in the form \(y=f(x)\)?</p>
$$xy=xy(x)=1$$
$$\frac{d}{dx}(xy(x))=\frac{d}{dx}(1)$$
<p>Use the product rule:</p>
$$(1)y(x)+x\frac{d}{dx}(y(x))=0$$
$$y+xy'=0$$
<p>(Note that the y(x) were converted to y... they are the same. This is not multiplication but just a reminder that
	y
	is function of x.)</p>
$$y'=-y/x$$
<p>Go back to the start and recognize we can solve for y.</p>
$$y=1/x$$
$$y'=-1/x^2$$
<h4>Differentials</h4>
<p>Given a function \(y=f(x)\) we call \(dy\) and \(dx\) differentials, and the relationship between them is given
	by
	\(dy=df=f'(x)dx\).
	<h4>Indefinite Integrals</h4>
	<p>Now that we've gone through derivatives, let's now do it backwards. The question is... what function did we
		differentiate to get \(f(x)\)?</p>
	<p>Let's say our function is \(f(x)=x^4+3x-9\).</p>
	<p>If you think about how a derivative works, in order to get \(x^4\), we need to take the derivative of
		\(x^5\).
		But if we take the derivative of that, we will get \(5x^4\). So the antiderivative of \(x^4\) should
		actually be
		\(\frac{1}{5}x^5\).</p>
	<p>So if you extend this for the rest of the terms, the antiderivative is \((1/5)x^5+(3/2)x^2-9x\). And then you
		think we would be done. But remember that the derivative of any constant is 0, so we still need to add on
		the
		antiderivative of 0 (a constant c), making our final antiderivative:</p>
	$$(1/5)x^5+(3/2)x^2-9x+c$$
	<p>If \(F(x)\) is any anti-derivative of \(f(x)\) then the most general anti-derivative of \(f(x)\) is called an
		indefinite integral and is denoted:</p>
	$$\int{f(x)dx}=F(x)+c$$
	<p>Now you might wonder about this dx (the differential) added after the function. You can think of dx as the
		end of
		the integral, where the integral (S-like) symbol is the left parentheses and the dx is the right
		parentheses.
	</p>
	<p>The dx also defines what variable we are integrating with respect to. For example, \(\int{2tdx}=2tx+c\), NOT
		\(x^2+c\).</p>
	<h4>Properties of the Indefinite Integral</h4>
	<p>We can factor multiplicative constants out of indefinite integrals, just like in derivatives.</p>
	<p>The integral of a sum of two functions is the sum of their individual integrals (just like derivatives).</p>
	<h4>Computing Indefinite Integrals</h4>
	<p>Let's start wit the integral of a power of x, which we've kind of worked through already.</p>
	$$\int{x^ndx}=\frac{x^{n+1}}{n+1}+c, n\neq-1$$
	<p>Then there's a simple one, which is just a constant, but seems to be trip people up pretty frequently.</p>
	$$\int{kdx}=kx+c$$
	<p>Then we can take a look at trig functions.</p>
	$$\int{\sin{x}dx}=-\cos{x}+c$$
	$$\int{\cos{x}dx}=\sin{x}+c$$
	$$\int{\sec^2{x}dx}=\tan{x}+c$$
	$$\int{\sec{x}\tan{x}dx}=\sec{x}+c$$
	$$\int{\csc^2{x}dx}=-\cot{x}+c$$
	$$\int{\csc{x}\cot{x}dx}=-\csc{x}+c$$
	<p>Now let's go through exponential and logarithmic functions.</p>
	$$\int{e^xdx}=e^x+c$$
	$$\int{a^xdx}=\frac{a^x}{\ln{a}}+c$$
	$$\int{\frac{1}{x}dx}=\ln{|x|}+c$$
	<h4>Substitution Rule for Indefinite Integrals</h4>
	$$\int{f(g(x))g'(x)dx}=\int{f(u)du}, \text{where } u=g(x)$$
	<h4>Definition of the Definite Integral</h4>
	<p>Given a function \(f(x)\) that is continuous on the interval \([a,b]\), we divide the interval into \(n\)
		subintervals of equal width \(\Delta{x}\), and from each interval choose a point, \(x_i^*\). Then the
		definite
		integral of \(f(x)\) from \(a\) to \(b\) is:</p>
	$$\int_a^b{f(x)dx}=\lim_{n\to\infty}\sum_{i=1}^n{f(x_i^*)\Delta{x}}$$
	<p>Imagine you graph a function and you want to find the area under the curve from x=a to x=b. "a" is called the
		lower limit and "b" is the upper limit and from a to b is the interval of integration. How would you find
		that
		area? What you could do is take an approximate area by getting the height at each point of the curve, and
		then
		multiplying the height by some width, to get a rectangle, and add all of those rectangles together. To get a
		more and more accurate approximation, you can keep making these rectangles smaller and smaller until you
		have an
		infinite number of infinitely narrow rectangles. This is what the definition of the definite integral does.
	</p>
	<h4>Properties of the Definite Integral</h4>
	<ol>
		<li>You can switch the limits on the integral as long as you add on a minus sign.</li>
		<li>If the limits are the same, the integral is zero.</li>
		<li>You can factor out any constant.</li>
		<li>You can break up sums of integrals.</li>
		<li>You can add up break up an integral into parts.</li>
		$$\int_a^b{f(x)dx}=\int_a^c{f(x)dx}+\int_c^b{f(x)dx}$$
		<li>As long as the function and limits are the same, the actual variable of integration doesn't really
			matter.
		</li>
	</ol>
	<h4>Net Change Theorem</h4>
	<p>We have already discussed one interpretation of the integral: the area under the curve of a function. Another
		interpretation is the net change in the quantity of the function. For example, imagine your x axis is time
		and
		your y axis is speed (distance over time). Then the integral gives you the total distance travelled over
		that
		period of time. Another example is inductors in circuits. The voltage is dependent on the inductance and
		change
		in current. So if you integrate the change in current over time, you get the total current. Which means,
		since
		the voltage depends on the change in current, you can also get the total current from integrating the
		voltage.
		On the other hand, for a capacitor, the voltage builds up on the parallel plates due to injection of charge,
		which would be the total current sent to the capacitor. So you can find the voltage as an integration of the
		current over time.</p>
	<h4>Fundamental Theorem of Calculus, Part 1</h4>
	<p>If \(f(x)\) is continuous on \([a,b]\), then \(g(x)=\int_a^x{f(t)dt}\) is continuous on \([a,b]\) and it is
		differentiable on \((a,b)\) and that \(g'(x)=f(x)\).</p>
	<p>In essence, the fundamental theorem of calculus connects derivatives and integrals. Let's say you want to
		look at
		some property... let's say distance, denoted by "y". This could be volume, energy... whatever. Let's say I
		get
		in a car and I start driving forward. I know I need to travel 100 miles north and dig at a location to find
		a
		treasure chest, but I don't have a GPS to tell me exactly where I am. All I have in the car is the meter
		which
		tells me how fast I'm moving. This meter is essentially telling me the derivative of distance with respect
		to
		time, or dy/dt. In order to find the distance where I am at any point, I need to integrate this derivative,
		aka
		my speed, from my starting timepoint "a" (in this case 0) to whatever time "x", and that will give me the
		total
		distance y I have traveled from time a to x.</p>
	<p>Let's look at an example.</p>
	$$\frac{d}{dx}\int_{x^2}^1{\frac{t^4+1}{t^2+1}dt}$$
	<p>Let's start from what we know. Say that we know the speed of our car is equal to
		\(f(t)=\frac{t^4+1}{t^2+1}\).
		When we integrate from \(x^2\) to 1, we're saying, from timepoint \(x^2\) all the way to timepoint 1, what
		is
		the total distance I have traveled? Then, with the differentiation, we're asking, how fast is our total
		distance
		changing as a function of x?</p>
	<p>So the first thing we can do is simplify things a bit. Instead of thinking about things backwards, going from
		\(x^2\) to 1, let's just swap the limits around, and ask, if we start at 1 second, and go to x^2 seconds,
		how
		far have I traveled? So we add a negative sign to the integral.</p>
	$$-\frac{d}{dx}\int_1^{x^2}{\frac{t^4+1}{t^2+1}dt}$$
	<p>Next, this pesky x^2 is pretty annoying. How can we change this to just x? We can use the chain rule of
		differentiation, which basically means we'll replace x^2 with x, and then multiply the derivative of x^2 in
		afterwards. As a reminder, the chain rule is as follows:</p>
	$$\frac{d}{dx}(g(u))=\frac{d}{du}(g(u))\frac{du}{dx}\;\text{where }u=f(x)$$
	<p>Again, the chain rule simply means... if you have a function inside another function, you can derive the
		outside
		function and then multiply it by the derivative of the inside function. So for our question, if we set
		\(u=x^2\)...</p>
	$$-\frac{d}{du}\int_1^{u}{\frac{t^4+1}{t^2+1}dt}\frac{du}{dt}$$
	<p>Now, we can use the Fundamental Theorem of Calculus, and derive the integral.</p>
	$$-\frac{u^4+1}{u^2+1}(2x)$$
	$$-2x\frac{x^8+1}{x^4+1}$$
	<p>So what really have we done here? What we've done is pretty simple. We found the speed at which we're
		traveling
		at a specific timepoint. But you might ask, didn't we already know the speed at any timepoint? Yes, we did,
		which is why this problem doesn't make for a great application example. But imagine that you want to know
		what
		speed you're traveling in seconds, but your clock runs in units of seconds^2. We had to convert those units
		into
		seconds first. And that's kind of what we've done. (Unfinished, will need to think about more.)</p>
	<li>Combinatorics</li>
	<li>Graph theory</li>
	<li>Descriptive statistics</li>
	<li>Probability theory</li>
	<li>Distributions and stochastic processes</li>
	<li>Trigonometry</li>
	<p>Trigonometry, or "measurement of triangles" is the branch of math that studies side lengths and angles of
		triangles. Became more popular due to the demands of navigation and the need for maps of large areas.</p>
	<img src="{{ url_for('static', filename='img/math/trig.png') }}" width=400>
	<h4>Law of cosines</h4>
	<p>The law of cosines, or cosine formula, or al-Kashi's theorem, relates the lengths of the sides of a triangle
		to
		the cosine of one of its angles. It states that, given a triangle with an angle between two side lengths a
		and
		b, then \(c^2=a^2+b^2-2ab\cos{\theta}\). This is a generalization of the Pythagorean theorem, and reduces to
		the
		Pythagorean them if the angle is a right angle.</p>
	<li>Calculus</li>
	<li>Infinitesimal calculus was added as a subfield of math around the 17th century.</li>
	<li>Probability</li>
	<li>Combinatorics: the area of mathematics concerned with counting. Involves enumeration (counting). Can be
		confusing because we are no longer talking about numbers, but about non-numerical objects, which we count,
		but
		convert those objects into numbers.</li>
	<li>Permutations and Combinations</li>
	<p>Permutations and combinations, as taught in middle/high school, are about figuring out how many ways you can
		select items from a set. I think this is often a confusing thing to learn because it's taught disjointedly
		from
		other subjects, and involves fairly fundamental aspects of math that are not taught in elementary math, and
		requires a different way of thinking. It's not really algebra, but is about combinators, or counting. So
		fundamentally we have to go back away from the fancy symbols we have been using, and just focus on counting
		things. In addition, it applies some stuff from probability with independent/dependent events. However, it
		has
		very obvious application which makes it interesting to teach. For example, if you technically enter all
		permutations of characters into a password field, you should be able to hack every online account ever
		created.
		However, with a quick understanding of permutations, you realize that is not likely.</p>
	<p>The first thing we can talk about is permutations with repetitions. How many ways can you order a set of
		numbers?
		If your set of numbers is {a, b, c}, then you can arrange them {a, a, a}, {b, b, b}, {c, c, c}, {a, a, b}...
		and
		so forth. I think about it this way. If you look at the first "slot", how many options do you have there?
		You
		have 3... a, b, or c. Now, if you pick a, then think about how many options you have for the second slot,
		you
		have 3 again... a, b, or c. So then for every option for the 1st slot, we have 3 options for the second
		slot. So
		in total, we have 3*3=9 options for the first two slots. Then, for each option in the first two slots, we
		have 3
		options for the 3rd slot, so then we have 3*3*3=27 total possibilities. This is the equation for
		permutations
		with repetitions: \(n^r\). n here is the total size of the original set we are picking from {a, b, c}. If
		our
		initial set was all the letters of the alphabet, n here would be 26. If our initial set was a deck of
		playing
		cards without jokers, it would be 52. r here is how many we are putting in order. So if we said, how many
		ways
		can you arrange 2 numbers from {a, b, c, d}, then it would be \(n^r=4^2=16\).</p>
	<p>So then let's look at permutations without repetitions. This time, if we pick "a" for our first option, we
		can't
		pick it again for our second slot. In the case of choosing 3 out of {a, b, c}, you can arrange them {a, b,
		c},
		{a, c, b}, {b, a, c}, {b, c, a}, {c, a, b}, {c, b, a}. This is kind of the more natural answer to the
		question,
		how many ways can you arrange a bunch of items? In total, there are 6 possible ways to arrange these
		numbers. So
		let's think about this in terms of slots again. In the first slot, we can choose any option. Then, in the
		second
		slot, you have one fewer option, so you now have n-1 options. Then in the third slot, you have n-2 options
		because you have taken 2 out already, and so forth... So as we go on, we realize the answer to how many
		options
		is \(n*(n-1)*(n-2)*...\). This is also termed \(n!\), or n-factorial. But that's not our answer quite yet.
		Let's
		say we only want to arrange 2 items from a set of 4. In this case, we are just doing 4 * (4-1). We don't
		care
		about the (4-2) and (4-3) because we're stopping after 2. What we notice here is (4-2) and (4-3) can be
		written
		as \(2*1 = 2!\). So we take n, subtract r, and that gives us the factorial that we need to remove because we
		don't care about them. So our ending equation for permutations without repetitions is \(n!/(n-r)!\).</p>
	<p>Now we will discuss combinations without repetition. The difference between combination and permutation is
		that
		for combinations, we don't care about the order. So whereas before with permutations, {a, b, c} was
		different
		from {c, b, a}, we now consider these to just be one option. So from our list of permutations without
		repetition, all we need to do is remove the ones which are simply permutations of each unique combination.
		Good
		news, though, is that we just did that! The number of ways we can arrange r numbers is just \(r!\). So the
		equation for combinations without repetitions is just the equation for permutations without repetitions
		divided
		by \(r!\), aka \(\frac{n!}{r!(n-r)!}\).</p>
	<p>Finally, we get to combinations with repetitions. In this case, we don't care about the order, but we can
		repeat
		getting one number more than once. Imagine this: you are at an ice cream parlor, and there are 4 different
		ice
		cream flavors you can choose from... {a, b, c, d}, and you get 3 scoops total for your ice cream cone. Now
		imagine there is a robot behind ice cream "a", and your job is to tell him whether to scoop up ice cream or
		move
		over to the right to the next ice cream flavor. We will imagine "O" means scoop up ice cream, and ">" means
		to
		move over to the right. How would we scoop up 3 scoops of "a"? It would just be OOO>>>. The robot would take
		3
		scoops of "a", and then move over all the way to the right. What if we wanted one scoop of "a" and 2 scoops
		of
		"d"? Then it would be O>>>OO. What you'll realize is that for each set of instructions, we will get a
		different
		combinations (with repetitions) of ice cream flavors. If OOO>>> means three scoops of "a", there is no other
		set
		of instructions we can give that will also give us three scoops of "a". Therefore, all we need to do to find
		the
		combinations with repetitions is to find how many ways we can position the "O"s throughout our instructions
		OOO>>>. But wait! We already know how to do that! There are 6 positions total. And we need to pick 3 of
		those
		positions. The order doesn't matter, because they're all "O," but we can't repeat a single position more
		than
		once. So this is just combinations without repetitions, and we have that equation above...
		\(\frac{6!}{3!(6-3)!}\), and that will be our answer. Now, the number of positions we have in total will
		always
		be \(n+r-1\), because we are taking r scoops and moving n-1 times to get to the end. And r stays the same.
		So
		our end equation for combinations with repetitions is
		\(\frac{(n+r-1)!}{r!(n+r-1-r)!}=\frac{(n+r-1)!}{r!(n-1)!}\).</p>
	<p>So you can see here that working with combinatorics takes a bit more out of the box thinking, and requires a
		lot
		of visualization and imagining multiple iterations of similar things, which makes it inherently difficult.
		But
		also makes it super interesting!</p>

	<h4>Student's t-test</h4>
	<p>William Sealy Gosset was working at Guiness brewery and developed a test to determine the difference for
		things,
		say, barley growth. He wanted to publish the test but the company was nervous that he would reveal secrets,
		so
		he published under the pseudonym "Student."</p>
	<p>Imagine you have two fields of barley. If you sample one field, you can get the height of each piece of
		barley
		and you can make a distribution of the heights. Do the same for the other. We could compare the means of the
		two
		distributions, but that only tells us so much. The means could be super far apart, but the variability of
		each
		sample could be so big that there isn't actually a real difference between the two fields. So we create the
		t-value, which is a ratio of signal to noise.</p>
	$$\frac{\text{signal}}{\text{noise}}=\frac{\text{difference between group means}}{\text{variability of
	groups}}=\frac{|\overline{x_1}-\overline{x_2}|}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}$$
	<p>Once you get the t-value, you can use a t-table to find the value of t that gives you p=0.05 (inferential
		statistic) for the specific degree of freedom \(df=n_1+n_2-2\).</p>
	<p>The aforementioned example is an independent (unpaired) t-test. But you can also do a paired t-test if, for
		example, you're sampling the same population twice, so that each datapoint has a corresponding datapoint in
		the
		other sample. A two-tailed t-test splits the 0.05 into both tails making each side 0.025.</p>
	<p>Assumptions require normal distribution, similar variance in the two samples, and there should be the same
		number
		of datapoints in each sample, and there should be 20-30 samples.</p>
	<h4>ANOVA</h4>
	<p>ANOVA can be used for measurements of more than two groups. The general linear model framework is \(data =
		model
		+ error\). ANOVA means ANalysis Of Variance. Sums of squares total (SST) is the number of datapoints times
		the
		variance. \(Variance = \frac{SST}{N}\)
		{% endblock %}