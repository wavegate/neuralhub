{% extends 'base.html' %}

{% block title %}Computer science - {% endblock %}

{% block content %}
<style>
  .first {
    font-size: 30px;
    margin: 30px 0 15px;
    color: #333333;
  }

  .second {
    font-size: 20px;
    margin: 20px 0 10px;
    text-decoration: underline;
    color: #333333;
  }

  .third {
    font-size: 100%;
    color: #333333;
    font-weight: 600;
  }

  .size {
    font-size: 130%;
  }

  p,
  button {
    font-size: 100%;
  }

  #integer1_remove {
    display: none;
  }

  iframe {
    display: block;
    margin: 0 auto;
  }

  .sidebar {
    position: fixed;
    margin-left: -375px;
    border-left: 8px solid #c8dce3;
    background-color: #fff;
    overflow-y: scroll;
  }

  .sidebar {
    width: 350px;
    height: 85vh;
  }

  .core {
    padding: 7px;
    width: 100%;
    background-color: beige;
    font-size: larger;
    margin-top: 15px;
    margin-bottom: 10px;
  }

  .core:first-child {
    margin-top: 0px;
  }

  .topic {
    padding-left: 15px;
  }

  .topic a {
    color: #333333;
  }

  .topic a:hover {
    text-decoration: underline;
  }

  a.anchor {
    display: block;
    position: relative;
    top: -150px;
    visibility: hidden;
  }

  .sidebar::-webkit-scrollbar {
    width: 8px;
    /* width of the entire scrollbar */
  }

  .sidebar::-webkit-scrollbar-track {
    background: beige;
    /* color of the tracking area */
  }

  .sidebar::-webkit-scrollbar-thumb {
    background-color: #c8dce3;
    /* color of the scroll thumb */
    /* roundness of the scroll thumb */
    border: 3px solid #c8dce3;
    /* creates padding around scroll thumb */
  }
</style>

<div class="sidebar">
  <div class="core">Software developmental fundamentals</div>
  <div class="topic"><a href="#algorithm_design">Algorithms and design</a></div>
  <div class="topic"><a href="#fundamental_programming">Fundamental programming concepts</a></div>
  <div class="topic"><a href="#fundamental_data">Fundamental data structures</a></div>
  <div class="topic"><a href="#development_methods">Development methods</a></div>
  <div class="core">Discrete structures</div>
  <div class="topic"><a href="#sets">Sets, relations, and functions</a></div>
  <div class="topic"><a href="#sets">Basic logic</a></div>
  <div class="topic"><a href="#sets">Proof techniques</a></div>
  <div class="topic"><a href="#sets">Basics of counting</a></div>
  <div class="topic"><a href="#sets">Graphs and trees</a></div>
  <div class="topic"><a href="#sets">Discrete probability</a></div>
  <div class="core">Algorithms and complexity</div>
  <div class="topic"><a href="#sets">Basic analysis</a></div>
  <div class="topic"><a href="#sets">Algorithmic strategies</a></div>
  <div class="topic"><a href="#sets">Fundamental data structures and algorithms</a></div>
  <div class="topic"><a href="#sets">Basic automata, computability and complexity</a></div>
  <div class="topic"><a href="#sets">Advanced computational complexity</a></div>
  <div class="topic"><a href="#sets">Advanced automata theory and computability</a></div>
  <div class="topic"><a href="#sets">Advanced data structures, algorithms, and analysis</a></div>
  <div class="core">Software engineering</div>
  <div class="topic"><a href="#software_requirements">Software requirements</a></div>
  <div class="topic"><a href="#software_design">Software design</a></div>
  <div class="topic"><a href="#software_construction">Software construction</a></div>
  <div class="topic"><a href="#software_testing">Software testing</a></div>
  <div class="topic"><a href="#software_maintenance">Software maintenance</a></div>
  <div class="topic"><a href="#software_configuration_management">Software configuration management</a></div>
  <div class="topic"><a href="#software_engineering_management">Software engineering management</a></div>
  <div class="topic"><a href="#software_engineering_process">Software engineering process</a></div>
  <div class="topic"><a href="#software_engineering_models_and_methods">Software engineering models and methods</a>
  </div>
  <div class="topic"><a href="#software_quality">Software quality</a></div>
  <div class="topic"><a href="#software_engineering_professional_practice">Software engineering professional
      practice</a>
  </div>
  <div class="topic"><a href="#software_engineering_economics">Software engineering economics</a></div>
  <div class="topic"><a href="#computing_foundations">Computing foundations</a></div>
  <div class="topic"><a href="#mathematical_foundations">Mathematical foundations</a></div>
  <div class="topic"><a href="#engineering_foundations">Engineering foundations</a></div>
  <div class="core">Systems fundamentals</div>
  <div class="topic"><a href="#sets">Computational paradigms</a></div>
  <div class="topic"><a href="#sets">Cross-layer communications</a></div>
  <div class="topic"><a href="#sets">State and state machines</a></div>
  <div class="topic"><a href="#sets">Parallelism</a></div>
  <div class="topic"><a href="#sets">Evaluation</a></div>
  <div class="topic"><a href="#sets">Resource allocation and scheduling</a></div>
  <div class="topic"><a href="#sets">Proximity</a></div>
  <div class="topic"><a href="#sets">Virtualization and isolation</a></div>
  <div class="topic"><a href="#sets">Reliability through redundancy</a></div>
  <div class="topic"><a href="#sets">Quantitative evaluation</a></div>
  <div class="core">Architecture and organization</div>
  <div class="topic"><a href="#sets">Digital logic and digital systems</a></div>
  <div class="topic"><a href="#sets">Machine level representation of data</a></div>
  <div class="topic"><a href="#sets">Assembly level machine organization</a></div>
  <div class="topic"><a href="#sets">Memory system organization and architecture</a></div>
  <div class="topic"><a href="#sets">Interfacing and communication</a></div>
  <div class="topic"><a href="#sets">Functional organization</a></div>
  <div class="topic"><a href="#sets">Multiprocessing and alternative architectures</a></div>
  <div class="topic"><a href="#sets">Performance enhancements</a></div>
  <div class="core">Computational science</div>
  <div class="topic"><a href="#sets">Introduction to modeling and simulation</a></div>
  <div class="topic"><a href="#sets">Modeling and simulation</a></div>
  <div class="topic"><a href="#sets">Processing</a></div>
  <div class="topic"><a href="#sets">Interactive visualization</a></div>
  <div class="topic"><a href="#sets">Data, information, and knowledge</a></div>
  <div class="topic"><a href="#sets">Numerical analysis</a></div>
  <div class="core">Graphics and visualization</div>
  <div class="topic"><a href="#sets">Fundamental concepts</a></div>
  <div class="topic"><a href="#sets">Basic rendering</a></div>
  <div class="topic"><a href="#sets">Geometric modeling</a></div>
  <div class="topic"><a href="#sets">Advanced rendering</a></div>
  <div class="topic"><a href="#sets">Computer animation</a></div>
  <div class="topic"><a href="#sets">Visualization</a></div>
  <div class="core">Human-computer interaction</div>
  <div class="topic"><a href="#sets">Foundations</a></div>
  <div class="topic"><a href="#sets">Designing interaction</a></div>
  <div class="topic"><a href="#sets">Programming interactive systems</a></div>
  <div class="topic"><a href="#sets">User-centered design & testing</a></div>
  <div class="topic"><a href="#sets">New interactive technologies</a></div>
  <div class="topic"><a href="#sets">Collaboration & communication</a></div>
  <div class="topic"><a href="#sets">Statistical methods for HCI</a></div>
  <div class="topic"><a href="#sets">Human factors & security</a></div>
  <div class="topic"><a href="#sets">Design-oriented HCI</a></div>
  <div class="topic"><a href="#sets">Mixed, augmented and virtual reality</a></div>
  <div class="core">Information assurance and security</div>
  <div class="topic"><a href="#sets">Foundational concepts in security</a></div>
  <div class="topic"><a href="#sets">Principles of secure design</a></div>
  <div class="topic"><a href="#sets">Defensive programming</a></div>
  <div class="topic"><a href="#sets">Threats and attacks</a></div>
  <div class="topic"><a href="#sets">Network security</a></div>
  <div class="topic"><a href="#sets">Cryptography</a></div>
  <div class="topic"><a href="#sets">Web security</a></div>
  <div class="topic"><a href="#sets">Platform security</a></div>
  <div class="topic"><a href="#sets">Security policy and governance</a></div>
  <div class="topic"><a href="#sets">Digital forensics</a></div>
  <div class="topic"><a href="#sets">Secure software engineering</a></div>
  <div class="core">Information management</div>
  <div class="topic"><a href="#sets">Information management concepts</a></div>
  <div class="topic"><a href="#sets">Database systems</a></div>
  <div class="topic"><a href="#sets">Data modeling</a></div>
  <div class="topic"><a href="#sets">Indexing</a></div>
  <div class="topic"><a href="#sets">Relational databases</a></div>
  <div class="topic"><a href="#sets">Query languages</a></div>
  <div class="topic"><a href="#sets">Transaction processing</a></div>
  <div class="topic"><a href="#sets">Distributed databases</a></div>
  <div class="topic"><a href="#sets">Physical database design</a></div>
  <div class="topic"><a href="#sets">Data mining</a></div>
  <div class="topic"><a href="#sets">Information storage and retrieval</a></div>
  <div class="topic"><a href="#sets">Multimedia systems</a></div>
  <div class="core">Intelligent systems</div>
  <div class="topic"><a href="#sets">Fundamental issues</a></div>
  <div class="topic"><a href="#sets">Basic search strategies</a></div>
  <div class="topic"><a href="#sets">Basic knowledge representation and reasoning</a></div>
  <div class="topic"><a href="#sets">Basic machine learning</a></div>
  <div class="topic"><a href="#sets">Advanced search</a></div>
  <div class="topic"><a href="#sets">Advanced representation and reasoning</a></div>
  <div class="topic"><a href="#sets">Reasoning under uncertainty</a></div>
  <div class="topic"><a href="#sets">Agents</a></div>
  <div class="topic"><a href="#sets">Natural language processing</a></div>
  <div class="topic"><a href="#sets">Advanced machine learning</a></div>
  <div class="topic"><a href="#sets">Robotics</a></div>
  <div class="topic"><a href="#sets">Perception and computer vision</a></div>
  <div class="core">Networking and communication</div>
  <div class="topic"><a href="#sets">Introduction</a></div>
  <div class="topic"><a href="#sets">Networked applications</a></div>
  <div class="topic"><a href="#sets">Reliable data delivery</a></div>
  <div class="topic"><a href="#sets">Routing and forwarding</a></div>
  <div class="topic"><a href="#sets">Local area networks</a></div>
  <div class="topic"><a href="#sets">Resource allocation</a></div>
  <div class="topic"><a href="#sets">Mobility</a></div>
  <div class="topic"><a href="#sets">Social networking</a></div>
  <div class="core">Operating systems</div>
  <div class="topic"><a href="#overview_operating">Overview of operating systems</a></div>
  <div class="topic"><a href="#sets">Operating system principles</a></div>
  <div class="topic"><a href="#sets">Concurrency</a></div>
  <div class="topic"><a href="#sets">Scheduling and dispatch</a></div>
  <div class="topic"><a href="#sets">Memory management</a></div>
  <div class="topic"><a href="#sets">Security and protection</a></div>
  <div class="topic"><a href="#sets">Virtual machines</a></div>
  <div class="topic"><a href="#sets">Device management</a></div>
  <div class="topic"><a href="#sets">File systems</a></div>
  <div class="topic"><a href="#sets">Real time and embedded systems</a></div>
  <div class="topic"><a href="#sets">Fault tolerance</a></div>
  <div class="topic"><a href="#sets">System performance evaluation</a></div>
  <div class="core">Platform-based development</div>
  <div class="topic"><a href="#sets">Introduction</a></div>
  <div class="topic"><a href="#sets">Web platforms</a></div>
  <div class="topic"><a href="#sets">Mobile platforms</a></div>
  <div class="topic"><a href="#sets">Industrial platforms</a></div>
  <div class="topic"><a href="#sets">Game platforms</a></div>
  <div class="core">Parallel and distributed computing</div>
  <div class="topic"><a href="#sets">Parallelism fundamentals</a></div>
  <div class="topic"><a href="#sets">Parallel decomposition</a></div>
  <div class="topic"><a href="#sets">Communciation and coordination</a></div>
  <div class="topic"><a href="#sets">Parallel algorithm, analysis, and programming</a></div>
  <div class="topic"><a href="#sets">Parallel architecture</a></div>
  <div class="topic"><a href="#sets">Parallel performance</a></div>
  <div class="topic"><a href="#sets">Distributed systems</a></div>
  <div class="topic"><a href="#sets">Cloud computing</a></div>
  <div class="topic"><a href="#sets">Formal models and semantics</a></div>
  <div class="core">Programming languages</div>
  <div class="topic"><a href="#sets">Object-oriented programming</a></div>
  <div class="topic"><a href="#sets">Functional programming</a></div>
  <div class="topic"><a href="#sets">Event-driven and reactive programming</a></div>
  <div class="topic"><a href="#sets">Basic type systems</a></div>
  <div class="topic"><a href="#sets">Program representation</a></div>
  <div class="topic"><a href="#sets">Language translation and execution</a></div>
  <div class="topic"><a href="#sets">Syntax analysis</a></div>
  <div class="topic"><a href="#sets">Compiler semantic analysis</a></div>
  <div class="topic"><a href="#sets">Code generation</a></div>
  <div class="topic"><a href="#sets">Runtime systems</a></div>
  <div class="topic"><a href="#sets">Static analysis</a></div>
  <div class="topic"><a href="#sets">Advanced programming constructs</a></div>
  <div class="topic"><a href="#sets">Concurrency and parallelism</a></div>
  <div class="topic"><a href="#sets">Type systems</a></div>
  <div class="topic"><a href="#sets">Formal semantics</a></div>
  <div class="topic"><a href="#sets">Language pragmatics</a></div>
  <div class="topic"><a href="#sets">Logic programming</a></div>
  <div class="core">Social issues and professional practice</div>
  <div class="topic"><a href="#sets">Social context</a></div>
  <div class="topic"><a href="#sets">Analytical tools</a></div>
  <div class="topic"><a href="#sets">Professional ethics</a></div>
  <div class="topic"><a href="#sets">Intellectual property</a></div>
  <div class="topic"><a href="#sets">Privacy and civil liberties</a></div>
  <div class="topic"><a href="#sets">Professional communication</a></div>
  <div class="topic"><a href="#sets">Sustainability</a></div>
  <div class="topic"><a href="#sets">History</a></div>
  <div class="topic"><a href="#sets">Economies of computing</a></div>
  <div class="topic"><a href="#sets">Security policies, laws and computer crimes</a></div>
</div>
SWEBOK v3
<div class="first">Software requirements</div><a class="anchor" id="software_requirements"></a>
<div class="second">Software requirements fundamentals</div>
<p>Software engineering is the application of a systematic, disciplined, quantifiable approach to the development,
  operation, and maintenance of software; that is, the application of engineering to software.</p>
<div class="third">Definition of a software requirement</div>
<p>At its most basic, a software requirement is a property that must be exhibited by something in order to solve some
  problem in the real world. An essential property of all software requirements it that they be verifiable as an
  individual feature as a functional requirement or at the system level as a nonfunctional requirement. Requirements
  have other attributes, such as priority ratings to enable tradeoffs in face of finite resources and a status value to
  enable project progress to be monitored. Software projects are critically vulnerable when the requirements-related
  activities are poorly performed. Software
  requirements express the needs and constraints placed on a software product that contribute to the solution of some
  real-world problem. The term "requirements engineering" denotes the systematic handling of requirements.</p>
<div class="third">Product and process requirements</div>
<p>A product requirement is a need or constraint on the software to be developed. A process requirement is essentially a
  constraint on the developt of the software.</p>
<div class="third">Functional and nonfunctional requirements</div>
<p>Functional requirements describe the functions that the software is to execute, also known as capabilities or
  features. A functional requirement can also be described as one for which a finite set of test steps can be written to
  validate its behavior. Nonfunctional requirements are ones that act to constrain the solution, also known as
  constraints or quality requirements. Examples of nonfunctional requirements are performance requirements,
  maintainability requirements, safety, reliability, security, interoperability, etc.</p>
<div class="third">Emergent properties</div>
<p>Emergent properties are requirements that cannot be addressed by a single component but that depend on how all the
  software components interoperate. Emergent properties are crucially dependent on system architecture.</p>
<div class="third">Quantifiable requirements</div>
<p>Software requirements should be stated as clearly and as unambiguously as possible, and, where appropriate,
  quantitatively. This is particularly important for nonfunctional requirements.</p>
<div class="third">System requirements and software requirements</div>
<p>A "system" means an interacting combination of elements to accomplish a defined objective, including hardware,
  software, firmware, people, information, techniques, facilities, services, and other support elements. System
  requirements are the requirements for the system as a whole. Software requirements are derived from system
  requirements. User requirements are the requirements of the system's customers or end users.</p>
<div class="second">Requirements process</div>
<div class="third">Process models</div>
<p>The requirements process is not a discrete front-end activity of the software life cycle, but rather a process
  initiated at the beginning of a project that continues to be refined throughout the life cycle. Software requirements
  are configuration items and are managed using the same software configuratoin management practices as other products
  of the softawre life cycle processes. Requirements need to be adapted to the organizations and project context.</p>
<div class="third">Process actors</div>
<p>The requirements process is fundamentally interdisciplinary, and the requirements specialist needs to mediate between
  the domain of the stakeholder and that of software engineering. THe stakeholders will vary across projects, but will
  always include users/operators and customers. Examples of software stakeholders include users (those who use the
  software), customers (those who have commissioned the software), market analysts (marketing people who establish what
  the market needs are and who act as proxy customers), regulators (regulatory authorities such as for applications in
  banking and public transport), and software engineers (constraints can have major impact on project cost or delivery
  if they fit poorly with the skillset of the engineers). It is the job of the softawre engineer to negotiate tradeoffs
  acceptable to principal stakeholders within budgetary, technical, regulatory, and other constraints. A prerequisite
  for this is that all the stakeholders be identified, the nature of their "stake" analyzed, and their requirements
  elicited.</p>
<div class="third">Process support and management</div>
<div class="third">Process quality and improvement</div>
<div class="second">Requirements elictation</div>
<p>Requirements elictation, or requirements capture, or requirements discovery, or requirements acquisition is concerned
  with the origins of software requirements and how the software engineer can
  collect them. One of the fundamental principles of a good requirements elictation process is that of effective
  communication between various stakeholders, continuing through the entire Software Development Life Cycle (SDLC)
  process with different stakeholders at different points in time. A critical element of requirements elictation is
  informing the project scope, which involves providing a description of the software being specified and its purpose
  and prioritizing the deliverables to ensure the customer's most important business needs are satisfied first.</p>
<div class="third">Requirements sources</div>
<p>Goals: the term goal or business concern or critical success factor refers to the overall, high-level objectives of
  the software. Goals provide the motivation for the software but are often vaguely formulated. A feasibility study is a
  relatively low-cost way of assessing value and cost of goals.</p>
<p>Domain knowledge: the software engineer needs to acquire or have available knowledge about the application domain.
  Domain knowledge provides the background against which all elicited requirements knowledge must be set in ordre to
  understand it.</p>
<p>Stakeholders: the software engineer needs to identify, represent, and manage the "viewpoints" of many different types
  of stakeholders.</p>
<p>Business rules: there are statements that define or constrain some aspect of the structure or the behavior of the
  business itself.</p>
<p>The operational environment: requirements will be derived fro mthe environment in which the software will be executed
  (eg. real-time software or performance constraints in a business environment).</p>
<p>The organizational environment: software is often required to support a business process. In general, new software
  should not force unplanned change on the business process.</p>
<div class="third">Elictation techniques</div>
<p>Software engineer must be sensitized to the fact that users may have difficulty describing their tasks, may leave
  important information unstated, or may be unwilling or unable to cooperate. Elicitation is not a passive activity. A
  number of techniques exist:</p>
<p>Inteviews: interviewing stakeholders is a traditional means of eliciting requirements.</p>
<p>Scenarios: scenarios provide context. The most common type of secnario is the use case description.</p>
<p>Prototypes: helps clarify ambiguous requirements. Act similar to scenarios. There is a wide range of prototyping
  techniques, from paper mockups of screen designs to beta-test versions of software products. Low fidelity prototypes
  are often preferred to avoid stakeholder "anchoring" on minor, incidental characteristics of a higher quality
  prorotype.</p>
<p>Facilitated meetings: acheive a summative effect, whereby a group of people can bring more insight into their
  software requirements than by working individually. Allow conflicting requirements surface early.</p>
<p>Observation: observational techniques such as ethnography (study of cultures) can be expensive but also instructive.
</p>
<p>User stories: commonly used in adaptive methods and refers to short, high-level descriptions of required
  functionality expressed in customer terms.</p>
<div class="second">Requirements analysis</div>
<div class="third">Requirements classification</div>
<p>Is the requirement function or nonfunctional? Is the requirement derived from one or more high-level requirements or
  an emergent property, or is being imposed directly on the software by a stakeholder or some other source? Is the
  requirement on the product or the process? What's the priority of the requirement? What's the scope of the requirement
  (extent to which a requirmeent affects the software and its components)? What's the volatility/stability of the
  requirement?</p>
<div class="third">Conceptual modeling</div>
<p>Models aid in understanding the situation in which the problem occurs, as well as helps depict a solution. Many
  modeling notations are part of the United Modeling Language (UML). The factors that influence the choice of modeling
  notation includes 1) the nature of the problem, 2) the expertise of the softawre engineer, 3) the process
  requirements.</p>
<div class="third">Architectural design and requirements allocation</div>
<p>Architectural design is the point at which the requirements process overlaps with software or systems design.</p>
<div class="third">Requirements negotation</div>
<p>Another term commonly used for this is conflict resolution. In most cases it is unwise for the software engineer to
  make a unilateral decision. It is often important for contractual reasons that such decisions be traeable back to the
  customer. Requirements prioritization is necessary, not only as a means to filter important requirements, but also in
  order to resolve conflicts and plan for staged deliveries, which means making complex decisions that require detailed
  domain knowledge and good estimation skills. In practice, software engineers perform requirement prioritization
  frequently without knowing about all the requirements.</p>
<div class="third">Formal analysis</div>
<p>Formal analysis has made an impact on some application domains, especially high-integrity systems. The formal
  expression of requirements requires a language with formally defined semantics. Formal analysis allows requirements to
  be expressed precisely and unambiguously, and allow them to be reasoned over, permitting desired properties of the
  specified software to be proven. Formal reasoning requires tool support, which fall into theorem provers or model
  checkers. In neither case can proof be full yautomated, and the level of competence in formal reasoning in order to
  use the tools restricts the wider application of formal analysis. It is generally counterproductive to apply
  formalization until the business goals and user requirements have come into sharp focus. Once the requirements have
  been stabilized and have been elaborated to specify concrete properties of the software, it may be beneficial to
  formalize at least the critical requirements.</p>
<div class="second">Requirements specification</div>
<p>The term specification refers to the assignment of numerical values or limits to a product's design goals. In
  software engineering, this typically refers to the production of a document that can be systematically reviewed,
  evaluated, and approved. For complex systems, this may include system definition, system requirements, and software
  requirements.</p>
<div class="third">System definition document</div>
<p>Also known as the user requirements document or concept of operations document, the system definition document
  records the system requirements. It defines the high-level system requirements from the domain perspective. Its
  readership includes representatives of the system users/customers (eg. marketing for market-driven software). The
  document lists the system requirements along with background information about the overall objectives for the system,
  its target environment, and a statement of the constraints, assumptions, and nonfunctional requirements. It may
  include conceptual models designed to illustrate the system context, usage scenarios, and the principal domain
  entities, as well as workflows.</p>
<div class="third">System requirements specification</div>
<p>System requirements specification is a systems engineering activity and falls outside the scope of software
  engineering.</p>
<div class="third">Software requirements specification</div>
<p>Software requirements specification establishes the basis for agreement between customers and contractors or
  suppliers on what the software product is to do as well as what it is not expected to do. Software requirements
  specification permits a rigorous assessment of requirements before design can begin and reduces later redesign. It
  also provides a realistic basis for estimating product costs, risks, and schedules. Software requirements are often
  written in natural language, but may be supplemented by formal or semiformal descriptions. The general rule is that
  notations should be used that allow the requirements to be described as precisely as possible.</p>
<p>Quality indicators for individual software requirements specification statements include imperatives, directives,
  weak phrases, options, and continuances. Indicators for the entire software requirements specification document
  include size, readability, specification, depth, and text structure.</p>
<div class="second">Requirements validation</div>
<p>The requirements documents may be subject to validation and vertification procedures. This ensures that the software
  engineer has understood the requirements and veritifes that a requirements document conforms to company standards and
  that it is understandable, consistent, and complete.</p>
<p>Formal notations offer the important advantage of these properties to be proven (in a restricted sense, at least).
  Different stakeholders should review the documents. Requirements documents are subject to the same configuration
  management practices as the other dleiverables of the software life cycle processes. Requirements validation is
  concerned with the process of examining the requirements document to ensure that it defines the right software.</p>
<div class="third">Requirements reviews</div>
<p>Perhaps the most common means of validation is by inspection or reviews of the requirements documents. A group of
  reviewers is assigned a brief to look for errors, mistaken assumptions, lack of clarity, and deviation from standard
  practice.</p>
<div class="third">Prototyping</div>
<p>Prototyping is commonly a means for validating the software engineer's interpretation of the software requirements,
  as well as for eliciting new requirements. The advantage of prototypes is they can make it easier to interpret the
  software engineer's assumptions and give useful feedback on why they are wrong. Disadvantages to prototyping include
  distraction of users' attention from core underlying functionaly towards quality or cosmetic problems. For this
  reason, some advocate prototypes that avoid software, such as flip-chart-based mockups. Prototypes may be costly to
  develop, but can avoid the wastage of resources caused by trying to satisfy erroneous requirements.</p>
<div class="third">Model validation</div>
<p>It is typically necessary to validate the quality of the models developed during analysis.</p>
<div class="third">Acceptance tests</div>
<p>An essential property of a software requirement is that it should be possible to validate that the finished product
  satisfies it. Requirements that cannot be validated are really just "wishes." An important task is therefore planning
  how to verify each requirement. In most cases, designing acceptance tests does this for how end-users typically
  conduct business using the system. Identifying and designing acceptance tests may be difficult for nonfunctional
  requirements. To be validated, they must first be analyzed and decomposed to the point where they can be expressed
  quantitatively.</p>
<div class="second">Practical considerations</div>
<p>The requirements process spans the whole software life cycle. Change management and the maintenance of the
  requirements in a state that accurately mirrors the software to be built, or that has been built, are key to the
  success of the software engineering process. Not every organization has a culture of documenting and managing
  requirements (common in dynamic start-up companies). Most often, however, as these companies expand, as their customer
  base grows, they discover they need to recover the requirements that motivated product features in order to assess the
  impact of proposed changes. Requirements documentation and change management are key.</p>
<div class="third">Iterative nature of the requirements process</div>
<p>There is general pressure in the softare industry for ever shorter development cycles, which is particularly
  pronounced in highly competitive, market-driven sectors. Most projects are constrained in some way by their
  environment, and many are upgrades to, or revisions of, existing software where the architecture is given. In
  practice, therefore, it is almost always impractical to implement the requirements process as a linear, deterministic
  process in which software requirements are elicited from the stakeholders, baselined, allocated, and handed over to
  the software development team. It is certainly a myth that the requirements for large software projects are ever
  perfectly understood or perfectly specified.</p>
<p>For software products that develop iteratively, a project team may baseline only those requirements needed for the
  current iteration. The requirements specialist can continue to develop requirements for future iterations, while
  developers proceed with design and construction of the current iteration. This approach provides customers with
  business value quickly while minimizing the cost of rework. Perhaps the most crucial point in understanding software
  requirements is that a significant proportion of the requirements WILL change. This can be due to errors in the
  analysis or change in the environment, eg. customer's operating or business environment, regulatory processes imposed
  by authorities, or market into which software must sell. Change has to be managed by ensuring that proposed changes go
  thorugh a defined review and approval process and by applying careful requirements tracing, impact analysis, and
  software configuration management.</p>
<div class="third">Change management</div>
<div class="third">Requirements attributes</div>
<p>Requirements should consist not only of a specification of what is required, but also of ancillary information, which
  helps manage and interpret the requirements. Requirements attributes must be defined, recorded, and updated as the
  software under development or maintenance evolves. This should include the various classification dimensions of the
  requirement and the verification method or relevant acceptance test plan section It may also include additional
  information, such as a summary rationale for each requirement, the source of each requirement, and a change history.
  The most important requirements attribute is an identifier that allows the requirements to be uniquely and
  unambiguously identifeid.</p>
<div class="third">Requirements tracing</div>
<p>Requirements tracing is concerned with recovering the source of requirements and predicting the effects of
  requirements. Tracing is fundamental to performing impact analysis when requirements change. A requirement should be
  traceable backward to the reuqirements and stakeholders that motivated it. Conversely, a requirement should be
  traceable forward into the reuqirements and design entities that satisfy it (eg. on the code modules tha timplement it
  or the test cases related to that code or even the given section on the user manual which describes the actual
  functionality).</p>
<p>The requirements tracing for a typical project will form a complex directed acyclic graph (DAG). Maintaining an
  up-to-date graph or traceability matrix is an activity that must be considered during the whole life cycle of a
  product.</p>
<div class="third">Measuring requirements</div>
<p>Functionalize size measurement (FSM) is a technique for evaluating the size of a body of functional requirements.</p>
<div class="second">Software requirements tools</div>
<p>Tools for dealing with software requirements fall into tools for modeling and tools for managing requirements.
  Requirements management tools usually support documentation, tracing, and change management. Many organizations have
  invested in requirements management tools, although many more manage their requirements in more ad hoc and generally
  less satisfactory ways (eg. using spreadsheets).</p>
<div class="first">Software design</div><a class="anchor" id="software_design"></a>
<p>Design is defined as both "the process of defining the architecture, components, interfaces, and other
  characteristics of a system or component" and "the result of that process." Viewed as a process, software design is
  the software engineering life cycle activity in which software requirements are analyzed in order to produce a
  description of the software's internal structure that will serve as the basis for its construction. A software design
  describes the software architecture-that is, how the softawre is decomposed and organized into components-and the
  interfaces between those components. It also describes the components at a level of detail that enables their
  construction.</p>
<div class="second">Software design fundamentals</div>
<div class="third">General design concepts</div>
<p>Design can be viewed as a form of problem solving. The concept of a wicked problem-a problem with no definitive
  solution- is interesting in understanding the limits of design. Goals, constraints, alternatives, representations, and
  solutions are of interest in understanding design in its general sense.</p>
<div class="third">Context of software design</div>
<div class="third">Software design process</div>
<p>Software design is generally a two step process: architectural design (high-level or top-level design) that describes
  how software is organized into components, and detailed design that describes the desired behavior of these
  components. The output of these two processes is a set of models and artifacts that record the major decisions that
  have been taken, along with an explanation of the rationale for each nontrivial decision.</p>
<div class="third">Software design principles</div>
<p>A principle is a comprehensive and fundamental law, doctrine, or assumption. Software design principles include
  abstraction; coupling and cohesion; decomposition and modularization; encapsulation/information hiding; separation of
  interface and implementation; sufficiency, completeness, and primitiveness; and separation of concerns.</p>
<p>Abstraction is a view of an object that focuses on the information relevant to a particular purpose and ignores the
  remainder of the information. Two key abstraction mechanisms are parametrization and specification. Parametrization
  abstracts from the details of data representations by representing the data as named parameters. Abstraction by
  specification leads to procedural abstraction, data abstraction, and control (iteration) abstraction.</p>
<p>Coupling is defined as a measure of the interdependence among modules in a computer program and cohesion is the
  measure of the strength of association of the elements within a module.</p>
<p>Decomposing and modularizing means that large software is divided into a number of smaller named components having
  well-defined interfaces that describe component interactions. Usually the goal is to place different functionalities
  and responsibilities in different components.</p>
<p>Encapsulation and information hiding is grouping and packaging the internal details of an abstraction and making
  those details inaccessible to external entities.
</p>
<p>The separation of interface and implementation defines a component by specifying a public interface (known to
  clients) that is separate from the details of how the
  component is realized.</p>
<p>Sufficiency and completeness ensures that a software component captures all the important characteristics of an
  abstraction and nothing more.
  Primitiveness means the design should be based on patterns that are easy to implement.</p>
<p>A concern is an "area of interest with respect to a software design." A design concern is an area of design that is
  relevant to one or more of its stakeholders. Separating concerns by views allows stakeholders to focus on a few things
  at a time and offers a means of managing complexity.</p>
<div class="second">Key issues in software design</div>
<p>Key issues include performance, security, reliability, usability, and how to decompose, organize, and package
  software components. Non-key issues that deal with some aspect of software's behavior that is not in the application
  domain but which addresses some of the supporting domains, are sometimes referred to as aspects.</p>
<div class="third">Concurrency</div>
<p>Design for concurrency is concerned with decomposing software into processes, tasks, and threads and dealing with
  related issues of efficiency, atomicity, synchronization, and scheduling.</p>
<div class="third">Control and handling of events</div>
<p>This is concerned with how to organize data and control flow and how to handle reactive and temporal events through
  various mechanisms such as implicit invocation and call-backs.</p>
<div class="third">Data persistence</div>
<p>Handles long-lived data.</p>
<div class="third">Distribution of components</div>
<p>This design issue is concerned with how to distribute the software across the hardware, how the components
  communicate, and how middleware can be used to deal with heterogeneous software.</p>
<div class="third">Error and exception handling and fault tolerance</div>
<p>How to prevent, tolerate, and process errors and deal with exceptional conditions.</p>
<div class="third">Interaction and presentation</div>
<p>Concerned with how to structure and organize interactions with users as well as the presentation of information (eg.
  separation of presentation and business logic using Model-View-Controller approach). Note that this does not specify
  user interface details, which is the task of user interface design.</p>
<div class="third">Security</div>
<p>How to prevent unauthorized disclosure, creation, change, deletion, or denial of access to information and other
  resources. Also concerned with how to tolerate security-related attacks or violations by limiting damage, continuing
  service, speeding repair and recovery, and failing and recovering securely. Access control is a fundamental concept of
  security, and one should also ensure the proper use of cryptology.</p>
<div class="second">Software structure and architecture</div>
<p>A software architecture is "the set of structures needed to reason about the system, which comprise software
  elements, relations among them, and properties of both." These design concepts can be used to design families of
  programs (ie. product lines). These are attempts to describe and thus reuse, design knowledge.</p>
<div class="third">Architectural structures and viewpoints</div>
<p>A view represents a partial aspect of a software architecture athat shows specific properties of a software system.
  Views pertain to distinct issues associated with software design. For example, the logical view (satisfying the
  functional requirements) vs. the process view (concurrency issues) vs. the physical view (distribution issues) vs. the
  development view (how the design is broken down into implementation units with explicit representatio nof the
  dependencies among the units).</p>
<div class="third">Architectural styles</div>
<p>An architectural style is a specialization of element and relation types, together with a set of constraints on how
  they can be used, or a provision of the software's high-level organization. Examples are general structures,
  distributed systems, interactive systems, and adaptable systems.</p>
<div class="third">Design patterns</div>
<p>A pattern is a common solution to a common problem in a given context, and design patterns are used to describe
  details at a lower level than architectural styles. These lower level design patterns include creational patterns (eg.
  builder, factory, prototype, singleton), structural patterns (eg. adapter, bridge, composite, decorator, facade,
  fly-weight, proxy), and behavioral patterns (eg. interpreter, iterator, mediator, memento, observer, state, strategy,
  template, visitor).</p>
<div class="third">Architecture design decisions</div>
<p>Architectural deisgn is a creative process. It is useful to think of the architectural design process from a
  decision-making perspective than from an activity perspective.</p>
<div class="third">Families of programs and frameworks</div>
<p>Software product lines can identify commonalities among members and design reusable and customizable components to
  account for variability among family membersn. In object-oriented (OO) programming, a key related notion is that of a
  framework: a partially completed software system that can be extended by appropriately instantiating specific
  extensions, such as plug-ins.</p>
<div class="second">User interface design</div>
<div class="third">General user interface design principles</div>
<p>User interface design should ensure that interaction between the human and the machine provides for effective
  operation and control of the machine. The user interface should be designed to match the skills, experience, and
  expectations of its anticipated users. This includes learnability (easy to learn), user familiarity (should use terms
  and concepts drawn from the experiences of people who will use the software), consistency (comparable operations are
  activated in the same way), minimal surprise, recoverability (allow users to recover from errors), user guidance (give
  meaningful feedback when errors occur and provide context-related help), and user diversity (allow for diverse types
  of users, eg. blind, poor eyesight, deaf, colorblind, etc.).</p>
<div class="third">User interface design issues</div>
<p>How should the user interact with the software? How should information from the software be presented to the user?
</p>
<div class="third">The design of user interaction modalities</div>
<p>User interaction styles can be classified into the following primary styles: question-answer (user issues a question
  to the software, and the software returns the answer), direct manipulation (users interact with objects on the
  computer screen), menu selection (user selects a command from a menu list of commands), form fill-in (user fills in
  forms), command language (user issues a command and related parameters), and natural language (user issues a command
  in natural language which is parsed and translated into software commands).</p>
<div class="third">The deisgn of information presentation</div>
<p>Information presentation may be textual or graphical in nature. A good design keeps the information presentation
  separate from the information itself. The MVC approach is an efective way to keep information presentation separated
  from information being presented. Response time and feedback are also part of design of information presentation.
  Response time is generally measured from the point at which a user executes a certain control action until the
  software responds with a response. An indication of progress is desirable while the software is preparing the
  response. Feedback can be provided by restating the user's input while processing is being completed. Abstract
  visualizatoins can be used when large amounts of information are to be presented.</p>
<p>Designers can use color to enhance an interface: limit the number of colors used, use color change to show change of
  software status, use color-coding to support the user's task, use color-coding in a thoughtful and consistent way, use
  colors to facilitate access for people with color blindness/deficiency, don't depend on color alone to convey
  important information.</p>
<div class="third">User interface design process</div>
<p>The design process usually involves 1) user analysis (designer analyzes users' tasks and how users interact with
  other people, 2) software prototyping, and 3) interface evaluation.</p>
<div class="third">Localization and internationalization</div>
<p>User interface design often needs to consider internationalization and localization, which are means of adapting
  softawre to the different languages, regional differences, and the technical requirements of a target market.
  Internationalization is the process of designing a software application so that it can be adapted to various languages
  and regions without major engineering changes. Localization is the process of adapting internationalized software for
  a specific region or language by adding locale-specific components and translating the text. Localization and
  internationalization should consider factors such as symbols, numbers, currency, time, and measurement units.</p>
<div class="third">Metaphors and conceptual models</div>
<p>An example of a metaphor is an icon of a trash ca nas a metaphor for the operation delete. Metaphors present
  potential problems with respect to internationalization since not all metaphors are meaningful across cultures.</p>
<div class="second">Software design quality analysis and evaluation</div>
<div class="third">Quality attributes</div>
<p>There is a distinction between qualities discernable at runtmie (performance, security, availability, functionality,
  usability) and those that are not (modifiability, portability, reusability, testability), and those related to
  architecture's intrinsic qualities (eg. conceptual integrity, correctness, completeness).</p>
<div class="third">Quality analysis and evaluation techniques</div>
<p>Software design reviews are informal and formalized techniques to determine the quality of design artifacts. Static
  analysis are formal or semiformal static (nonexecutable) analysis that can be used to evaluate a design (eg.
  fault-tree analysis or automated cross-checking). Design vulnerability analysis can be performed if security is a
  concern. Formal design analysis uses mathematical models that allow designers to predicate the behavior and validate
  the performance of software instead of having to rely entirely on testing. Simulation and prototyping can help analyze
  quality.</p>
<div class="third">Measures</div>
<p>Measures can be classified as function-based (structured) which are obtained by analyzing functional decomposition,
  generally represented using a structure chart aka hierarchical diagram, and object-oriented design measures which are
  usually represented as a class diagram.</p>
<div class="second">Software design notations</div>
<div class="third">Structural descriptions (static view)</div>
<p>Mostly but not always graphical notations that describe and represent the structural aspects of a software
  design-that is, they are used to describe the major components and how they are interconnected: architecture
  description languages (ADLs) are textual, often formal, languages used to describe software architecture in terms of
  components and connectors, class and object diagrams are used to represent a set of classes and objects and their
  interrelationships, component diagrams represent a set of components (physical and replaceable parts of a system that
  conform to and provide the realization of a set of interfaces) and their interrelationships, class responsibility
  collaborator cards (CRCs) denote names, responsibilities, and collaborators of components, deployment diagrams
  represent a set of physical nodes and their relationships, entity-relationship diagrams (ERDs) represent conceptual
  models of data stored in information repositories, interface description languages (IDLs) are programming-like
  languages used to define interfaces of software components, and structure charts are used to describe the calling
  structure of programs.</p>
<div class="third">Behavioral descriptions (dynamic view)</div>
<p>Activity diagrams are used to show control flow from activity to activity. Communication diagrams show interactions
  that occur among a grou pof objects (emphasis on objects, their links, and the messages they exchange on those links).
  Data flow diagrams (DFDs) show data flow among elements and can be used for security analysis as they offer
  identification of possible paths for attack and disclosure of confidential information. Decision tables and diagrams
  represent complex combinations of conditions and ctions. Flowcharts represent the flow of control and the associated
  actions to be performed. Sequence diagrams show interactions among a group of objects, with emphasis on the time
  ordering of messages passed between objects. State transition and state chart diagrams show control flow from state to
  state and how the behavior of a component changes based on its current state in a state machine. Formal specification
  languages are textual languages that use basic notions from mathematics (eg. logic, set, sequence) to rigorously and
  abstractly define software component interfaces and behavior, often in terms of pre- and postconditions. Pseudo code
  and program design languages (PDLs) are structured programming-like languages used to describe the behavior of a
  procedure or method.</p>
<div class="second">Software design strategies and methods</div>
<div class="third">Genreal strategies</div>
<p>Divide-and-conquer and stepwise refinement strategies, top-down vs. bottom-up strategies, and strategies making use
  of heuristics, use of patterns and pattern languages, and use of an iterative and incremental approach.</p>
<div class="third">Function-oriented (structured) design</div>
<p>One of the classical methods of software design, where decomposition centers on identifying the major software
  functions and then elaborating and refining them in a hierarchical top-down manner.</p>
<div class="third">Object-oriented design</div>
<p>Noun = object; verb = method; adjective = attribute, where inheritance and polymorphism play a key role. This has
  evolved since to a field of component-based design, where metainformation can be defined and accessed.</p>
<div class="third">Data structure-centered design</div>
<p>Starts from data structures a program manipulates rather than from the function it performs. The software engineer
  first describes the input and output data structures and then develops the program's control structure based on these
  data structure diagrams.</p>
<div class="third">Component-based design (CBD)</div>
<p>A software component is an independent unit, having well-defined interfaces and dependencies that can be composed and
  deployed independently. Component-based design addresses issues related to providing, developing, and itnegrating such
  componnets in order to improve reuse. Components with a certain degree of trustworthiness should not depend on less
  trustworthy components.</p>
<div class="third">Other methods</div>
<p>Iterative and adaptive methods implement software increments and reduce emphasis on rigorous software requirement and
  design. Aspect-oriented design constructs software using aspects to implement the crosscutting concerns and extensions
  that are identified during the software requirement process. Service-oriented architecture builds distributed software
  using web services executed on distributed computers.</p>
<div class="second">Software design tools</div>
<p>Software design tools help translate requirements model into a design representation, provide support for
  representing functional components and their interfaces, implement heuristics refinement and partitioning, and provide
  guidleines for quality assessment.</p>

<div class="first">Software construction</div><a class="anchor" id="software_construction"></a>
<p>The term software construction refers to the detailed creation of working software through a combination of coding,
  verification, unit testing, integration testing, and debugging.</p>
<div class="second">Software construction fundamentals</div>
<div class="third">Minimizing complexity</div>
<p>Minimizing complexity is motivated by the fact that people are limited in their ability to hold complex structures
  and information in their working memory over long periods of time. Reduced complexity is achieved through emphasizing
  code creation that is simple and readable rather than clever. It is accomplished through use of standards, modular
  design, etc.</p>
<div class="third">Anticipating change</div>
<p>Anticipating change helps software engineers build extensible softawre, which means they can enhance a software
  product without disrupting the underlying structure.</p>
<div class="third">Constructing for verification</div>
<p>Constructing for verification means building software in such a way that faults can be readily found by the software
  engineers writing the software as well as by the testers and users during independent testing and operational
  activities. Specific techniques include following coding standards to support code reviews and unit testing,
  organizing code to support automated testing, and restricting the use of complex or hard-to-understand language
  structures.</p>
<div class="third">Reuse</div>
<p>Reuse refers to using existing assets in solving different problems. These typically include libraries, modules,
  components, source code, and commercial off-the-shelf (COTS) assets. "Construction for reuse" means to create reusable
  software assets, and "construction with reuse" means to reuse software assets in the construction of a new solution.
</p>
<div class="third">Standards in construction</div>
<p>Standards that directly affect construction issues include communication methods (eg. standards for document formats
  and contents), programming languages, coding standards (eg. standards for namign conventions, layouts, and
  indentation), platforms (eg. interface standards for operating system calls), and tools (eg. diagrammatic standards
  for notations like UML). Standards can be external or internal.</p>
<div class="second">Managing construction</div>
<div class="third">Construction in life cycle models</div>
<p>Waterfall and staged-delivery life cycle models treat construction as an activity that occurs only after significant
  prerequisite work has been completed, and emphasize the activities that precede construction (requirements and
  design). The main emphasis in these models may be coding.</p>
<p>Evolutionary prototyping and agile development are more iterative, and tend to treat construction as an activity that
  occurs concurrently with other software development activities. These approaches usually mix design, coding, and
  testing activities as all part of construction.</p>
<p>In general, software construction is mostly coding and debugging, but it also involves construction planning,
  detailed design, unit testing, integration testing, etc.</p>
<div class="third">Construction planning</div>
<p>The choice of construction method affects the extent to which construction prerequisites are performed, the order in
  which they are performed, and the degree to which they should be completed before construction work begins.
  Constructoin planning also defines the order in whcih the components are created and integrated, the integration
  strategy (eg. phased or incremental integration), the software quality management processes, the allocation of task
  assignments to specific software engineers, etc.</p>
<div class="third">Construction measurement</div>
<p>Construction activities and artifacts can be measured, eg. code developed, code modified, code reused, code
  destroyed, code complexity, code inspection statistics, fault-fix and fault-find rates, effort, and scheduling. These
  can be useful for managing construction.</p>
<div class="second">Practical considerations</div>
<div class="third">Construction design</div>
<p>Just as construction workers building a physical structure must make small-scale modifications to account for
  unanticipated gaps in the builder's plans, software construction workers must make modifications on a smaller or
  larger scale to flesh out details of software design during construction.</p>
<div class="third">Construction languages</div>
<p>Construction languages include all forms of communication by which a human can specify an executable problem solution
  to a problem. The simplest type of construction language is a configuration language, in which software engineers
  choose from a limited set of predefined options to create new or custom software installations. The text-based
  configuration files used in both the Windows and Unix operating systems are examples of this.</p>
<p>Toolkit languages are used to build applications out of elements in toolkits. Scripting languages are commonly used
  kinds of application programming languages, also called batch files or macros. Programming languages are the most
  flexible type of construction languages. They also contain the least amount of information about specific application
  areas and development processes, and so require the most training and skill to use effectively. The choice of
  programming language can have a large effect on the likelihood of vulnerabilities being introduced during coding.</p>
<p>There are three general kinds of notation used for programing languages. Linguistic notations (eg. C/C++, Java) use
  textual strings to represent complex software constructions and have a sentence-like syntax. Formal notations (eg.
  Event-B) rely less on intuitive, everyday meanings of words and text strings and more on definitions backed up by
  precise, unambiguous and formal (or mathematical) definitions. Formal construction are at the base of most forms of
  system programming notations, where accuracy, time behavior, and testability are more miportant than ease of mapping
  into natural language. Visual notations (eg. Matlab) rely on direct visual interpretation and placement of visual
  entities that represent the underlying software. Visual construction is limited by the difficulty of making "complex"
  statements using only the arrangement of icons on a display.</p>
<div class="third">Coding</div>
<p>Consider techniques for creating understandable source code (naming conventions, source code layout), use of classes,
  enumerated types, variables, named constants, use of control structures, handling of error conditions, prevention of
  code-level security breaches, resource usage via use of exclusion mechanisms and discipline in accessing serially
  reusable resources, source code organization, code documentation, and code tuning.</p>
<div class="third">Construction testing</div>
<p>Construction involves two forms of testing, often performed by the software engineers who wrote the code: unit
  testing and integration testing. The purpose is to reduce the gap between the time when faults are inserted and the
  time when those faults are detected. Test cases may be written before or after code is written.</p>
<div class="third">Construction for reuse</div>
<p>Construction for reuse creates software that has the potential to be reused in the future, usually based on
  variability analysis and design. To aovid the problem of code clones, it is desired to encapsulate reusable code
  fragments into well-structured libraries or components. The tasks related to reuse include variability implementation
  with mechanisms such as parameterization, conditional compilation, design patterns, etc., variability encapsulation to
  make the software assets easy to configure and customize, testing the variability provided by the reusable software
  assets, and description and publication of reusable software assets.</p>
<div class="third">Construction with reuse</div>
<p>Construction with reuse means to create new software with the reuse of existing software assets. The most popular
  method of reuse is to reuse code from the libraries provided by the language, platform, tools being used, or an
  organization repository. Tasks for construction with reuse include selection of reusable units, databases, test
  procedures, or test data, evaluation of code or test reusability, integration of reusable software assets into current
  software, and reporting of reuse information on new code, test procedures, or test data.</p>
<div class="third">Construction quality</div>
<p>The primary technique use for construction quality include unit testing and integration testing, test-first
  development, use of assertions and defensive programming, debugging, inspections, technical reviews, and static
  analysis. Programmers should know good practices and common vulnerabilities-for example, from widely recognized lists
  about common vulnerabilities. Automated static analysis of code for security weaknesses is available for several
  common programming languages.</p>
<div class="third">Integration</div>
<p>Concerns related to construction integration include planning the sequence in which components will be integrated,
  identifying what hardware is needed, creating scaffolding to support interim versions of the software, determining the
  degree of testing and quality work performed on components before they are integrated, and determining points in the
  project at which interim versions of the software are tested.</p>
<p>Programs can be integrated by either phased or incremental approach. Phased integration, also called "big bang"
  integration, delays integration until all parts are complete. Incremental integration involves writing and testing a
  program in small pieces and then combining the pieces one at a time. Stubs, drivers, and mock objects are usually
  needed to enable incremental integration.</p>
<div class="second">Construction technologies</div>
<div class="third">API design and use</div>
<p>An application programming interface (API) is the set of signatures that are exported and available to the users of a
  library or a framework to write their applications. Besides signatures, an API should always include statements about
  the program's effects and/or behaviors (i.e., its semantics). API design should try to make the API easy to learn and
  memorize, lead to readable code, be hard to misuse, be easy to extend, be complete, and maintain backward
  compatibility.</p>
<div class="third">Object-oriented runtime issues</div>
<p>Object-oriented languages support runtime mechanisms that increase flexibility and adaptability of object-oriented
  programs. Polymorphism is the ability of a language to support general operations without knowing until runtime what
  kind of concrete objects the software will include. Because the program does not know the exact type of objects in
  advance, the exact behavior is determined at runtime (called dynamic binding). Reflection is the ability of a program
  to observe and modify its own structure and behavior at runtime, allowing inspection of classes, interfaces, fields,
  and methods at runtime without knowing their names at compile time.</p>
<div class="third">Parameterization and generics</div>
<p>Parametrized types, also known as generics (Ada, Eiffel) and templates (C++), enable the definition of a type or
  class without specifying all the other types it uses. The unspecified types are supplied as parameters at the point of
  use. Parameterized types provide a third way (in addition to class inheritance and object composition) to compose
  behaviors in object-oriented software.</p>
<div class="third">Assertions, design by contract, and defensive programming</div>
<p>An assertion is an executable predicate that's placed in a program (usually a routine or macro) that allows runtime
  checks of the program. Assertions are normally compiled into the code at development time and are later compiled out
  of code so they don't degrade the performance. Design by contract is a development approach in which preconditions and
  postconditions are included for each routine. A contract provides a precise specification of the semantics of a
  routine. Defensive programming means to protect a routine from being broken by invalid inputs. Common ways are to
  check the values of all the input parameters and deciding how to handle bad inputs.</p>
<div class="third">Error handling, exception handling, and fault tolerance</div>
<p>Errors can be handled with assertions, returning a neutral value, substituting the next piece of valid data, logging
  a warning message, returning an error code, or shutting down. Exceptions detect and process errors or exceptional
  events. The basic structure of an exception is that a routine uses throws a detected exception and an exception
  handling block will catch the exception in a try-catch block. The try-catch block may process the erroneous condition
  or it may return control to the calling routine. Exception handling should be carefully designed following common
  principles such as including in the exception message all information that led to the exception, avoiding empty catch
  blocks, knowing the exceptions the library code throws, perhaps building a centralized exception reporter, and
  standardizing the program's use of exceptions. Fault tolerance is a collection of techniques that increase software
  reliability by detecting errors and recovering from them if possible or containing their effects if recovery is not
  possible. The most common fault tolerance strategies include backing up and retrying, using auxiliary code, using
  voting algorithms, and replacing an erroneous value with a phony value that will have a benign effect.</p>
<div class="third">Executable models</div>
<p>Executable models abstract away the details of specific programming languages and decisions about the organization of
  the software. A specification built in an executable modeling language like xUML (executable UML) can be deployed in
  various software environmnets without change. An executable-model compiler (transformer) can turn an executable model
  into an implementation using a set of decisions about the target hardware and sofware environment. Executable models
  are one foundation supporting the Model-Driven Architecture (DMA) initiative of the Object Management Group (OMG). An
  executable model is a way to completely specify a Platform Indepdent Model (PIM), which is a model of a solution to a
  problem that does not rely on any implementation technologies. The Platform Specific Model (PSM) weaves together the
  PIM and the platform on which it relies.</p>
<div class="third">State-based and table-driven construction techniques</div>
<p>State-based programming, or automata-based programming, is a programming technology using finite state machines to
  describe program behaviors. The main idea is to construct computer programs the same way the automation of
  technological processes is done. Combined with object-oriented programming, state-based programming forms a new
  composite approach called state-based, object-oriented programming. A table-driven method is a schema that uses tables
  to look up information rather than using logic statements such as if and case.</p>
<div class="third">Runtime configuration and internationalization</div>
<p>Runtime configuration is a technique that binds variable values and program settings when the program is running,
  usually by updating and reading configuration files in a just-in-time model. Internationalization is the technical
  activity of preparing a program, usually an interactive one, to support multiple locales. The corresponding activity,
  localization, is the activity of modifying a program to support a specific local language.</p>
<div class="third">Grammar-based input processing</div>
<p>Grammar-based input processing involves syntax analysis, or parsing, of the input token stream, and involves creation
  of a data structure (called a parse tree or syntax tree) representing the input data.</p>
<div class="third">Concurrency primitives</div>
<p>A synchronization primitive is a programming abstraction provided by a programming language or the operating system
  that facilitates concurrency and synchronization. Well-known concurrency primitives include semaphores, monitors, and
  mutexes. A semaphore is a protected variable or abstract data type that provides a simple but useful abstraction for
  controlling access to a common resource by multiple processes or threads in a concurrent programming environment. A
  monitor is an abstract data type that presents a set of programmer-defined operations that are executed with mutual
  exclusion. A mutex (mutual exclusion) is a synchronization primitive that grants exclusive access to a shared resource
  by only one process or thread at a time.</p>
<div class="third">Middleware</div>
<p>Middleware is a broad classification for software that provides services above the operating system layer yet below
  the application program layer. Middleware can provide runtime containers for software components to provide message
  passing, persistence, and a transparent location across a network. Middleware can be viewed as a connector between the
  components that use the middleware. Modern message-oriented middleware usually provides an Enterprise Service Bus
  (ESB), which supports service-oriented interaction and communication between multiple software applications.</p>
<div class="third">Construction methods for distributed software</div>
<p>A distributed system is a collection of physically separate, possibly heterogeneous computer systems that are
  networked to provide the users with access to the various resources that the system maintains. Construction of
  distributed software is distinguished by issues such as paralliems, communication, and fault tolerance. Distributed
  programming typically falls into client-server, 3-tier architecture, n-tier architecture, distributed objects, loose
  coupling, or tight coupling.</p>
<div class="third">Constructive heterogeneous systems</div>
<p>Heterogeneous systems consist of a variety of specialized computational units of different types, such as Digital
  Signal Processors (DSPs), microcontrollers, and peripheral processors. These computational units are independently
  controlled and communicate with one another. Embedded systems are typically heterogeneous systems. Software
  development and virtual hardware development proceed concurrently through stepwise decomposition. The hardware part is
  usually simulated in field programmable gate arrays (FPGAs) or application-specific integrated circuits (ASICs). The
  software part is translated into a low-level programming language.</p>
<div class="third">Performance analysis and tuning</div>
<p>Code efficiency, determined by architecture, detailed design decisions, and data-structure and algorithm selection,
  influences an execution speed and size. Performance analysis is the investigation of a program's behavior using
  information gathered as the program's executes, with the goal of identifying possible hot spots in the program to be
  improved. Code tuning, which improves performance at the code level, is the practice of modifying correct code in ways
  to make it run more efficiently.</p>
<div class="third">Platform standards</div>
<p>Platform standards are a set of standard services and APIs that compatible platform implementations must implement.
  Examples are Java 2 Platform Enterprise Edition (J2EE) and POSIX standard for operating systems (Portable Operating
  System Interface), which reppresents a set of standards implemented primarily for UNIX-based operating systems.</p>
<div class="third">Test-first programming</div>
<p>Test-first programming, also known as test-driven development (TDD), is a popular development style in which test
  cases are written prior to writing any code.</p>
<div class="second">Software construction tools</div>
<div class="third">Development environments</div>
<p>A development environment, or integrated development environment (IDE), provides comprehensive facilities to
  programmers for software construction by integrating a set of development tools. In addition to basic code editing
  functions, modern IDEs often offer other features like compilation and error detection from within the editor,
  itnegration with source code control, build/test/debugging tools, compressed or outline views of programs, automated
  code transforms, and support for refactoring.</p>
<div class="third">GUI builders</div>
<p>A Graphical User Interface (GUI) builder is a software development tool that enables the developer to create and
  maintain GUIs in a What You See Is What You Get (WYSIWYG) mode. A GUI builder usually includes a visual editor for the
  developer to design forms and windows and manage the layout of the widgets by dragging, dropping, and parameter
  setting.</p>
<div class="third">Unit testing tools</div>
<p>Unit testing verifies the functioning of software modules in isolation from other software elements that are
  separately testable and is often automated.</p>
<div class="third">Profiling, performance analysis, and slicing tools</div>
<p>The most common performance analysis tools are profiling tools. An execution profiling tool monitors the code while
  it runs and records how many times each statement is executed or how much time the program spends on each statement or
  execution path. Program slicing involves computation of the set of program statements (the program slice) that may
  affect the values of specified variables at some point of interest, referred to as a slicing criterion.</p>

<div class="first">Software testing</div><a class="anchor" id="software_testing"></a>
<p>Software testing consists of the dynamic verification that a program provides expected behaviors on a finite set of
  test cases, suitably selected from the usually infinite execution domain. Dynamic means that testing always implies
  executing the program on selected inputs (as opposed to static techniques which do not execute code). Finite is
  because exhaustive testing could take forever to execute. Selected is because selection of which test technique and
  which test cases can be difficult. Expected
  means the tests should have some expected outcome.</p>
<p>Software testing is, or should be pervasive throughout the entire development and maintenance life cycle. Software
  failures experienced after delivery are addressed by corrective maintenance.</p>
<p>The test target and test objective together determine how the test set is identified, both with regard to its
  consistency (how much testing is enough, aka test adequacy criteria) and to its composition (which test cases should
  be selected, aka selection criteria).</p>
<div class="second">Software testing fundamentals</div>
<div class="third">Testing-related terminology</div>
<p>Many terms are used in software engineering to describe a malfunction: notably fault, failure, and error. It is
  essential to clearly distinguish between the cause of a malfunction (fault) and an undesired effect in the system's
  delivered services (failure). There may be faults in the software that never manifest as a failure. It is the faults
  that can and must be removed. The more generic term defect can be used to refer to either a fault or a failure, when
  the distinction is not important. To avoid ambiguity, one could refer to failure-causing inputs instead of faults,
  since faults can't be proved to cause a failure.</p>
<div class="third">Key issues</div>
<p>Key issues in testing include having a test selection/test adequacy criterion that can determine whether a set of
  test cases is sufficient, determining testing effectiveness by analyzing a set of program executions, and testing for
  defect discovery by trying to find a test that causes the system to fail. The oracle problem (an agent that decides
  whether a program behaved correctly in a given test). Testing theory warns against ascribing an unjustified field of
  confidence to a series of successful tests. Most results of testing theory are negative, in that they state what
  testing can never achieve as opposed to what is actually achieved. The Dijkstra aphorism is that program testing can
  show bugs but never show their absence. The problem of infeasible paths are control flow paths that cannot be
  exercised by any input data, and pose a significant problem in path-based testing. Testability means either the ease
  with which a given test coverage criterion can be satisfied or the likelihood, measured statistically, that a set of
  test cases will expose a failure if the software is faulty.</p>
<div class="third">Relationship of testing to other activities</div>
<p>Testing is related to but different from, for example, static software quality management techniques, correctness
  proofs and formal verification, debugging, and program construction.</p>
<div class="second">Test levels</div>
<p>Software testing is usually performed at different levels throughout the development and maintenance processes.
  Levels can be distinguished based on the object of testing, called the target, or on the purpose, called the
  objective.</p>
<div class="third">The target of the test</div>
<p>The target of the test can vary: a single module, a group of modules, or an entire system. Three test stages can be
  distinguished: unit, integration, and system.</p>
<p>Unit testing verifies the functioning in isolation of software elements that are separately testable. Typically, unit
  testing occurs with access to the code being tested and with the support of debugging tools. The programmers who wrote
  the code typically, but not always, conduct unit testing.</p>
<p>Integration testing is the process of verifying the interactions among software components. Classic integration test
  strategies, such as top-down and bottom-up, are often used with hierarchically structured software. Modern, systematic
  integration strategies are typically architecture-driven, involving incrementally integrating components based on
  identified functional threads. Integration testing is often an ongoing activity during which software engineers
  abstract away lower-level perspectives and concentrate on the perspectives of the level at which they are integrating.
</p>
<p>System testing is concerned with testing the behavior of an entire system, usually for the nonfunctional system
  requirements such as speed, security, accuracy, and reliability. External interfaces to other applications, utilities,
  hardware devices, or operating environments are usually evaluated at this level.</p>
<div class="third">Objectives of testing</div>
<p>Stating the objectives of testing in precise, quantitative terms supports measurement and control of the test
  process. Test cases can be designed to check that the functional specifications are correctly implemented, referred to
  in the literature as conformance testing, correctness testing, or functional testing. Nonfunctional properties can be
  tested as well. Important objects include reliability, security vulnerabilities, usability, and software acceptance.
</p>
<p>Acceptance or qualification testing determines whether a system satisfies its acceptance criteria, usually by
  checking desired system behaviors against the customer's requirements.</p>
<p>Installation testing can be viewed as system testing conducted in the operational environment of hardware
  configurations and other operational constraints.</p>
<p>Before software is released, it is sometimes given to a small, selected group of potential users for alpha testing
  and to a larger set of representative useres for beta testing.</p>
<p>Testing improves reliability by identifying and correcting faults. Statistical measures of reliability can be
  derived by randomly generating test cases according to the operational profile of the software, an approach called
  operational testing.</p>
<p>Regression testing is the selective retesting of a system or component to verify that modifications have not caused
  unintended effects and that the system or component still complies with its specified requirements.</p>
<p>Performance testing verifies that the software meets the specified performance requirements and assess performance
  characteristics such as capacity and response time.</p>
<p>Security testing is focused on the verification that software is protected from external attacks. Usually, security
  testing also includes verification against misuse and abuse of the software or system (negative testing).</p>
<p>Stress testing exercises software at maximum design load with the goal of determining behavioral limits and to test
  defense mechanisms in critical systems.</p>
<p>Back-to-back testing is testing in which two or more variants of a program are executed with the same inputs, the
  outputs are compared, and errors are analyzed in case of discrepancies.</p>
<p>Recovery testing verifies software restart capabilties after a system crash or other disaster.</p>
<p>Interface testing verifies whether the components interface to provide the correct exchange of data and control
  information. A specific objective of interface testing is to simulate the use of APIs by end-user applications.</p>
<p>Configuration testing verifies software under different configurations.</p>
<p>Usability and human computer-interaction testing evaluates how easy it is for end useres to learn and to use
  software.</p>
<div class="second">Test techniques</div>
<p>One of the aims of testing is to detect failures and to break a program. Testing techniques can be classified based
  on how tests are generated. Sometimes these techniques are classified as white-box or glass-box if the tests are
  based on how the software has been designed or coded, or black-box if the test cases rely only on input/output
  behavior.</p>
<div class="third">Based on the software engineer's intuition and experience</div>
<p>Ad hoc testing uses tests derived relying on the software engnieer's skill, intuion, and experience with similar
  programs. This is perhaps the most widely practiced techniques, and are useful for identifying test cases not
  easily generated by more formal techniques.</p>
<p>Exploratory testing is simultaneous learning, test design, and test execution. The tests are not defined in
  advance but are dynamically designed, executed, and modified.</p>
<div class="third">Input domain-based techniques</div>
<p>Equivalence parititioning involves partitioning the input domain into a collectio nof subsets (or equivalent
  classes). A representative set of tests is taken from each equivalency class.</p>
<p>Pairwise testing involves test cases derived by combining interesting values for every pair of a set of input
  variables. Pairwise testing belongs to combinatorial testing. Techniques that includes higher-level combinations than
  pairs are referred to as t-wise, whereby every possible combination of t input variables is considered.</p>
<p>Boundary-value analysis includes test cases chosen on or near the boundaries of the input domain of variables, with
  the underlying rationale that many faults tend to concentrate near the extreme values of inputs. An extension of this
  technique is robustness testing, wherein test cases are also chosen outside the input domain to test robustness in
  processing unexpected or erroneous inputs.</p>
<p>Random testing have tests generated purely at random (not to be confused with statistical testing from operational
  profile). Fuzz testing or fuzzing is a special form of random testing aimed at breaking the software, most often used
  for security testing.</p>
<div class="third">Code-based techniques</div>
<p>Control flow-based coverage criteria are aimed at covering all the statements, blocks of statements, or specified
  combinations of statements in a program. The strongest of the control flow-based criteria is path testing, which aims
  to execute all entry-to-exit control paths in a program's control flow graph. Since exhaustive path testing is
  generally not feasible because of loops, other less stringent criteria focus on coverage of paths that limit loop
  iterations such as statement coverage, branch coverage, and condition/decision testing. The adequacy of such tests is
  measured in percentages.</p>
<p>Data flow-based testing has a control flow graph annotated with information about how the program varialbes are
  defined, used, and killed (undefined). The strongest criterion, all defition-use paths, requires that for each
  variable every control flow path segment to a use of that definition is executed. Weaker strategies such as
  all-definitions and all-uses are employed to reduce the number of paths required.</p>
<p>The control structure of a program can be graphically represented using a flow graph, a directed graph where the
  nodes and arcs correspond to program elements.</p>
<div class="third">Fault-based techniques</div>
<p>Fault-based techniques specifically aim to reveal categories of likely or predefined faults. To better focus the test
  case generation, a fault model can be introduced that classifies different types of faults.</p>
<p>Error guessing involves test cases designed by software engnieers who try to anticipate the most plausible faults in
  a given program.</p>
<p>A mutant is a slightly modified version of the program under test, differing by a small syntactic change. Every test
  case has the original program and all generated mutants. If a test case is successful in identifying the difference
  between the program and a mutant, the latter is said to be killed. Mutation testing was originally conceived as a
  technique to evaluate test sets, and is a testing criterion in itself. The underlying assumption of mutation testing,
  the coupling effect, is that by looking for simple syntactic faults, more complex but real faults will be found.</p>
<div class="third">Usage-based techniques</div>
<p>Reliability evaluation, or operational testing, the tests reproduce the operational environment of the software, or
  the software's operational profile, as closely as possible. To do this, inputs are assigned probabilities, or
  profiles, according to their frequency of occurrence in actual operation.</p>
<p>Specialized heuristics, called usability inspection methods, are applied for the systematic observation of system
  usage under controlled conditions in order to determine how well people can use teh system and its interfaces.
  Usability heuristics include cognitive walkthroughs, claims analysis, field observations, thinking aloud, and even
  approaches such as user questionnaires and interviews.</p>
<div class="third">Model-based testing techniques</div>
<p>A model in this context is an abstract (formal) representation of the software under test or of its software
  requirements. Model-based testing is used to validate requirements, check their consistency, and generate test cases
  focused on the behavioral aspects of the software.</p>
<p>Decision tables represent logical relationships between conditions and actions. Test cases are systematically derived
  by considering every possible combination of conditions and their corresponding resultant actions. A related technique
  is cause-effect graphing.</p>
<p>A program can be modeled as a finite state machine.</p>
<p>Stating the specifications in a formal language permits automatic derivation of functional test cases and provides an
  oracle for checking test results. Testing and test control notation version 3 (TTCN3) is a language for writing test
  cases, particularly suitable for testing complex communication protocols.</p>
<p>Workflow models specify a sequence of activities performed by humans and/or software applications, usually
  represented through graphical notations. Each sequence of actions constitutes one workflow (ie. scenario).</p>
<div class="third">Techniques based on the nature of the application</div>
<p>Additional techniques for test derivation depends on nature of software (eg. object-oriented, component-based,
  web-based, concurrent, protocol-based, real-time systems, safety-critical systems, service-oriented, open-source,
  embedded).</p>
<div class="third">Selecting and combining techniques</div>
<p>Model-based and code-based test techniques are often contrasted as functional vs. structural testing. These should be
  seen as complements. In addition, test cases can be selected in a deterministic way or randomly drawn from some
  distribution of inputs, such as is done in reliability testing.</p>
<div class="second">Test-related measures</div>
<p>A clear distinction should be made between test-related measures that provide an evaluation of a program under test,
  based on the observed test ouputs, and the measures that evaluate the thoroughness of the test set. For example,
  achieving high branch coverage improves chances of finding failures but is not a testing objective.</p>
<div class="third">Evaluation of the program under test</div>
<p>Measures based on software size (eg. source lines of code, functional size, or frequency with which modules call one
  another) is one measure. It is important to know which types of faults may be found in the software under test. A
  program under test can be evaluated by counting discovered faults as the ratio between the number of faults found and
  the size of the program. A statistical estimate of software reliability, which can be obtained by observing
  reliability achieved, can evaluate a software product and decide whether or not testing can be stopped. Reliability
  growth models provide a prediction of reliability based on failures. These models are divided into failure-count and
  time-between-failure models.</p>
<div class="third">Evaluation of the tests performed</div>
<p>Coverage or thoroughness measures evaluate the thoroughness of executed tests, dynamically measuring the ratio
  between covered elements and the total number.</p>
<p>In fault seeding, some faults are artificially introduced into a program before testing. Testing effectiveness can be
  evaluated, in theory, by how well they discover these artificial faults. In practice, statisticians question the
  distribution and representativeness of seeded faults.</p>
<p>The ratio of killed mutants to the total number of generated mutants measures the effectiveness of an executed test
  set in mutation testing.</p>
<p>It is important to be precise as to the property against which the techniques are being assessed.</p>
<div class="second">Test process</div>
<p>Testing concepts, strategies, techniques, and measures need to be integrated into a defined and controlled process.
  The test process supports testing activities and provides guidance to testers and testing teams.</p>
<div class="third">Pratical considerations</div>
<p>Successful testing requires a collaborative attitude towards testing and quality assurance activities. The mindset of
  individual code ownership among programmers may need to be overcome in order to foster a favorable reception towards
  failure discovery and correction.</p>
<p>The testing phases can be guided by various aims such as risk-based or scenario-based.</p>
<p>Test activities conducted at different levels must be organized.</p>
<p>Documentation is an integral part of the formalization of the test process. Test documents may include the test plan,
  test design specification, test procedure specification, test case specification, test log, and test incident report.
  The software under test is documented as the test item. Test documentation should be under the control of software
  configuration management.</p>
<p>Test-driven development (TDD) originated as one of the core extreme programming (XP) practices and consists of
  writing unit tests prior to writing the code to be tested. In this way, test cases are a surrogate for software
  requirements.</p>
<p>The testing team can be composed of internal members, external members, or both.</p>
<p>Measures related to resources spent on testing are used by managers to control and improve the testing process.</p>
<p>Thoroughness measures and considerations about costs and risks of possible remaining failures, help to determine when
  a test stage can be determinated.</p>
<p>The means used to test each part of the software should be reused systematically. A repository of test materials
  should be under control of software configuration management.</p>
<div class="third">Test activities</div>
<p>Test activities must be planned, including coordination of personnel, availability of test facilities and equipment,
  creation and maintenance of all test-related documentation, and planning for possible undesirable outcomes.</p>
<p>Generation
  of test cases is based on the level of testing to be performed and the particular testing techniques. Test cases
  should be under the control of software configuration management and include the expected results for each test.</p>
<p>The
  environment used for testing should be compatible with other adopted software engineering tools. Executoin of tests
  should embody a basic principle of scientific experimentation: everything during testing should be performed and
  documented clearly enough that another person could replicate the results.</p>
<p>The results of testing should be evaluated
  to determine whether the testing has been successful. Testing activities can be entered into a testing log to identify
  when a test was conducted, who performed the test, what software configuratoin was used, and other relevant
  identificatio ninformation. Defects can be tracked and analyzed to determine when they were introduced into the
  software, why they were created (eg. poorly defined requirements, incorrect variable declaration, memory leak,
  programming syntax error), and when they could have been first observed in the software.</p>
<div class="second">Software testing tools</div>
<div class="third">Testing tool support</div>
<p>Testing requires many labor-intensive tasks, running numerous program executions, and handling a great amount of
  information. Appropriate tools can make this less error-prone. Tool selection depends on diverse evidence, suc has
  development choices, evaluation objectives, execution facilities, and so on.</p>
<div class="third">Categories of tools</div>
<p>Test harnesses (drivers, stubs) provide a controlled environment in which tests can be launched and test ouputs can
  be logged. In order to execute parts of a program, dirvers and stubs are provided to simulate calling and are called
  modules, respectively. Test generators provide assistance in the generation test cases. Capture/replay tools replay
  previously executed tests. Oracle/file comparators/assertion checking tools assist in deciding whether a test outcome
  is successful or not. Coverage analyzers assess which and how many entities of the program flow graph have been
  exercised amongst all those required by the selected test coverage criterion. The analysis can be done thanks to
  program instrumenters that insert recording probes into the code. Tracers record the history of a program's execution
  paths. Regression testing tools support the reexecution of a test suite after a section of software has been modified.
  Reliability evaluation tools support test results analysis and graphical visualization.</p>


<div class="first">Software maintenance</div><a class="anchor" id="software_maintenance"></a>
<p>Historically, software development has been more important than maintenance, but this is changing as organizations
  strive to get more out of their software by making it operate as long as possible as well as the development of the
  open source paradigm making people maintain software developed by others. Software maintenance is defined as the
  totality of activities required to provide cost-effective support to software. Software maintenance involves
  both pre-delivery and post-delivery aspects.</p>
<div class="second">Software maintenance fundamentals</div>
<div class="third">Definitions and terminology</div>
<p>The objective of software maintenance is to modify existing software while preserving its integrity.</p>
<div class="third">Nature of maintenance</div>
<p>Software maintenance sustains the software product throughout its life cycle. A maintainer is an organization that
  performs maintenance activities, and sometimes refers to the individuals who perform those activities, contrasting
  them with developers.</p>
<div class="third">Need for maintenance</div>
<p>Maintenance must be performed to correct faults, improve design, implement enhancements, interface with other
  software, adapt programs so that different hardware, software, sytsem features, and telecommunications facilities can
  be used, migrate legacy software, and retire software. Five key characteristics of maintainer's activites are
  maintaining control over the software's day-to-day functions, maintaining control over software modification,
  perfecting existing functions, identifying security threats and fixing security vulnerabilities, and preventing
  software performance from degrading to unacceptable levels.</p>
<div class="third">Majority of maintenance costs</div>
<p>Maintenance of software costs a lot but there is a misconception that most of the costs are from corrections.</p>
<div class="third">Evolution of software</div>
<p>One of the eight "Laws of Evolution" is that maintenance is evolutionary development and that maintenance decisions
  are aided by understand what happens to software over time. Software will grow more complex unless some action is
  taken to reduce this complexity.</p>
<div class="third">Categories of maintenance</div>
<p>Corrective maintenance is reactive modifications or repairs of a software product peformed after delivery to correct
  discovered problems. Included in ths category is emergency maintenance, which is an unscheduled modification performed
  to temporarily keep a software product operational pending corrective maintenance.</p>
<p>Adaptive maintenance is modification of a software product performed after delivery to keep a software product usable
  in a changed or changing environment.</p>
<p>Perfective maintenance is modification of a software product after delivery to provide enhancements for users,
  improvement of program documentation, and recoding to improve software performance, maintainability, or other software
  attributes.</p>
<p>Preventive maintenance is modification after delivery to detect and correct latent faults before they become
  operational faults.</p>
<p>Adaptive and perfective maintenance are classified as maintenance enhancements. Preventive and perfective are
  proactive, while corrective and adaptive are reactive. Preventive and corrective are correction.</p>
<div class="second">Key issues in software maintenance</div>
<div class="third">Technical issues</div>
<p>Limited understanding refers to how quickly a software engineer can understand where to make a change or conrrection
  in software that he did not develop. The topic of software comprehension is of great interest to software engineers.
  Comprehension is more difficult in text-oriented representation (eg. in source code).</p>
<p>Regression testing (selective retesting of software or a component to verify that modifications have not caused
  unintended effects) is an important testing concept in maintenance. Coordinating tests when different members of the
  maintenance team are working on different problems at the same time remains a challenge. When software performs
  critical functions, it may be difficult to bring it offline to test. Tests cannot be executed in the most meaning
  place-the production system.</p>
<p>Impact analysis describes how to conduct, cost-effectively, a complete analysis of the impact of a change in existing
  software. It identifies all systems and software products affected by a software change request and develops an
  estimate of the resources needed to accomplish the change. The change request, sometimes called a modification request
  (MR) or problem report (PR), must first be analyzed and translated into software terms. Impact analysis is performed
  after a change request enters the software configuration management process.</p>
<p>The severity of a problem is often used to decide how and when it will be fixed.</p>
<p>Maintainability is the capability of the software product to be modified, including corrections, improvements, and
  adaptations of the software to changes in environment as well as changes in requirements and functional
  specifications. Developers are prone to disregard maintainer's requirements which can result in lack of software
  documentation and test environments, which leads to difficulties in program comprehension and subsequent impact
  analysis.</p>
<div class="third">Management issues</div>
<p>Organizational objectives help to look at the return on investment of software maintenance activities. Extending the
  life of software can have less clarity in terms of the return on investment, so the view at the senior management
  level is often that of a major activity consuming significant resources with no clear quantifiable benefit for the
  organization.</p>
<p>Staffing refers to how to attract and keep software maintenance staff. Maintenance is not viewed as glamorous work.
  Software maintenance personnel are frequently viewed as "second-class citizens," and morale therefore suffers.</p>
<p>The software life cycle process is a set of activities, methods, practices, and transformations that people use to
  develop and maintain software and its associated products. At the process level, software maintenance is similar to
  software development.</p>
<p>Organizational aspects describe how to identify which organization and/or functil will be responsible for the
  maintenance of software. The team that developed the software is not necessarily the team that maintains it. Having a
  permanent maintenance team allows for specialization, creates communication channels, promotes an egoless, collegiate
  atmosphere, reduces dependency on individuals, and allows for periodic audit checks.</p>
<p>Outsourcing and offshoring software maintenance has become a major industry. Organizations are outsourcing entire
  portfolios of software, including software maintenance More often, the outsourcing option is selected for less
  mission-critical software. Outsourcing requires a significant initial investment and the setup of a maintenance
  process that will require automation.</p>
<div class="third">Maintenance cost estimation</div>
<p>The two most popular approaches to estimating resources for software maintenance are the use of parametric models and
  the use of experience.</p>
<p>Parametric cost modeling (mathematical models) uses historical data from past maintenance to use and calibrate
  mathematical models, and cost drier attributes affect the estimates.</p>
<p>Experience, in the form of expert judgment, is often used to estimate maintenance effort. Clearly, the best approach
  to maintenance estimation is to combine historical data and experience.</p>
<div class="third">Software maintenance measurement</div>
<p>Measurable entities related to maintenance include process, resource, and product.</p>
<p>Measures for subcharacteristics of maintainability include analyzability, the measures of the maintainer's effort or
  resources expended in trying to diagnose deficiencies or causes of failure, changeability, the measures of the
  maintainer's effort associated with implementing a specified modification, stability, measures of the unexpected
  behavior of software, testability, measures of effort in trying to test the modified software, size, complexity,
  understandability, and maintainability.</p>
<div class="second">Maintenance process</div>
<div class="third">Maintenance processes</div>
<p>Software maintenance activities iclude process implementation, problem and modification analysis, modification
  implementation, maintenance review/acceptance, migration, and software retirement. Ohter maintenance process models
  include quick fix, spiral, Osborne's, iterative enhancement, and reuse-oriented.</p>
<div class="third">Maintenance activities</div>
<p>Maintenance activities are similar to those of software development: performing analysis, design, coding, testing,
  and documentation, tracking requirements, and updating documentation.</p>
<p>Unique activities include program understanding, transition (transfer software progressively from developer to
  maintainer), modification request acceptance/rejection, maintenance help desk, impact analysis, and maintenance
  service-level agreements (SLAs) and maintenance licenses and contracts that describe services and quality objectives.
</p>
<p>Supporting activities include documentation, software configuration management, verification and validation, problem
  resolution, software quality assurance, reviews, audits, training maintainers and users.</p>
<p>Planning activities are associated with business planning (organizational level), maintenance planning (transition
  level), release/version planning (software level), and individual software change request planning (request level). At
  the individual request level, planning is carried out during impact analysis. At the release/version planning level,
  maintainer collects the dates of availability of individual requests, agrees with users on content of
  releases/versions, identifies potential conflicts and develops alternatives, assesses risks, and informs all
  staeholders.</p>
<p>Maintenance phase usually lasts for many years. Making estimates of resouces is a key element of maintenance
  planning. A concept document should be developed followed by a maintenance plan. The document should address the scope
  of software maintenance, adaptation of the software maintenanc eprocess, identification of the osftware maintenance
  organization, and estimate of software maintenance costs. The software maintenance plan should specify how users will
  request software modifications or report problems.</p>
<p>Software configuration management procedures should provide for the verification, validation, and audit of each step
  required to identify, authorize, implement and release the software product. Modifications to software must be
  controlled by using an approved software configuration management (SCM) process.</p>
<p>Maintainers should have a software quality program.</p>
<div class="second">Techniques for maintenance</div>
<div class="third">Program comprehension</div>
<p>Code browsers are key tools for program comprehension and are used to organize and present source code. Clear and
  concise documentation can also aid in program comprehension.</p>
<div class="third">Reengineering</div>
<P>Reengineering is the examination and alteration of software to reconstitute it in a new form, including the
  subsequent implementation of the new form. It is often undertaken to replace aging legacy software. Refactoring is a
  reengineering technique that aims at reorganizing a program without changing its behavior.</p>
<div class="third">Reverse engineering</div>
<p>Reverse engineering is the process of analyzing software to identify the software's components and their
  inter-relationships and to create representations of the software in another form or at higher levels of abstraction.
  Reverse engineering does not change the software or result in new software, but produces call graphs and control flow
  graphs. Types include redocumentation, design recovery, and data reverse engineering, where logical schemas are
  recovered from physical databases.</p>
<div class="third">Migration</div>
<p>The maintainer needs to determine the actions needed to migrate software to run in different environments in a
  migration plan that covers migration requirements, migration tools, conversion of product and data, execution,
  verification, and support. Migrating software can also entail notification of intent (a statement of why the old
  environment is no longer supported), parallel operations (make available old and new environments so the user
  experiences a smooth transition), notification of completion, postoperation review, and data archival.</p>
<div class="third">Retirement</div>
<p>Retirement involves a retirement plan, which covers retirement requirements, impact, replacement, schedule, and
  effort.</p>
<div class="second">Software maintenance tools</div>
<p>Tools for program comprehension include program slicers (selecting parts of a program affected by a change), static
  analyzers (general viewing and summaries of a program content), dynamic analyzers (allow maintainers to trace the
  execution path of a program), data flow analyzers (track all possible data flows), cross-referencers (generate indices
  of program components), and dependency analyzers (understand relationships between components of a program).</p>

<div class="first">Software configuration management</div><a class="anchor" id="software_configuration_management"></a>
<div class="second">Management of the SCM process</div>
<div class="third">Organizational context for SCM</div>
<div class="third">Constraints and guidance for the SCM process</div>
<div class="third">Planning for SCM</div>
<div class="third">SCM plan</div>
<div class="third">Surveillance of software configuration management</div>
<div class="second">Software configuration identification</div>
<div class="third">Identifying items to be controlled</div>
<div class="third">Software library</div>
<div class="second">Software configuration control</div>
<div class="third">Requesting, evaluating, and approving software changes</div>
<div class="third">Implementing software changes</div>
<div class="third">Deviations and waivers</div>
<div class="second">Software configuration status accounting</div>
<div class="third">Software configuration status information</div>
<div class="third">Software configuration status reporting</div>
<div class="second">Software configuration auditing</div>
<div class="third">Software functional configuration audit</div>
<div class="third">Software physical configuration audit</div>
<div class="third">In-process audits of a software baseline</div>
<div class="second">Software release management and delivery</div>
<div class="third">Software building</div>
<div class="third">Software release management</div>

<div class="first">Software engineering management</div><a class="anchor" id="software_engineering_management"></a>
<div class="second">Initiation and scope definition</div>
<div class="third">Determination and negotation of requirements</div>
<div class="third">Feasibility analysis</div>
<div class="third">Process for the review and revision of requirements</div>
<div class="second">Software project planning</div>
<div class="third">Process planning</div>
<div class="third">Determine deliverables</div>
<div class="third">Effort, schedule, and cost estimation</div>
<div class="third">Resource allocation</div>
<div class="third">Risk management</div>
<div class="third">Quality management</div>
<div class="third">Plan management</div>
<div class="second">Software project enactment</div>
<div class="third">Implementation of plans</div>
<div class="third">Software acquisition and supplier contract management</div>
<div class="third">Implementation of measurement process</div>
<div class="third">Monitor process</div>
<div class="third">Control process</div>
<div class="third">Reporting</div>
<div class="second">Review and evaluation</div>
<div class="third">Determining satisfaction of requirements</div>
<div class="third">Reviewing and evaluating performance</div>
<div class="second">Closure</div>
<div class="third">Determining closure</div>
<div class="third">Closure activities</div>
<div class="second">Software engineering measurement</div>
<div class="third">Establish and sustain measurement commitment</div>
<div class="third">Plan the measurement process</div>
<div class="third">Perform the measurement process</div>
<div class="third">Evaluate measurement</div>
<div class="second">Software engineering management tools</div>

<div class="first">Software engineering process</div><a class="anchor" id="software_engineering_process"></a>
<div class="second">Software process definition</div>
<div class="third">Software process management</div>
<div class="third">Software process infrastructure</div>
<div class="second">Software life cycles</div>
<div class="third">Categories of software processes</div>
<div class="third">Software life cycle models</div>
<div class="third">Software process adaptation</div>
<div class="third">Practical considerations</div>
<div class="second">Software process assessment and improvement</div>
<div class="third">Software process assessment models</div>
<div class="third">Software process assessment methods</div>
<div class="third">Software process improvement models</div>
<div class="third">Continuous and staged software process ratings</div>
<div class="second">Software measurement</div>
<div class="third">Software process and product measurement</div>
<div class="third">Quality of measurement results</div>
<div class="third">Software information models</div>
<div class="third">Software process measurement techniques</div>
<div class="second">Software engineering process tools</div>

<div class="first">Software engineering models and methods</div><a class="anchor"
  id="software_engineering_models_and_methods"></a>
<div class="second">Modeling</div>
<div class="third">Modeling principles</div>
<div class="third">Properties and expression of models</div>
<div class="third">Syntax, semantics, and pragmatics</div>
<div class="third">Preconditions, postconditions, and invariants</div>
<div class="second">Types of models</div>
<div class="third">Information modeling</div>
<div class="third">Behavioral modeling</div>
<div class="third">Structure modeling</div>
<div class="second">Analysis of models</div>
<div class="third">Analyzing for completeness</div>
<div class="third">Analyzing for consistency</div>
<div class="third">Analyzing for correctness</div>
<div class="third">Traceability</div>
<div class="third">Interaction analysis</div>
<div class="second">Software engineering methods</div>
<div class="third">Heuristic methods</div>
<div class="third">Formal methods</div>
<div class="third">Prototyping methods</div>
<div class="third">Agile methods</div>

<div class="first">Software quality</div><a class="anchor" id="software_quality"></a>
<div class="second">Software quality fundamentals</div>
<div class="third">Software engineering culture and ethics</div>
<div class="third">Value and costs of quality</div>
<div class="third">Models and quality characteristics</div>
<div class="third">Software quality improvement</div>
<div class="third">Software safety</div>
<div class="second">Software quality management processes</div>
<div class="third">Software quality assurance</div>
<div class="third">Verification & validation</div>
<div class="third">Reviews and audits</div>
<div class="second">Practical considerations</div>
<div class="third">Software quality requirements</div>
<div class="third">Defect characterization</div>
<div class="third">Software quality management techniques</div>
<div class="third">Software quality measurement</div>
<div class="second">Software quality tools</div>

<div class="first">Software engineering professional practice</div><a class="anchor"
  id="software_engineering_professional_practice"></a>
<div class="second">Professionalism</div>
<div class="third">Accreditation, certification, and licensing</div>
<div class="third">Codes of ethics and professional conduct</div>
<div class="third">Nature and role of professional societies</div>
<div class="third">Nature and role of software engineering standards</div>
<div class="third">Economic impact of software</div>
<div class="third">Employment contracts</div>
<div class="third">Legal issues</div>
<div class="third">Documentation</div>
<div class="third">Tradeoff analysis</div>
<div class="second">Group dynamics and psychology</div>
<div class="third">Dynamics of working in teams/groups</div>
<div class="third">Individual cognition</div>
<div class="third">Dealing with problem complexity</div>
<div class="third">Interacting with stakeholders</div>
<div class="third">Dealing with uncertainty and ambiguity</div>
<div class="third">Dealing with multicultural environments</div>
<div class="second">Communication skills</div>
<div class="third">Reading, undestanding, and summarizing</div>
<div class="third">Writing</div>
<div class="third">Team and group communication</div>
<div class="third">Presentation skills</div>

<div class="first">Software engineering economics</div><a class="anchor" id="software_engineering_economics"></a>
<div class="second">Software engineering economics fundamentals</div>
<div class="third">Finance</div>
<div class="third">Accounting</div>
<div class="third">Controlling</div>
<div class="third">Cash flow</div>
<div class="third">Decision-making process</div>
<div class="third">Valuation</div>
<div class="third">Inflation</div>
<div class="third">Depreciation</div>
<div class="third">Taxation</div>
<div class="third">Time-value of money</div>
<div class="third">Efficiency</div>
<div class="third">Effectiveness</div>
<div class="third">Productivity</div>
<div class="second">Life cycle economics</div>
<div class="third">Product</div>
<div class="third">Project</div>
<div class="third">Program</div>
<div class="third">Portfolio</div>
<div class="third">Product life cycle</div>
<div class="third">Project life cycle</div>
<div class="third">Proposals</div>
<div class="third">Investment decisions</div>
<div class="third">Planning horizon</div>
<div class="third">Price and pricing</div>
<div class="third">Cost and costing</div>
<div class="third">Performance measurement</div>
<div class="third">Earned value management</div>
<div class="third">Termination decisions</div>
<div class="third">Replacement and retirement decisions</div>
<div class="second">Risk and uncertainty</div>
<div class="third">Goals, estimates, and plans</div>
<div class="third">Estimation techniques</div>
<div class="third">Addressing uncertainty</div>
<div class="third">Prioritization</div>
<div class="third">Decisions under risk</div>
<div class="third">Decisions under uncertainty</div>
<div class="second">Economic analysis methods</div>
<div class="third">For-profit decision analysis</div>
<div class="third">Minimum acceptable rate of return</div>
<div class="third">Return on investment</div>
<div class="third">Return on capital employed</div>
<div class="third">Cost-benefit analysis</div>
<div class="third">Cost-effectiveness analysis</div>
<div class="third">Break-even analysis</div>
<div class="third">Business case</div>
<div class="third">Multiple attribute evaluation</div>
<div class="third">Optimization analysis</div>
<div class="second">Practical considerations</div>
<div class="third">The "good enough" principle</div>
<div class="third">Friction-free economy</div>
<div class="third">Ecosystems</div>
<div class="third">Offshoring and outsourcing</div>

<div class="first">Computing foundations</div><a class="anchor" id="computing_foundations"></a>
<div class="second">Problem solving techniques</div>
<div class="third">Definition of problem solving</div>
<div class="third">Formulating the real problem</div>
<div class="third">Analyze the problem</div>
<div class="third">Design a solution search strategy</div>
<div class="third">Problem solving using programs</div>
<div class="second">Abstraction</div>
<div class="third">Levels of abstraction</div>
<div class="third">Encapsulation</div>
<div class="third">Hierarchy</div>
<div class="third">Alternate abstractions</div>
<div class="second">Programming fundamentals</div>
<div class="third">The programming process</div>
<div class="third">Programming paradigms</div>
<div class="second">Programming language basics</div>
<div class="third">Programming language overview</div>
<div class="third">Syntax and semantics of programming languages</div>
<div class="third">Low-level programming languages</div>
<div class="third">High-level programming languages</div>
<div class="third">Declarative vs. imperative programming languages</div>
<div class="second">Debugging tools and techniques</div>
<div class="third">Types of errors</div>
<div class="third">Debugging techniques</div>
<div class="third">Debugging tools</div>
<div class="second">Data structure and representation</div>
<div class="third">Data structure overview</div>
<div class="third">Types of data structure</div>
<div class="third">Operations on data structures</div>
<div class="second">Algorithms and complexity</div>
<div class="third">Overview of algorithms</div>
<div class="third">Attributes of algorithms</div>
<div class="third">Algorithmic analysis</div>
<div class="third">Algorithmic design strategies</div>
<div class="third">Algorithmic analysis strategies</div>
<div class="second">Basic concept of a system</div>
<div class="third">Emergent system properties</div>
<div class="third">Systems engineering</div>
<div class="third">Overview of a computer system</div>
<div class="second">Computer organization</div>
<div class="third">Computer organization overview</div>
<div class="third">Digital systems</div>
<div class="third">Digital logic</div>
<div class="third">Computer expression of data</div>
<div class="third">The central processing unit (CPU)</div>
<div class="third">Memory system organization</div>
<div class="third">Input and output (I/O)</div>
<div class="second">Compiler basics</div>
<div class="third">Compiler/interpreter overview</div>
<div class="third">Interpretation and compilation</div>
<div class="third">The compilation process</div>
<div class="second">Operating system basics</div>
<div class="third">Operating systems overview</div>
<div class="third">Tasks of an operating system</div>
<div class="third">Operating system abstractions</div>
<div class="third">Operating systems classification</div>
<div class="second">Database basics and data management</div>
<div class="third">Entity and schema</div>
<div class="third">Database management systems (DBMS)</div>
<div class="third">Database query language</div>
<div class="third">Tasks of DBMS packages</div>
<div class="third">Data management</div>
<div class="third">Data mining</div>
<div class="second">Network communication basics</div>
<div class="third">Types of network</div>
<div class="third">Basic network components</div>
<div class="third">Networking protocols and standards</div>
<div class="third">The Internet</div>
<div class="third">Internet of things</div>
<div class="third">Virtual private network (VPN)</div>
<div class="second">Parallel and distributed computing</div>
<div class="third">Parallel and distributed computing overview</div>
<div class="third">Difference between parallel and distributed computing</div>
<div class="third">Parallel and distributed computing models</div>
<div class="third">Main issues in distributed computing</div>
<div class="second">Basic user human factors</div>
<div class="third">Input and output</div>
<div class="third">Error messages</div>
<div class="third">Software robustness</div>
<div class="second">Basic developer human factors</div>
<div class="third">Structure</div>
<div class="third">Comments</div>
<div class="second">Secure software development and maintenance</div>
<div class="third">Software requirements security</div>
<div class="third">Software design security</div>
<div class="third">Software construction security</div>
<div class="third">Software testing security</div>
<div class="third">Build security into software engineering process</div>
<div class="third">Software security guidelines</div>

<div class="first">Mathematical foundations</div><a class="anchor" id="mathematical_foundations"></a>
<div class="second">Sets, relations, functions</div>
<div class="third">Set operations</div>
<div class="third">Properties of set</div>
<div class="third">Relation and function</div>
<div class="second">Basic logic</div>
<div class="third">Propositional logic</div>
<div class="third">Predicate logic</div>
<div class="second">Proof techniques</div>
<div class="third">Methods of proving theorems</div>
<div class="second">Basics of counting</div>
<div class="second">Graphs and trees</div>
<div class="third">Graphs</div>
<div class="third">Trees</div>
<div class="second">Discrete probability</div>
<div class="second">Finite state machines</div>
<div class="second">Grammars</div>
<div class="third">Language recognition</div>
<div class="second">Numerical precision, accuracy, and errors</div>
<div class="second">Number theory</div>
<div class="third">Divisibility</div>
<div class="third">Prime number, GCD</div>
<div class="second">Algebraic structures</div>
<div class="third">Group</div>
<div class="third">Rings</div>

<div class="first">Engineering foundations</div><a class="anchor" id="engineering_foundations"></a>
<div class="second">Empirical methods and experimental techniques</div>
<div class="third">Designed experiment</div>
<div class="third">Observational study</div>
<div class="third">Retrospective study</div>
<div class="second">Statistical analysis</div>
<div class="third">Unit of analysis (sampling units), population, and sample</div>
<div class="third">Concepts of correlation and regression</div>
<div class="second">Measurement</div>
<div class="third">Levels (scales) of measurement</div>
<div class="third">Direct and derived measures</div>
<div class="third">Reliability and validity</div>
<div class="third">Assessing reliability</div>
<div class="second">Engineering design</div>
<div class="third">Engineering design in engineering education</div>
<div class="third">Design as a problem solving activity</div>
<div class="third">Steps involved in engineering design</div>
<div class="second">Modeling, simulation, and prototyping</div>
<div class="third">Modeling</div>
<div class="third">Simulation</div>
<div class="third">Prototyping</div>
<div class="second">Standards</div>
<div class="second">Root cause analysis</div>
<div class="third">Techniques for conducting root cause analysis</div>



<div class="first">Overview of operating systems</div><a class="anchor" id="overview_operating"></a>
<h4>Kernel</h4>
<p>The kernel is a computer program at the core of a computer's operating system that generally has complete
  control
  over everything in the system. It is the portion of the operating system that is always resident in memory, and
  facilitates interactions between hardware and software components. It controls all hardware resources (e.g. I/O,
  memory, cryptography) via device drivers, arbitrates conflicts between processes concerning such resources, and
  optimizes the utilization of common resources e.g. CPU & cache usage, file systems, and network sockets. It is
  one
  of
  the first programs loaded on startup (after the bootloader). It connects the application software to the
  hardware of
  a
  computer.</p>
<h4>Operating system</h4>
<p>An operating system is system software that manages computer hardware, software resources, and provides common
  services for computer programs.</p>
<h4>Assembly language</h4>
<p>Assembly language, or assembler language, is any low-level programming language in which there is a very strong
  correspondence between the instructions in the language and the architecture's machine code instructions. It
  usually
  has
  one statement per machine instruction. Assembly code is converted into executable machine code by a utility
  program
  reffered to as an assembler. The term originally meant "a program that assembles another program consisting of
  several
  sections into a single program." The conversion process is referred to as assembly, as in assembling the source
  code.
</p>
<h4>Linux</h4>
<p>Linux is a family of free and open-source operating systems based on the Linux kernel, examples include Debian,
  Ubuntu, Fedora, CentOS, Gentoo, Arch Linux, and many others. 90% of all cloud infrastructure and 74% of the
  world's
  smartphones are powered by Linux. Linux-based operating systems depend heavily on working with the command line
  interface, while most personal computers rely on graphical interfaces. Linux filesystems also have a different
  structure than those found on Windows or MacOS.</p>
<h4>Terminal</h4>
<p>A terminal is an input and output environment that presents a text-only window running a shell. A shell is a
  program
  that exposes the computer's operating system to a user or program. In Linux systems, the shell presented in a
  terminal
  is a command line interpreter. A command line interface is a user interface which processes commands to a
  computer
  program and outputs the results.</p>

<div class="first">Introduction</div><a class="anchor" id="platform"></a>
<h4>Overview of platforms (e.g., Web, Mobile, Game, Industrial)</h4>
<h4>Programming via platform-specific APIs</h4>
<h4>Overview of Platform Languages (e.g., Objective C, HTML5)</h4>
<h4>Programming under platform constraints</h4>
<div class="first">Web platforms</div><a class="anchor" id="web"></a>
<h4>Web programming languages (e.g., HTML5, JavaScript, PHP, CSS)</h4>
<h4>Web platform constraints</h4>
<h4>Software as a Service (SaaS)</h4>
<h4>Web standards</h4>
Design and implement a simple web application
Describe the constraints that the web puts on developers
Compare and contrast web programming with general purpose programming
Describe the differences between Software-as-a-Service and traditional software products
Discuss how web standards impact software development
Review an existing web application against a current web standard
<div class="first">Mobile platforms</div><a class="anchor" id="mobile"></a>
<div class="first">Industrial platforms</div><a class="anchor" id="industrial"></a>
<div class="first">Game platforms</div><a class="anchor" id="game"></a>
<div class="first">Object-oriented programming</div><a class="anchor" id="platform"></a>
<h4>Object-oriented design</h4>
Decomposition into objects carrying state and having behavior, class-hierarchy design for modeling
<h4>Definition of classes: fields, methods, and constructors</h4>
<h4>Subclasses, inheritance, and method overriding</h4>
<h4>Dynamic dispatch: definition of method-call</h4>
<div class="first">Functional programming</div><a class="anchor" id="platform"></a>
<h4>Effect-free programming</h4>
Function calls have no side effects, facilitating compositional reasoning
Variables are immutable, preventing unexpected changes to program data by other code
Data can be freely aliased or copied without introducing unintended effects from mutation
<h4>Processing structured data (e.g., trees) via functions with cases for each data variant</h4>
Associated language constructs such as discriminated unions and pattern-matching over them
Functions defined over compound data in terms of functions applied to the constituent pieces
<h4>First-class functions (taking, returning, and storing functions)</h4>
<div class="first">Event-driven and reactive programming</div><a class="anchor" id="platform"></a>
<h4>Events and event handlers</h4>
<h4>Canonical uses such as GUIs, mobile devices, robots, servers</h4>
<h4>Using a reactive framework</h4>
Defining event handlers/listeners
Main event loop not under event-handler-writer's control
<h4>Externally-generated events and program-generated events</h4>
<h4>Separation of model, view, and controller</h4>
<div class="first">Basic type systems</div><a class="anchor" id="platform"></a>
<h4>A type as a set of values together with a set of operations</h4>
Primitive types (e.g., numbers, Booleans)
Compound types built from other types (e.g., records, unions, arrays, lists, functions, references)
<h4>Association of types to variables, arguments, results, and fields</h4>
<h4>Type safety and errors caused by using values inconsistently given their intended types</h4>
<h4>Goals and limitations of static typing</h4>
Eliminating some classes of errors without running the program
Undecidability means static analysis must conservatively approximate program behavior
<div class="first">Program representation</div><a class="anchor" id="platform"></a>
<div class="first">Language translation and execution</div><a class="anchor" id="platform"></a>
<div class="first">Syntax analysis</div><a class="anchor" id="platform"></a>
<div class="first">Compiler semantic analysis</div><a class="anchor" id="platform"></a>
<div class="first">Code generation</div><a class="anchor" id="platform"></a>
<div class="first">Runtime systems</div><a class="anchor" id="platform"></a>
<div class="first">Static analysis</div><a class="anchor" id="platform"></a>
<div class="first">Advanced programming constructs</div><a class="anchor" id="platform"></a>
<div class="first">Concurrency and parallelism</div><a class="anchor" id="platform"></a>
<div class="first">Type systems</div><a class="anchor" id="platform"></a>
<div class="first">Formal semantics</div><a class="anchor" id="platform"></a>
<div class="first">Language pragmatics</div><a class="anchor" id="platform"></a>
<div class="first">Logic programming</div><a class="anchor" id="platform"></a>
<div class="first">Algorithms and design</div><a class="anchor" id="algorithm_design"></a>
<h4>The concept and properties of algorithms</h4>
Informal comparison of alogirthm efficiency (e.g., operation counts)
<h4>The role of algorithms in the problem-solving process</h4>
<h4>Problem-solving strategies</h4>
Iterative and recursive mathematical functions
Iterative and recursive traversal of data structures
Divide-and-conquer strategies
<h4>Fundamental design concepts and principles</h4>
Abstraction, program decomposition, encapsulation and information binding, separation of behavior and
implementation
<div class="first">Fundamental programming concepts</div><a class="anchor" id="fundamental_programming"></a>
<h4>Basic syntax and semantics of a higher-level language</h4>
<h4>Variables and primitive data types (e.g., numbers, characters, Booleans)</h4>
<h4>Expressions and assignments</h4>
<h4>Simple I/O including file I/O</h4>
<h4>Conditional and iterative control structures</h4>
<h4>Functions and parameter passing</h4>
<h4>The concept of recursion</h4>
<div class="first">Fundamental data structures</div><a class="anchor" id="fundamental_data"></a>
<h4>Arrays</h4>
<h4>Records/structs (heterogeneous aggregates)</h4>
<h4>Strings and string processing</h4>
<h4>Abstract data types and their implementation</h4>
Stacks, queues, priorty queues, sets, maps
<h4>References and aliasing</h4>
<h4>Linked lists</h4>
<h4>Strategies for choosing the appropriate data structure</h4>
<div class="first">Development methods</div><a class="anchor" id="development_methods"></a>
<h4>Program comprehension</h4>
<h4>Program correctness</h4>
Types of errors (syntax, logic, run-time), the concept of a specification, defensive programming (e.g., secure
coding,
exception handling), code reviews, testing fundamentals and test-case generation, the role and the use of
contracts,
including pre- and post-conditions, unit testing
<h4>Simple refactoring</h4>
<h4>Modern programming environments</h4>
Code search, programming using library components and their APIs
<h4>Debugging strategies</h4>
<h4>Documentation and program style</h4>
<div class="first">Software processes</div><a class="anchor" id="platform"></a>
<h4>Systems level considerations, i.e., the interaction of software with its intended environment (cross-reference
  IAS/Secure Software Engineering)</h4>
<h4>Introduction to software process models (e.g., waterfall, incremental, agile)</h4>
Activities within software lifecycles
<h4>Programming in the large vs. individual programming</h4>
<div class="first">Software project management</div><a class="anchor" id="platform"></a>
<h4>Team participation</h4>
Team processes including responsibilities for tasks, meeting structure, and work schedule
Roles and responsibilities in a software team
Team conflict resolution
Risks associated with virtual teams (communication, perception, structure)
<h4>Effort estimation (at the personal level)</h4>
<h4>Risk (cross reference IAS/Secure Software Engineering)</h4>
The role of risk in the lifecycle
Risk categories including security, safety, market, financial, technology, people, quality, structure and process
<div class="first">Tools and environments</div><a class="anchor" id="platform"></a>
<h4>Software configuration management and version control</h4>
<h4>Release management</h4>
<h4>Requirements analysis and design modeling tools</h4>
<h4>Testing tools including static and dynamic analysis tools</h4>
<h4>Programming environments that automate parts of program construction processes (e.g., automated builds)</h4>
Continuous integration
<h4>Tool integration concepts and mechanisms</h4>
<div class="first">Requirements engineering</div><a class="anchor" id="platform"></a>
<h4>Describing functional requirements using, for example, use cases or user stories</h4>
<h4>Properties of requirements including consistency, validity, completeness, and feasibility</h4>
<div class="first">Software design</div><a class="anchor" id="platform"></a>
<h4>System design principles</h4>
Levels of abstraction (architectural design and detailed design), separation of concerns, information hiding,
coupling
and cohesion, re-use of standard structures
<h4>Design paradigms</h4>
Structured design (top-down functional decomposition), object-oriented analysis and design, event driven design,
component-level design, data-structured centered, aspect oriented, function oriented, service oriented
<h4>Structural and behavioral models of software designs</h4>
<h4>Design patterns</h4>
<div class="first">Software construction</div><a class="anchor" id="platform"></a>
<h4>Coding practices</h4>
techniques, idioms/patterns, mechanisms for building quality programs (cross-reference IAS/Defensive Programming;
SDF/Development Methods)
Defensive coding practices
Secure coding practices
Using exception handling mechanisms to make programs more robust, fault-tolerant
<h4>Coding standards</h4>
<h4>Integration strategies</h4>
<h4>Development context: "green field" vs. existing code base</h4>
Change impact analysis, change actualization
<div class="first">Software verification and validation</div><a class="anchor" id="platform"></a>
<h4>Verification and validation concepts</h4>
<h4>Inspections, reviews, audits</h4>
<h4>Testing types, including human computer interface, usability, reliability, security, conformance to
  specification
  (cross-reference IAS/Secure Software Engineering)</h4>
<h4>Testing fundamentals (cross-reference SDF/Development Methods)</h4>
Unit, integration, validation, and system testing
Test plan creation and test case generation
Black-box and white-box testing techniques
Regression testing and test automation
<h4>Defect tracking</h4>
<h4>Limitations of testing in particular domains, such as parallel or safety-critical systems</h4>
<div class="first">Software evolution</div><a class="anchor" id="platform"></a>
<div class="first">Software reliability</div><a class="anchor" id="platform"></a>
<div class="first">Formal methods</div><a class="anchor" id="platform"></a>

<div class="size">
  https://www.acm.org/binaries/content/assets/education/cs2013_web_final.pdf
  <p>The top core competencies from computer science for general application include software development
    fundamentals,
    discrete structures, algorithms and complexity, and systems fundamentals.</p>
  <h1>Computer Science</h1>
  <h2>Algorithms and Complexity (AL)</h2>
  <h3>Basic Analysis</h3>
  Differences among best, expected, and worst case behaviors of an algorithm
  • Asymptotic analysis of upper and expected complexity bounds
  • Big O notation: formal definition
  • Complexity classes, such as constant, logarithmic, linear, quadratic, and exponential
  • Empirical measurements of performance
  • Time and space trade-offs in algorithms
  <h3>Algorithmic Strategies</h3>
  <h3>Fundamental Data Structures and Algorithms</h3>
  Simple numerical algorithms, such as computing the average of a list of numbers, finding the min, max,
  and mode in a list, approximating the square root of a number, or finding the greatest common divisor
  • Sequential and binary search algorithms
  • Worst case quadratic sorting algorithms (selection, insertion)
  • Worst or average case O(N log N) sorting algorithms (quicksort, heapsort, mergesort)
  • Hash tables, including strategies for avoiding and resolving collisions
  • Binary search trees
  o Common operations on binary search trees such as select min, max, insert, delete, iterate over tree
  • Graphs and graph algorithms
  o Representations of graphs (e.g., adjacency list, adjacency matrix)
  o Depth- and breadth-first traversals
  Heaps
  • Graphs and graph algorithms
  o Shortest-path algorithms (Dijkstra’s and Floyd’s algorithms)
  o Minimum spanning tree (Prim’s and Kruskal’s algorithms)
  • Pattern matching and string/text algorithms (e.g., substring matching, regular expression matching, longest
  common subsequence algorithms)
  <h3>Basic Automata Computability and Complexity</h3>
  Finite-state machines
  • Regular expressions
  • The halting problem
  <h3>Advanced Computational Complexity</h3>
  <h3>Advanced Automata Theory and Computability</h3>
  <h3>Advanced Data Structures Algorithms and Analysis</h3>
  <h2>Architecture and Organization (AR)</h2>
  <h3>Digital Logic and Digital Systems</h3>
  <h3>Machine Level Representation of Data</h3>
  Bits, bytes, and words
  • Numeric data representation and number bases
  • Fixed- and floating-point systems
  • Signed and twos-complement representations
  • Representation of non-numeric data (character codes, graphical data)
  • Representation of records and arrays
  <h3>Assembly Level Machine Organization</h3>
  <h3>Memory System Organization and Architecture</h3>
  Storage systems and their technology
  • Memory hierarchy: importance of temporal and spatial locality
  • Main memory organization and operations
  • Latency, cycle time, bandwidth, and interleaving
  • Cache memories (address mapping, block size, replacement and store policy)
  • Multiprocessor cache consistency/Using the memory system for inter-core synchronization/atomic memory
  operations
  • Virtual memory (page table, TLB)
  • Fault handling and reliability
  • Error coding, data compression, and data integrity (cross-reference SF/Reliability through Redundancy)
  <h3>Interfacing and Communication</h3>
  <h3>Functional Organization</h3>
  <h3>Multiprocessing and Alternative Architectures</h3>
  <h3>Performance Enhancements</h3>
  <h2>Computational Science (CN)</h2>
  <p>Computational science is a field of applied computer science, that is, the application of computer science to
    solve
    problems across a range of disciplines. It combines computer simulation, scientific visualization,
    mathematical
    modeling, computer programming and data structures, networking, database design, symbolic computation, and
    high
    performance computing with various disciplines. The needs of scientists and engineers for computation have
    long
    driven research and innovation in computing. Computational neuroscience is a subfield of computational
    science.
  </p>
  <p>A goal in neural engineering is to abstract the concept of the brain. But the brain trying to model itself is
    a
    bit
    meta. Some say that dreams are essential models of various situations our subconscious is trying to prepare us
    for.
    In order to understand the brain, we should understand various modeling and simulation techniques used in
    computer
    science.</p>
  <h3>Introduction to Modeling and Simulation</h3>
  Models as abstractions of situations
  • Simulations as dynamic modeling
  • Simulation techniques and tools, such as physical simulations, human-in-the-loop guided simulations, and
  virtual reality
  • Foundational approaches to validating models (e.g., comparing a simulation’s output to real data or the
  output of another model)
  • Presentation of results in a form relevant to the system being modeled
  <h3>Modeling and Simulation</h3>
  Purpose of modeling and simulation including optimization; supporting decision making, forecasting,
  safety considerations; for training and education
  • Tradeoffs including performance, accuracy, validity, and complexity
  • The simulation process; identification of key characteristics or behaviors, simplifying assumptions;
  validation of outcomes
  • Model building: use of mathematical formulas or equations, graphs, constraints; methodologies and
  techniques; use of time stepping for dynamic systems
  Formal models and modeling techniques: mathematical descriptions involving simplifying assumptions
  and avoiding detail. Examples of techniques include:
  o Monte Carlo methods
  o Stochastic processes
  o Queuing theory
  o Petri nets and colored Petri nets
  o Graph structures such as directed graphs, trees, networks
  o Games, game theory, the modeling of things using game theory
  o Linear programming and its extensions
  o Dynamic programming
  o Differential equations: ODE, PDE
  o Non-linear techniques
  o State spaces and transitions
  • Assessing and evaluating models and simulations in a variety of contexts; verification and validation of
  models and simulations
  • Important application areas including health care and diagnostics, economics and finance, city and urban
  planning, science, and engineering
  • Software in support of simulation and modeling; packages, languages
  <h3>Processing</h3>
  <h3>Interactive Visualization</h3>
  <h3>Data, Information, and Knowledge</h3> !!
  Content management models, frameworks, systems, design methods (as in IM. Information Management)
  • Digital representations of content including numbers, text, images (e.g., raster and vector), video (e.g.,
  QuickTime, MPEG2, MPEG4), audio (e.g., written score, MIDI, sampled digitized sound track) and
  animations; complex/composite/aggregate objects; FRBR
  • Digital content creation/capture and preservation, including digitization, sampling, compression,
  conversion, transformation/translation, migration/emulation, crawling, harvesting
  • Content structure / management, including digital libraries and static/dynamic/stream aspects for:
  o Data: data structures, databases
  o Information: document collections, multimedia pools, hyperbases (hypertext, hypermedia),
  catalogs, repositories
  o Knowledge: ontologies, triple stores, semantic networks, rules
  • Processing and pattern recognition, including indexing, searching (including: queries and query languages;
  central / federated / P2P), retrieving, clustering, classifying/categorizing, analyzing/mining/extracting,
  rendering, reporting, handling transactions
  • User / society support for presentation and interaction, including browse, search, filter, route, visualize,
  share, collaborate, rate, annotate, personalize, recommend
  • Modeling, design, logical and physical implementation, using relevant systems/software
  <h3>Numerical Analysis</h3>
  <h2>Discrete Structures (DS)</h2>
  <h3>Sets, Relations, and Functions</h3>
  Sets
  o Venn diagrams
  o Union, intersection, complement
  o Cartesian product
  o Power sets
  o Cardinality of finite sets
  • Relations
  o Reflexivity, symmetry, transitivity
  o Equivalence relations, partial orders
  • Functions
  o Surjections, injections, bijections
  o Inverses
  o Composition
  <h3>Basic Logic</h3>
  Propositional logic (cross-reference: Propositional logic is also reviewed in IS/Knowledge Based
  Reasoning)
  • Logical connectives
  • Truth tables
  • Normal forms (conjunctive and disjunctive)
  • Validity of well-formed formula
  • Propositional inference rules (concepts of modus ponens and modus tollens)
  • Predicate logic
  o Universal and existential quantification
  • Limitations of propositional and predicate logic (e.g., expressiveness issues)
  <h3>Proof Techniques</h3>
  Notions of implication, equivalence, converse, inverse, contrapositive, negation, and contradiction
  • The structure of mathematical proofs
  • Direct proofs
  • Disproving by counterexample
  • Proof by contradiction
  • Induction over natural numbers
  <h4>Principle of Mathematical Induction</h4>
  <p>For each natural number \(n \in \mathbb{N}\), suppose that \(P(n)\) denotes a proposition which is either
    true
    or
    false. Let \(A={n \in \mathbb{N}:P(n)}\) is true. Suppose the following conditions hold: a) \(1 \in A\) and
    b) for each \(k \in \mathbb{N}\), if \(k \in A\)
    , then \(k+1 \in A\). Then \(A=\mathbb{N}\).</p>
  • Structural induction
  • Weak and strong induction (i.e., First and Second Principle of Induction)
  • Recursive mathematical definitions
  <h3>Basics of Counting</h3>
  Counting arguments
  o Set cardinality and counting
  o Sum and product rule
  o Inclusion-exclusion principle
  o Arithmetic and geometric progressions
  • The pigeonhole principle
  • Permutations and combinations
  o Basic definitions
  o Pascal’s identity
  o The binomial theorem
  • Solving recurrence relations (cross-reference: AL/Basic Analysis)
  o An example of a simple recurrence relation, such as Fibonacci numbers
  o Other examples, showing a variety of solutions
  • Basic modular arithmetic
  <h3>Graphs and Trees</h3>
  Trees
  o Properties
  o Traversal strategies
  • Undirected graphs
  • Directed graphs
  • Weighted graphs
  <h3>Discrete Probability</h3>
  Finite probability space, events
  • Axioms of probability and probability measures
  • Conditional probability, Bayes’ theorem
  • Independence
  • Integer random variables (Bernoulli, binomial)
  • Expectation, including Linearity of Expectation
  <h2>Graphics and Visualization (GV)</h2> !!
  Media applications including user interfaces, audio and video editing, game engines, cad, visualization,
  virtual reality
  • Digitization of analog data, resolution, and the limits of human perception, e.g., pixels for visual display,
  dots for laser printers, and samples for audio (HCI/Foundations)
  • Use of standard APIs for the construction of UIs and display of standard media formats (see HCI/GUI
  construction)
  • Standard media formats, including lossless and lossy formats
  <h3>Fundamental Concepts</h3>
  <h3>Basic Rendering</h3>
  <h3>Geometric Modeling</h3>
  <h3>Advanced Rendering</h3>
  <h3>Computer Animation</h3>
  <h3>Visualization</h3>
  Visualization of 2D/3D scalar fields: color mapping, isosurfaces
  • Direct volume data rendering: ray-casting, transfer functions, segmentation
  • Visualization of:
  o Vector fields and flow data
  o Time-varying data
  o High-dimensional data: dimension reduction, parallel coordinates,
  o Non-spatial data: multi-variate, tree/graph structured, text
  • Perceptual and cognitive foundations that drive visual abstractions
  • Visualization design
  • Evaluation of visualization methods
  • Applications of visualization
  <h2>Human-Computer Interaction (HCI)</h2>
  <h3>Foundations</h3>
  Contexts for HCI (anything with a user interface, e.g., webpage, business applications, mobile applications,
  and games)
  • Processes for user-centered development, e.g., early focus on users, empirical testing, iterative design
  • Different measures for evaluation, e.g., utility, efficiency, learnability, user satisfaction
  • Usability heuristics and the principles of usability testing
  • Physical capabilities that inform interaction design, e.g., color perception, ergonomics
  • Cognitive models that inform interaction design, e.g., attention, perception and recognition, movement, and
  memory; gulfs of expectation and execution
  • Social models that inform interaction design, e.g., culture, communication, networks and organizations
  • Principles of good design and good designers; engineering tradeoffs
  • Accessibility, e.g., interfaces for differently-abled populations (e.g., blind, motion-impaired)
  • Interfaces for differently-aged population groups (e.g., children, 80+)
  <h3>Designing Interaction</h3>
  Principles of graphical user interfaces (GUIs)
  • Elements of visual design (layout, color, fonts, labeling)
  • Task analysis, including qualitative aspects of generating task analytic models
  • Low-fidelity (paper) prototyping
  • Quantitative evaluation techniques, e.g., keystroke-level evaluation
  • Help and documentation
  • Handling human/system failure
  • User interface standards
  <h3>Programming Interactive Systems</h3>
  Software Architecture Patterns, e.g., Model-View controller; command objects, online, offline (cross
  reference PL/Event Driven and Reactive Programming, where MVC is used in the context of event-driven
  programming)
  • Interaction Design Patterns: visual hierarchy, navigational distance
  • Event management and user interaction
  • Geometry management (cross-reference GV/Geometric Modelling)
  • Choosing interaction styles and interaction techniques
  • Presenting information: navigation, representation, manipulation
  • Interface animation techniques (e.g., scene graphs)
  • Widget classes and libraries
  • Modern GUI libraries (e.g. iOS, Android, JavaFX) GUI builders and UI programming environments (crossreference
  PBD/Mobile Platforms)
  • Declarative Interface Specification: Stylesheets and DOMs
  • Data-driven applications (database-backed web pages)
  • Cross-platform design
  • Design for resource-constrained devices (e.g. small, mobile devices)
  <h3>User-Centered Design and Testing</h3>
  Approaches to, and characteristics of, the design process
  • Functionality and usability requirements (cross-reference to SE/Requirements Engineering)
  • Techniques for gathering requirements, e.g., interviews, surveys, ethnographic and contextual enquiry
  • Techniques and tools for the analysis and presentation of requirements, e.g., reports, personas
  • Prototyping techniques and tools, e.g., sketching, storyboards, low-fidelity prototyping, wireframes
  • Evaluation without users, using both qualitative and quantitative techniques, e.g., walkthroughs, GOMS,
  expert-based analysis, heuristics, guidelines, and standards
  • Evaluation with users, e.g., observation, think-aloud, interview, survey, experiment
  • Challenges to effective evaluation, e.g., sampling, generalization
  • Reporting the results of evaluations
  • Internationalization, designing for users from other cultures, cross-cultural
  <h3>New Interactive Technologies</h3>
  Choosing interaction styles and interaction techniques
  • Representing information to users: navigation, representation, manipulation
  • Approaches to design, implementation and evaluation of non-mouse interaction
  o Touch and multi-touch interfaces
  o Shared, embodied, and large interfaces
  o New input modalities (such as sensor and location data)
  o New Windows, e.g., iPhone, Android
  o Speech recognition and natural language processing (cross reference IS/Natural Language
  Processing)
  o Wearable and tangible interfaces
  o Persuasive interaction and emotion
  o Ubiquitous and context-aware interaction technologies (Ubicomp)
  o Bayesian inference (e.g. predictive text, guided pointing)
  o Ambient/peripheral display and interaction
  <h3>Collaboration and Communication</h3>
  <h3>Statistical Methods for HCI</h3>
  <h3>Human Factors and Security</h3>
  <h3>Design-Oriented HCI</h3>
  <h3>Mixed, Augmented and Virtual Reality</h3>
  Output
  o Sound
  o Stereoscopic display
  o Force feedback simulation, haptic devices
  • User input
  o Viewer and object tracking
  o Pose and gesture recognition
  o Accelerometers
  o Fiducial markers
  o User interface issues
  • Physical modelling and rendering
  o Physical simulation: collision detection & response, animation
  o Visibility computation
  o Time-critical rendering, multiple levels of details (LOD)
  • System architectures
  o Game engines
  o Mobile augmented reality
  o Flight simulators
  o CAVEs
  o Medical imaging
  • Networking
  o p2p, client-server, dead reckoning, encryption, synchronization
  o Distributed collaboration
  <h2>Information Assurance and Security (IAS)</h2>
  <h3>Foundational Concepts in Security</h3>
  <h3>Principles of Secure Design</h3>
  <h3>Defensive Programming</h3>
  <h3>Threats and Attacks</h3>
  <h3>Network Security</h3>
  <h3>Cryptography</h3>
  <h3>Web Security</h3>
  <h3>Platform Security</h3>
  <h3>Security Policy and Governance</h3>
  <h3>Digital Forensics</h3>
  <h3>Secure Software Engineering</h3>
  <h2>Information Management (IM)</h2>
  <h3>Information Management Concepts</h3>
  Information systems as socio-technical systems
  • Basic information storage and retrieval (IS&R) concepts
  • Information capture and representation
  • Supporting human needs: searching, retrieving, linking, browsing, navigating
  Approaches to and evolution of database systems
  • Components of database systems
  Design of core DBMS functions (e.g., query mechanisms, transaction management, buffer management,
  access methods)
  • Database architecture and data independence
  • Use of a declarative query language
  • Systems supporting structured and/or stream content
  <h3>Database Systems</h3>
  <h3>Data Modeling</h3>
  Data modeling
  • Conceptual models (e.g., entity-relationship, UML diagrams)
  • Spreadsheet models
  • Relational data models
  • Object-oriented models (cross-reference PL/Object-Oriented Programming)
  • Semi-structured data model (expressed using DTD or XML Schema, for example)
  <h3>Indexing</h3>
  The impact of indices on query performance
  • The basic structure of an index
  • Keeping a buffer of data in memory
  • Creating indexes with SQL
  • Indexing text
  • Indexing the web (e.g., web crawling)
  <h3>Relational Databases</h3>
  Mapping conceptual schema to a relational schema
  • Entity and referential integrity
  • Relational algebra and relational calculus
  • Relational Database design
  • Functional dependency
  • Decomposition of a schema; lossless-join and dependency-preservation properties of a decomposition
  • Candidate keys, superkeys, and closure of a set of attributes
  • Normal forms (BCNF)
  • Multi-valued dependency (4NF)
  • Join dependency (PJNF, 5NF)
  • Representation theory
  <h3>Query Languages</h3>
  Overview of database languages
  • SQL (data definition, query formulation, update sublanguage, constraints, integrity)
  • Selections
  • Projections
  • Select-project-join
  • Aggregates and group-by
  • Subqueries
  • QBE and 4th-generation environments
  • Different ways to invoke non-procedural queries in conventional languages
  • Introduction to other major query languages (e.g., XPATH, SPARQL)
  • Stored procedures
  <h3>Transaction Processing</h3>
  Transactions
  • Failure and recovery
  • Concurrency control
  • Interaction of transaction management with storage, especially buffering
  <h3>Distributed Databases</h3>
  <h3>Physical Database Design</h3>
  <h3>Data Mining</h3>
  Uses of data mining
  • Data mining algorithms
  • Associative and sequential patterns
  • Data clustering
  • Market basket analysis
  • Data cleaning
  • Data visualization (cross-reference GV/Visualization and CN/Interactive Visualization)
  <h3>Information Storage and Retrieval</h3>
  Documents, electronic publishing, markup, and markup languages
  • Tries, inverted files, PAT trees, signature files, indexing
  • Morphological analysis, stemming, phrases, stop lists
  • Term frequency distributions, uncertainty, fuzziness, weighting
  • Vector space, probabilistic, logical, and advanced models
  • Information needs, relevance, evaluation, effectiveness
  • Thesauri, ontologies, classification and categorization, metadata
  • Bibliographic information, bibliometrics, citations
  • Routing and (community) filtering
  • Multimedia search, information seeking behavior, user modeling, feedback
  • Information summarization and visualization
  • Faceted search (e.g., using citations, keywords, classification schemes)
  • Digital libraries
  • Digitization, storage, interchange, digital objects, composites, and packages
  • Metadata and cataloging
  • Naming, repositories, archives
  • Archiving and preservation, integrity
  • Spaces (conceptual, geographical, 2/3D, VR)
  • Architectures (agents, buses, wrappers/mediators), interoperability
  • Services (searching, linking, browsing, and so forth)
  • Intellectual property rights management, privacy, and protection (watermarking)
  <h3>Multimedia Systems</h3>
  • Input and output devices, device drivers, control signals and protocols, DSPs
  • Standards (e.g., audio, graphics, video)
  • Applications, media editors, authoring systems, and authoring
  • Streams/structures, capture/represent/transform, spaces/domains, compression/coding
  • Content-based analysis, indexing, and retrieval of audio, images, animation, and video
  Presentation, rendering, synchronization, multi-modal integration/interfaces
  • Real-time delivery, quality of service (including performance), capacity planning, audio/video
  conferencing, video-on-demand
  <h2>Intelligent Systems (IS)</h2>
  <h3>Fundamental Issues</h3>
  <h3>Basic Search Strategies</h3>
  <h3>Basic Knowledge Representation and Reasoning</h3>
  Review of propositional and predicate logic (cross-reference DS/Basic Logic)
  • Resolution and theorem proving (propositional logic only)
  • Forward chaining, backward chaining
  • Review of probabilistic reasoning, Bayes theorem (cross-reference with DS/Discrete Probability)
  <h3>Basic Machine Learning</h3>
  <h3>Advanced Search</h3>
  <h3>Advanced Representation and Reasoning</h3>
  <h3>Reasoning Under Uncertainty</h3>
  Review of basic probability (cross-reference DS/Discrete Probability)
  • Random variables and probability distributions
  o Axioms of probability
  o Probabilistic inference
  o Bayes’ Rule
  • Conditional Independence
  • Knowledge representations
  o Bayesian Networks
   Exact inference and its complexity
   Randomized sampling (Monte Carlo) methods (e.g. Gibbs sampling)
  o Markov Networks
  o Relational probability models
  o Hidden Markov Models
  • Decision Theory
  o Preferences and utility functions
  o Maximizing expected utility
  <h3>Agents</h3>
  Definitions of agents
  • Agent architectures (e.g., reactive, layered, cognitive)
  • Agent theory
  • Rationality, game theory
  o Decision-theoretic agents
  o Markov decision processes (MDP)
  • Software agents, personal assistants, and information access
  o Collaborative agents
  o Information-gathering agents
  o Believable agents (synthetic characters, modeling emotions in agents)
  • Learning agents
  • Multi-agent systems
  o Collaborating agents
  o Agent teams
  o Competitive agents (e.g., auctions, voting)
  o Swarm systems and biologically inspired models
  <h3>Natural Language Processing</h3>
  Deterministic and stochastic grammars
  • Parsing algorithms
  o CFGs and chart parsers (e.g. CYK)
  o Probabilistic CFGs and weighted CYK
  • Representing meaning / Semantics
  o Logic-based knowledge representations
  o Semantic roles
  o Temporal representations
  o Beliefs, desires, and intentions
  • Corpus-based methods
  • N-grams and HMMs
  • Smoothing and backoff
  Examples of use: POS tagging and morphology
  • Information retrieval (Cross-reference IM/Information Storage and Retrieval)
  o Vector space model
   TF & IDF
  o Precision and recall
  • Information extraction
  • Language translation
  • Text classification, categorization
  o Bag of words model
  <h3>Advanced Machine Learning</h3>
  Definition and examples of broad variety of machine learning tasks
  • General statistical-based learning, parameter estimation (maximum likelihood)
  • Inductive logic programming (ILP)
  • Supervised learning
  o Learning decision trees
  o Learning neural networks
  o Support vector machines (SVMs)
  • Ensembles
  • Nearest-neighbor algorithms
  • Unsupervised Learning and clustering
  o EM
  o K-means
  o Self-organizing maps
  • Semi-supervised learning
  • Learning graphical models (Cross-reference IS/Reasoning under Uncertainty)
  • Performance evaluation (such as cross-validation, area under ROC curve)
  • Learning theory
  • The problem of overfitting, the curse of dimensionality
  • Reinforcement learning
  o Exploration vs. exploitation trade-off
  o Markov decision processes
  o Value and policy iteration
  • Application of Machine Learning algorithms to Data Mining (cross-reference IM/Data Mining)
  <h3>Robotics</h3>
  Overview: problems and progress
  o State-of-the-art robot systems, including their sensors and an overview of their sensor processing
  o Robot control architectures, e.g., deliberative vs. reactive control and Braitenberg vehicles
  o World modeling and world models
  o Inherent uncertainty in sensing and in control
  • Configuration space and environmental maps
  • Interpreting uncertain sensor data
  • Localizing and mapping
  • Navigation and control
  • Motion planning
  • Multiple-robot coordination
  <h3>Perception and Computer Vision</h3>
  Computer vision
  o Image acquisition, representation, processing and properties
  o Shape representation, object recognition and segmentation
  o Motion analysis
  • Audio and speech recognition
  • Modularity in recognition
  • Approaches to pattern recognition (cross-reference IS/Advanced Machine Learning)
  o Classification algorithms and measures of classification quality
  o Statistical techniques
  <h2>Networking and Communication (NC)</h2>
  <h3>Introduction</h3>
  Organization of the Internet (Internet Service Providers, Content Providers, etc.)
  • Switching techniques (e.g., circuit, packet)
  • Physical pieces of a network, including hosts, routers, switches, ISPs, wireless, LAN, access point, and
  firewalls
  • Layering principles (encapsulation, multiplexing)
  • Roles of the different layers (application, transport, network, datalink, physical)
  <h3>Networked Applications</h3>
  Naming and address schemes (DNS, IP addresses, Uniform Resource Identifiers, etc.)
  • Distributed applications (client/server, peer-to-peer, cloud, etc.)
  • HTTP as an application layer protocol
  • Multiplexing with TCP and UDP
  • Socket APIs
  <h3>Reliable Data Delivery</h3>
  <h3>Routing and Forwarding</h3>
  <h3>Local Area Networks</h3>
  <h3>Resource Allocation</h3>
  <h3>Mobility</h3>
  <h3>Social Networking</h3>
  <h2>Operating Systems (OS)</h2>
  <h3>Overview of Operating Systems</h3>
  <h3>Operating System Principles</h3>
  <h3>Concurrency</h3>
  <h3>Scheduling and Dispatch</h3>
  <h3>Memory Management</h3>
  <h3>Security and Protection</h3>
  <h3>Virtual Machines</h3>
  <h3>Device Management</h3>
  <h3>File Systems</h3>
  <h3>Real Time and Embedded Systems</h3>
  <h3>Fault Tolerance</h3>
  <h3>System Performance Evaluation</h3>
  <h2>Platform-Based Development (PBD)</h2>
  <h3>Introduction</h3>
  <h3>Web Platforms</h3>
  <h3>Mobile Platforms</h3>
  <h3>Industrial Platforms</h3>
  <h3>Game Platforms</h3>
  <h2>Parallel and Distributed Computing (PD)</h2>
  <h3>Parallelism Fundamentals</h3>
  Multiple simultaneous computations
  • Goals of parallelism (e.g., throughput) versus concurrency (e.g., controlling access to shared resources)
  • Parallelism, communication, and coordination
  o Programming constructs for coordinating multiple simultaneous computations
  o Need for synchronization
  • Programming errors not found in sequential programming
  o Data races (simultaneous read/write or write/write of shared state)
  o Higher-level races (interleavings violating program intention, undesired non-determinism)
  o Lack of liveness/progress (deadlock, starvation)
  <h3>Parallel Decomposition</h3>
  <h3>Communication and Coordination</h3>
  <h3>Parallel Algorithms, Analysis, and Programming</h3>
  <h3>Parallel Architecture</h3>
  <h3>Parallel Performance</h3>
  <h3>Distributed Systems</h3>
  <h3>Cloud Computing</h3>
  <h3>Formal Models and Semantics</h3>
  <h2>Programmign Languages (PL)</h2>
  <h3>Object-Oriented Programming</h3>
  <h3>Functional Programming</h3>
  <h3>Event-Driven and Reactive Programming</h3>
  <h3>Basic Type Systems</h3>
  A type as a set of values together with a set of operations
  o Primitive types (e.g., numbers, Booleans)
  o Compound types built from other types (e.g., records, unions, arrays, lists, functions, references)
  • Association of types to variables, arguments, results, and fields
  • Type safety and errors caused by using values inconsistently given their intended types
  • Goals and limitations of static typing
  o Eliminating some classes of errors without running the program
  o Undecidability means static analysis must conservatively approximate program behavior
  <h3>Program Representation</h3>
  Programs that take (other) programs as input such as interpreters, compilers, type-checkers, documentation
  generators
  • Abstract syntax trees; contrast with concrete syntax
  • Data structures to represent code for execution, translation, or transmission
  <h3>Language Translation and Execution</h3>
  <h3>Syntax Analysis</h3>
  <h3>Compiler Semantic Analysis</h3>
  <h3>Code Generation</h3>
  <h3>Runtime Systems</h3>
  <h3>Static Analysis</h3>
  <h3>Advanced Programming Constructs</h3>
  <h3>Concurrency and Parallelism</h3>
  <h3>Type Systems</h3>
  <h3>Formal Semantics</h3>
  <h3>Language Pragmatics</h3>
  <h3>Logic Programming</h3>
  <h2>Software Development Fundamentals (SDF)</h2>
  <h3>Algorithms and Design</h3>
  <h3>Fundamental Programming Concepts</h3>
  Basic syntax and semantics of a higher-level language
  • Variables and primitive data types (e.g., numbers, characters, Booleans)
  • Expressions and assignments
  • Simple I/O including file I/O
  • Conditional and iterative control structures
  • Functions and parameter passing
  • The concept of recursion
  <h3>Fundamental Data Structures</h3>
  Arrays
  • Records/structs (heterogeneous aggregates)
  • Strings and string processing
  • Abstract data types and their implementation
  o Stacks
  o Queues
  o Priority queues
  o Sets
  o Maps
  • References and aliasing
  • Linked lists
  • Strategies for choosing the appropriate data structure
  <h3>Development Methods</h3>
  <h2>Software Engineering (SE)</h2>
  <h3>Software Processes</h3>
  <h3>Software Project Management</h3>
  <h3>Tools and Environments</h3>
  Software configuration management and version control
  • Release management
  • Requirements analysis and design modeling tools
  • Testing tools including static and dynamic analysis tools
  • Programming environments that automate parts of program construction processes (e.g., automated builds)
  o Continuous integration
  • Tool integration concepts and mechanisms
  <h3>Requirements Engineering</h3>
  <h3>Software Design</h3>
  System design principles: levels of abstraction (architectural design and detailed design), separation of
  concerns, information hiding, coupling and cohesion, re-use of standard structures
  • Design Paradigms such as structured design (top-down functional decomposition), object-oriented analysis
  and design, event driven design, component-level design, data-structured centered, aspect oriented,
  function oriented, service oriented
  • Structural and behavioral models of software designs
  • Design patterns
  <h3>Software Construction</h3>
  <h3>Software Verification and Validation</h3>
  <h3>Software Evolution</h3>
  <h3>Software Reliability</h3>
  <h3>Formal Methods</h3>
  <h2>Systems Fundamentals (SF)</h2>
  <h3>Computational Paradigms</h3>
  Basic building blocks and components of a computer (gates, flip-flops, registers, interconnections;
  Datapath + Control + Memory)
  • Hardware as a computational paradigm: Fundamental logic building blocks; Logic expressions,
  minimization, sum of product forms
  • Application-level sequential processing: single thread
  • Simple application-level parallel processing: request level (web services/client-server/distributed), single
  thread per server, multiple threads with multiple servers
  • Basic concept of pipelining, overlapped processing stages
  • Basic concept of scaling: going faster vs. handling larger problems
  <h3>Cross-Layer Communications</h3>
  <h3>State and State Machines</h3>
  <h3>Parallelism</h3>
  Sequential vs. parallel processing
  • Parallel programming vs. concurrent programming
  • Request parallelism vs. Task parallelism
  • Client-Server/Web Services, Thread (Fork-Join), Pipelining
  • Multicore architectures and hardware support for synchronization
  <h3>Evaluation</h3>
  <h3>Resource Allocation and Scheduling</h3>
  Kinds of resources (e.g., processor share, memory, disk, net bandwidth)
  • Kinds of scheduling (e.g., first-come, priority)
  • Advantages of fair scheduling, preemptive scheduling
  <h3>Proximity</h3>
  Speed of light and computers (one foot per nanosecond vs. one GHz clocks)
  • Latencies in computer systems: memory vs. disk latencies vs. across the network memory
  • Caches and the effects of spatial and temporal locality on performance in processors and systems
  • Caches and cache coherency in databases, operating systems, distributed systems, and computer
  architecture
  • Introduction into the processor memory hierarchy and the formula for average memory access time
  <h3>Virtualization and Isolation</h3>
  <h3>Reliability through Reduncancy</h3>
  <h3>Quantitative Evaluation</h3>
  <h2>Social Issues and Professional Practice (SP)</h2>
  <h3>Social Context</h3>
  Social implications of computing in a networked world (cross-reference HCI/Foundations/social models;
  IAS/Fundamental Concepts/social issues)
  • Impact of social media on individualism, collectivism and culture
  Growth and control of the Internet (cross-reference NC/Introduction/organization of the Internet)
  • Often referred to as the digital divide, differences in access to digital technology resources and its
  resulting
  ramifications for gender, class, ethnicity, geography, and/or underdeveloped countries.
  • Accessibility issues, including legal requirements
  • Context-aware computing (cross-reference HCI/Design for non-mouse interfaces/ ubiquitous and contextaware)
  <h3>Analytical Tools</h3>
  <h3>Professional Ethics</h3>
  <h3>Intellectual Property</h3>
  Philosophical foundations of intellectual property
  • Intellectual property rights (cross-reference IM/Information Storage and Retrieval/intellectual property and
  protection)
  • Intangible digital intellectual property (IDIP)
  • Legal foundations for intellectual property protection
  • Digital rights management
  • Copyrights, patents, trade secrets, trademarks
  • Plagiarism
  <h3>Privacy and Civil Liberties</h3>
  <h3>Professional Communication</h3>
  <h3>Sustainability</h3>
  <h3>History</h3>
  <h3>Economics of Computing</h3>
  <h3>Security Policies, Laws and Computer Crimes</h3>


  <h4>Principal Component Analysis</h4>
  <p>PCA is a dimensionality-reduction method used to reduce the dimensionality of large data sets, by
    transforming
    a
    large set of variables into a smaller one that still contains most of the information in the large set. The
    goal
    is
    to keep as much accuracy as possible while allowing for simplicity.</p>
  <p>The first step of PCA is standardization, which standardizes the range of continuous initial variables so
    that
    each
    one contributes equally to the analysis. If this is not performed, differences in the larger ranges will
    dominate
    over those with small ranges. This can be done mathematically by finding the z-score:</p>
  $$z=\frac{\text{value}-\text{mean}}{\text{standard deviation}}$$
  <p>The next step is covariance matrix computation. This aims to understand how the variables of the input data
    set
    are
    varying from the mean with respect to each other, to see if there is any relationship between them. The
    covariance
    matrix is a \(p\times p\) symmetric matrix (where p is the number of dimensions) that has as entries the
    covariances
    associated with all possible pairs of the initial variables. For example, a data set with 3 dimensions (say x,
    y,
    and z) would have a covariance matrix in this form:</p>
  $$ \left[
  \begin{array}{c}
  Cov(x,x)&Cov(x,y)&Cov(x,z)\\
  Cov(y,x)&Cov(y,y)&Cov(y,z)\\
  Cov(z,x)&Cov(z,y)&Cov(z,z)
  \end{array}
  \right] $$
  <p>Since the covariance of a variable with itself is its variance, the mani diagonal (top left to bottom right)
    is
    just the variances of each initial variable. And since the covariance is commutative (Cov(a,b,)=Cov(b,a)), the
    entries of the covariance matrix are symmetric with respect to the main diagonal.</p>
  <p>The next step is to compute the eigenvectors and eigenvalues of the covariance matrix to identify the
    principal
    components. Principal components are new variables that are constructed as linear combinations or mixtures of
    initial variables, but done in a way such that most of the information is compressed into the first
    components.
    So,
    10-dimensional data still gives you 10 principal components, but tries to put the maximum possible information
    into
    the first component, then the maximum remaining information in the second, and so on. Thus, you can discard
    components with low information and consider remaining components as your new variables. Geometrically
    speaking,
    principal components represent the directions of the data that explain a maximal amount of variance. Simply
    put,
    think of principal components as new axes that provide the best angle to see and evaluate the data, so that
    differences between observations are better visible. They are lines that maximize the variance (average of
    squared
    distances from the projected points to the origin).</p>
  <img src="{{url_for('static',filename='img/computer_science/PCA.gif')}}" style="width: 70%" alt="Builtin.com">
  <p>Now let's go back to eigenvectors and eigenvalues. Every eigenvector has an eigenvalue, and their number is
    equal
    to the number of dimensions of the data. For example, for a 3-dimensional data set, there are 3 variables and
    thus 3
    eigenvectors with 3 corresponding eigenvalues. The eigenvectors of the Covariance matrix are the directions of
    the
    axes where there is the most variance and that we call Principal Components. And eigenvalues are simply the
    coefficients attached to eigenvactors, which give the amount of variance carried in each Principal Component.
  </p>
  <p>Next, we create the feature vector. After we have ranked the principal components in order of significance,
    we
    choose which components we wish to discard, and form the remaining ones a matrix of vectors that we call the
    feature
    vector. This makes it the first step in dimensionality reduction, because we have removed principal
    components.
  </p>
  <p>Finally, we recast the data along the principal components axes. We use the feature vector to reorient the
    data
    from the original axes to the one represented by the principal components. This can be done by multiplying the
    transpose of the original data set by the transpose of the feature vector.</p>
  <h4>k-means clustering</h4>
  <p>k-means clustering is a method of vector quantization, originally from signal processing, that aims to
    partitian n
    observations into k clusters in whcih each observation belongs to the cluster with the nearest mean.</p>
  <h4>Uniform Manifold Approximation and Projection for Dimension Reduction</h4>
  <p>UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension
    reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic
    topology.
    The
    result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive
    with
    t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time
    performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a
    general purpose dimension reduction technique for machine learning.</p>

  <h3>MongoDB-Express-Angular-NodeJS (MEAN) Stack</h3>
  <h4>Angular</h4>
  <p>Angular is a client-side (browser) framework which allows you to build Single-Page-Applications (SPA). It
    creates
    "mobile app"-like websites because there is no refreshing of the page.</p>
  <h4>NodeJS</h4>
  <p>NodeJS is a server-side library. It listens to requests and sends responses.</p>
  <h4>Express</h4>
  <p>Express is a Node framework which simplifies writing server-side code and logic.</p>
  <h4>mongoDB</h4>
  <p>mongoDB is a noSQL database which stores "documents" in collections" instead of "records" in "tables" as in
    SQL. It
    stores application data (users, products, etc.). It is more flexible in terms of structure compared to SQL.
  </p>
  <p>First you need to download and install NodeJS. Then install the Angular CLI. Then create a new Angular
    project
    (ng
    new). 'ng serve' will serve the project.</p>
  <p>Each component needs logic (ts file) and template (html file).</p>
</div>
{% endblock %}