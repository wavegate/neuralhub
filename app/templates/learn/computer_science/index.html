{% extends 'base.html' %}

{% block content %}
<style>
  .size {
    font-size: 130%;
  }
</style>

<h4>Kernel</h4>
<p>The kernel is a computer progrma at the core of a computer's operating system that generally has complete control
  over everything in the system. It is the portion of the operating system that is always resident in memory, and
  facilitates interactions between hardware and software components. It controls all hardware resources (e.g. I/O,
  memory, cryptography) via device drivers, arbitrates conflicts between processes concerning such resources, and
  optimizes the utilization of common resources e.g. CPU & cache usage, file systems, and network sockets. It is one of
  the first programs loaded on startup (after the bootloader). It connects the application software to the hardware of a
  computer.</p>
<h4>Operating system</h4>
<p>An operating system is system software that manages computer hardware, software resources, and provides common
  services for computer programs.</p>
<h4>Assembly language</h4>
<p>Assembly language, or assembler language, is any low-level programming language in which there is a very strong
  correspondence between the instructions in the language and the architecture's machine code instructions. It usually
  has
  one statement per machine instruction. Assembly code is converted into executable machine code by a utility program
  reffered to as an assembler. The term originally meant "a program that assembles another program consisting of several
  sections into a single program." The conversion process is referred to as assembly, as in assembling the source code.
</p>
<h4>Linux</h4>
<p>Linux is a family of free and open-source operating systems based on the Linux kernel, examples include Debian,
  Ubuntu, Fedora, CentOS, Gentoo, Arch Linux, and many others. 90% of all cloud infrastructure and 74% of the world's
  smartphones are powered by Linux. Linux-based operating systems depend heavily on working with the command line
  interface, while most personal computers rely on graphical interfaces. Linux filesystems also have a different
  structure than those found on Windows or MacOS.</p>
<h4>Terminal</h4>
<p>A terminal is an input and output environment that presents a text-only window running a shell. A shell is a program
  that exposes the computer's operating system to a user or program. In Linux systems, the shell presented in a terminal
  is a command line interpreter. A command line interface is a user interface which processes commands to a computer
  program and outputs the results.</p>
<div class="size">
  https://www.acm.org/binaries/content/assets/education/cs2013_web_final.pdf
  <p>The top core competencies from computer science for general application include software development fundamentals,
    discrete structures, algorithms and complexity, and systems fundamentals.</p>
  <h1>Computer Science</h1>
  <h2>Algorithms and Complexity (AL)</h2>
  <h3>Basic Analysis</h3>
  Differences among best, expected, and worst case behaviors of an algorithm
  • Asymptotic analysis of upper and expected complexity bounds
  • Big O notation: formal definition
  • Complexity classes, such as constant, logarithmic, linear, quadratic, and exponential
  • Empirical measurements of performance
  • Time and space trade-offs in algorithms
  <h3>Algorithmic Strategies</h3>
  <h3>Fundamental Data Structures and Algorithms</h3>
  Simple numerical algorithms, such as computing the average of a list of numbers, finding the min, max,
  and mode in a list, approximating the square root of a number, or finding the greatest common divisor
  • Sequential and binary search algorithms
  • Worst case quadratic sorting algorithms (selection, insertion)
  • Worst or average case O(N log N) sorting algorithms (quicksort, heapsort, mergesort)
  • Hash tables, including strategies for avoiding and resolving collisions
  • Binary search trees
  o Common operations on binary search trees such as select min, max, insert, delete, iterate over tree
  • Graphs and graph algorithms
  o Representations of graphs (e.g., adjacency list, adjacency matrix)
  o Depth- and breadth-first traversals
  Heaps
  • Graphs and graph algorithms
  o Shortest-path algorithms (Dijkstra’s and Floyd’s algorithms)
  o Minimum spanning tree (Prim’s and Kruskal’s algorithms)
  • Pattern matching and string/text algorithms (e.g., substring matching, regular expression matching, longest
  common subsequence algorithms)
  <h3>Basic Automata Computability and Complexity</h3>
  Finite-state machines
  • Regular expressions
  • The halting problem
  <h3>Advanced Computational Complexity</h3>
  <h3>Advanced Automata Theory and Computability</h3>
  <h3>Advanced Data Structures Algorithms and Analysis</h3>
  <h2>Architecture and Organization (AR)</h2>
  <h3>Digital Logic and Digital Systems</h3>
  <h3>Machine Level Representation of Data</h3>
  Bits, bytes, and words
  • Numeric data representation and number bases
  • Fixed- and floating-point systems
  • Signed and twos-complement representations
  • Representation of non-numeric data (character codes, graphical data)
  • Representation of records and arrays
  <h3>Assembly Level Machine Organization</h3>
  <h3>Memory System Organization and Architecture</h3>
  Storage systems and their technology
  • Memory hierarchy: importance of temporal and spatial locality
  • Main memory organization and operations
  • Latency, cycle time, bandwidth, and interleaving
  • Cache memories (address mapping, block size, replacement and store policy)
  • Multiprocessor cache consistency/Using the memory system for inter-core synchronization/atomic memory
  operations
  • Virtual memory (page table, TLB)
  • Fault handling and reliability
  • Error coding, data compression, and data integrity (cross-reference SF/Reliability through Redundancy)
  <h3>Interfacing and Communication</h3>
  <h3>Functional Organization</h3>
  <h3>Multiprocessing and Alternative Architectures</h3>
  <h3>Performance Enhancements</h3>
  <h2>Computational Science (CN)</h2>
  <p>Computational science is a field of applied computer science, that is, the application of computer science to solve
    problems across a range of disciplines. It combines computer simulation, scientific visualization, mathematical
    modeling, computer programming and data structures, networking, database design, symbolic computation, and high
    performance computing with various disciplines. The needs of scientists and engineers for computation have long
    driven research and innovation in computing. Computational neuroscience is a subfield of computational science.</p>
  <p>A goal in neural engineering is to abstract the concept of the brain. But the brain trying to model itself is a bit
    meta. Some say that dreams are essential models of various situations our subconscious is trying to prepare us for.
    In order to understand the brain, we should understand various modeling and simulation techniques used in computer
    science.</p>
  <h3>Introduction to Modeling and Simulation</h3>
  Models as abstractions of situations
  • Simulations as dynamic modeling
  • Simulation techniques and tools, such as physical simulations, human-in-the-loop guided simulations, and
  virtual reality
  • Foundational approaches to validating models (e.g., comparing a simulation’s output to real data or the
  output of another model)
  • Presentation of results in a form relevant to the system being modeled
  <h3>Modeling and Simulation</h3>
  Purpose of modeling and simulation including optimization; supporting decision making, forecasting,
  safety considerations; for training and education
  • Tradeoffs including performance, accuracy, validity, and complexity
  • The simulation process; identification of key characteristics or behaviors, simplifying assumptions;
  validation of outcomes
  • Model building: use of mathematical formulas or equations, graphs, constraints; methodologies and
  techniques; use of time stepping for dynamic systems
  Formal models and modeling techniques: mathematical descriptions involving simplifying assumptions
  and avoiding detail. Examples of techniques include:
  o Monte Carlo methods
  o Stochastic processes
  o Queuing theory
  o Petri nets and colored Petri nets
  o Graph structures such as directed graphs, trees, networks
  o Games, game theory, the modeling of things using game theory
  o Linear programming and its extensions
  o Dynamic programming
  o Differential equations: ODE, PDE
  o Non-linear techniques
  o State spaces and transitions
  • Assessing and evaluating models and simulations in a variety of contexts; verification and validation of
  models and simulations
  • Important application areas including health care and diagnostics, economics and finance, city and urban
  planning, science, and engineering
  • Software in support of simulation and modeling; packages, languages
  <h3>Processing</h3>
  <h3>Interactive Visualization</h3>
  <h3>Data, Information, and Knowledge</h3> !!
  Content management models, frameworks, systems, design methods (as in IM. Information Management)
  • Digital representations of content including numbers, text, images (e.g., raster and vector), video (e.g.,
  QuickTime, MPEG2, MPEG4), audio (e.g., written score, MIDI, sampled digitized sound track) and
  animations; complex/composite/aggregate objects; FRBR
  • Digital content creation/capture and preservation, including digitization, sampling, compression,
  conversion, transformation/translation, migration/emulation, crawling, harvesting
  • Content structure / management, including digital libraries and static/dynamic/stream aspects for:
  o Data: data structures, databases
  o Information: document collections, multimedia pools, hyperbases (hypertext, hypermedia),
  catalogs, repositories
  o Knowledge: ontologies, triple stores, semantic networks, rules
  • Processing and pattern recognition, including indexing, searching (including: queries and query languages;
  central / federated / P2P), retrieving, clustering, classifying/categorizing, analyzing/mining/extracting,
  rendering, reporting, handling transactions
  • User / society support for presentation and interaction, including browse, search, filter, route, visualize,
  share, collaborate, rate, annotate, personalize, recommend
  • Modeling, design, logical and physical implementation, using relevant systems/software
  <h3>Numerical Analysis</h3>
  <h2>Discrete Structures (DS)</h2>
  <h3>Sets, Relations, and Functions</h3>
  Sets
  o Venn diagrams
  o Union, intersection, complement
  o Cartesian product
  o Power sets
  o Cardinality of finite sets
  • Relations
  o Reflexivity, symmetry, transitivity
  o Equivalence relations, partial orders
  • Functions
  o Surjections, injections, bijections
  o Inverses
  o Composition
  <h3>Basic Logic</h3>
  Propositional logic (cross-reference: Propositional logic is also reviewed in IS/Knowledge Based
  Reasoning)
  • Logical connectives
  • Truth tables
  • Normal forms (conjunctive and disjunctive)
  • Validity of well-formed formula
  • Propositional inference rules (concepts of modus ponens and modus tollens)
  • Predicate logic
  o Universal and existential quantification
  • Limitations of propositional and predicate logic (e.g., expressiveness issues)
  <h3>Proof Techniques</h3>
  Notions of implication, equivalence, converse, inverse, contrapositive, negation, and contradiction
  • The structure of mathematical proofs
  • Direct proofs
  • Disproving by counterexample
  • Proof by contradiction
  • Induction over natural numbers
  <h4>Principle of Mathematical Induction</h4>
  <p>For each natural number \(n \in \mathbb{N}\), suppose that \(P(n)\) denotes a proposition which is either true or
    false. Let \(A={n \in \mathbb{N}:P(n)}\) is true. Suppose the following conditions hold: a) \(1 \in A\) and
    b) for each \(k \in \mathbb{N}\), if \(k \in A\)
    , then \(k+1 \in A\). Then \(A=\mathbb{N}\).</p>
  • Structural induction
  • Weak and strong induction (i.e., First and Second Principle of Induction)
  • Recursive mathematical definitions
  <h3>Basics of Counting</h3>
  Counting arguments
  o Set cardinality and counting
  o Sum and product rule
  o Inclusion-exclusion principle
  o Arithmetic and geometric progressions
  • The pigeonhole principle
  • Permutations and combinations
  o Basic definitions
  o Pascal’s identity
  o The binomial theorem
  • Solving recurrence relations (cross-reference: AL/Basic Analysis)
  o An example of a simple recurrence relation, such as Fibonacci numbers
  o Other examples, showing a variety of solutions
  • Basic modular arithmetic
  <h3>Graphs and Trees</h3>
  Trees
  o Properties
  o Traversal strategies
  • Undirected graphs
  • Directed graphs
  • Weighted graphs
  <h3>Discrete Probability</h3>
  Finite probability space, events
  • Axioms of probability and probability measures
  • Conditional probability, Bayes’ theorem
  • Independence
  • Integer random variables (Bernoulli, binomial)
  • Expectation, including Linearity of Expectation
  <h2>Graphics and Visualization (GV)</h2> !!
  Media applications including user interfaces, audio and video editing, game engines, cad, visualization,
  virtual reality
  • Digitization of analog data, resolution, and the limits of human perception, e.g., pixels for visual display,
  dots for laser printers, and samples for audio (HCI/Foundations)
  • Use of standard APIs for the construction of UIs and display of standard media formats (see HCI/GUI
  construction)
  • Standard media formats, including lossless and lossy formats
  <h3>Fundamental Concepts</h3>
  <h3>Basic Rendering</h3>
  <h3>Geometric Modeling</h3>
  <h3>Advanced Rendering</h3>
  <h3>Computer Animation</h3>
  <h3>Visualization</h3>
  Visualization of 2D/3D scalar fields: color mapping, isosurfaces
  • Direct volume data rendering: ray-casting, transfer functions, segmentation
  • Visualization of:
  o Vector fields and flow data
  o Time-varying data
  o High-dimensional data: dimension reduction, parallel coordinates,
  o Non-spatial data: multi-variate, tree/graph structured, text
  • Perceptual and cognitive foundations that drive visual abstractions
  • Visualization design
  • Evaluation of visualization methods
  • Applications of visualization
  <h2>Human-Computer Interaction (HCI)</h2>
  <h3>Foundations</h3>
  Contexts for HCI (anything with a user interface, e.g., webpage, business applications, mobile applications,
  and games)
  • Processes for user-centered development, e.g., early focus on users, empirical testing, iterative design
  • Different measures for evaluation, e.g., utility, efficiency, learnability, user satisfaction
  • Usability heuristics and the principles of usability testing
  • Physical capabilities that inform interaction design, e.g., color perception, ergonomics
  • Cognitive models that inform interaction design, e.g., attention, perception and recognition, movement, and
  memory; gulfs of expectation and execution
  • Social models that inform interaction design, e.g., culture, communication, networks and organizations
  • Principles of good design and good designers; engineering tradeoffs
  • Accessibility, e.g., interfaces for differently-abled populations (e.g., blind, motion-impaired)
  • Interfaces for differently-aged population groups (e.g., children, 80+)
  <h3>Designing Interaction</h3>
  Principles of graphical user interfaces (GUIs)
  • Elements of visual design (layout, color, fonts, labeling)
  • Task analysis, including qualitative aspects of generating task analytic models
  • Low-fidelity (paper) prototyping
  • Quantitative evaluation techniques, e.g., keystroke-level evaluation
  • Help and documentation
  • Handling human/system failure
  • User interface standards
  <h3>Programming Interactive Systems</h3>
  Software Architecture Patterns, e.g., Model-View controller; command objects, online, offline (cross
  reference PL/Event Driven and Reactive Programming, where MVC is used in the context of event-driven
  programming)
  • Interaction Design Patterns: visual hierarchy, navigational distance
  • Event management and user interaction
  • Geometry management (cross-reference GV/Geometric Modelling)
  • Choosing interaction styles and interaction techniques
  • Presenting information: navigation, representation, manipulation
  • Interface animation techniques (e.g., scene graphs)
  • Widget classes and libraries
  • Modern GUI libraries (e.g. iOS, Android, JavaFX) GUI builders and UI programming environments (crossreference
  PBD/Mobile Platforms)
  • Declarative Interface Specification: Stylesheets and DOMs
  • Data-driven applications (database-backed web pages)
  • Cross-platform design
  • Design for resource-constrained devices (e.g. small, mobile devices)
  <h3>User-Centered Design and Testing</h3>
  Approaches to, and characteristics of, the design process
  • Functionality and usability requirements (cross-reference to SE/Requirements Engineering)
  • Techniques for gathering requirements, e.g., interviews, surveys, ethnographic and contextual enquiry
  • Techniques and tools for the analysis and presentation of requirements, e.g., reports, personas
  • Prototyping techniques and tools, e.g., sketching, storyboards, low-fidelity prototyping, wireframes
  • Evaluation without users, using both qualitative and quantitative techniques, e.g., walkthroughs, GOMS,
  expert-based analysis, heuristics, guidelines, and standards
  • Evaluation with users, e.g., observation, think-aloud, interview, survey, experiment
  • Challenges to effective evaluation, e.g., sampling, generalization
  • Reporting the results of evaluations
  • Internationalization, designing for users from other cultures, cross-cultural
  <h3>New Interactive Technologies</h3>
  Choosing interaction styles and interaction techniques
  • Representing information to users: navigation, representation, manipulation
  • Approaches to design, implementation and evaluation of non-mouse interaction
  o Touch and multi-touch interfaces
  o Shared, embodied, and large interfaces
  o New input modalities (such as sensor and location data)
  o New Windows, e.g., iPhone, Android
  o Speech recognition and natural language processing (cross reference IS/Natural Language
  Processing)
  o Wearable and tangible interfaces
  o Persuasive interaction and emotion
  o Ubiquitous and context-aware interaction technologies (Ubicomp)
  o Bayesian inference (e.g. predictive text, guided pointing)
  o Ambient/peripheral display and interaction
  <h3>Collaboration and Communication</h3>
  <h3>Statistical Methods for HCI</h3>
  <h3>Human Factors and Security</h3>
  <h3>Design-Oriented HCI</h3>
  <h3>Mixed, Augmented and Virtual Reality</h3>
  Output
  o Sound
  o Stereoscopic display
  o Force feedback simulation, haptic devices
  • User input
  o Viewer and object tracking
  o Pose and gesture recognition
  o Accelerometers
  o Fiducial markers
  o User interface issues
  • Physical modelling and rendering
  o Physical simulation: collision detection & response, animation
  o Visibility computation
  o Time-critical rendering, multiple levels of details (LOD)
  • System architectures
  o Game engines
  o Mobile augmented reality
  o Flight simulators
  o CAVEs
  o Medical imaging
  • Networking
  o p2p, client-server, dead reckoning, encryption, synchronization
  o Distributed collaboration
  <h2>Information Assurance and Security (IAS)</h2>
  <h3>Foundational Concepts in Security</h3>
  <h3>Principles of Secure Design</h3>
  <h3>Defensive Programming</h3>
  <h3>Threats and Attacks</h3>
  <h3>Network Security</h3>
  <h3>Cryptography</h3>
  <h3>Web Security</h3>
  <h3>Platform Security</h3>
  <h3>Security Policy and Governance</h3>
  <h3>Digital Forensics</h3>
  <h3>Secure Software Engineering</h3>
  <h2>Information Management (IM)</h2>
  <h3>Information Management Concepts</h3>
  Information systems as socio-technical systems
  • Basic information storage and retrieval (IS&R) concepts
  • Information capture and representation
  • Supporting human needs: searching, retrieving, linking, browsing, navigating
  Approaches to and evolution of database systems
  • Components of database systems
  Design of core DBMS functions (e.g., query mechanisms, transaction management, buffer management,
  access methods)
  • Database architecture and data independence
  • Use of a declarative query language
  • Systems supporting structured and/or stream content
  <h3>Database Systems</h3>
  <h3>Data Modeling</h3>
  Data modeling
  • Conceptual models (e.g., entity-relationship, UML diagrams)
  • Spreadsheet models
  • Relational data models
  • Object-oriented models (cross-reference PL/Object-Oriented Programming)
  • Semi-structured data model (expressed using DTD or XML Schema, for example)
  <h3>Indexing</h3>
  The impact of indices on query performance
  • The basic structure of an index
  • Keeping a buffer of data in memory
  • Creating indexes with SQL
  • Indexing text
  • Indexing the web (e.g., web crawling)
  <h3>Relational Databases</h3>
  Mapping conceptual schema to a relational schema
  • Entity and referential integrity
  • Relational algebra and relational calculus
  • Relational Database design
  • Functional dependency
  • Decomposition of a schema; lossless-join and dependency-preservation properties of a decomposition
  • Candidate keys, superkeys, and closure of a set of attributes
  • Normal forms (BCNF)
  • Multi-valued dependency (4NF)
  • Join dependency (PJNF, 5NF)
  • Representation theory
  <h3>Query Languages</h3>
  Overview of database languages
  • SQL (data definition, query formulation, update sublanguage, constraints, integrity)
  • Selections
  • Projections
  • Select-project-join
  • Aggregates and group-by
  • Subqueries
  • QBE and 4th-generation environments
  • Different ways to invoke non-procedural queries in conventional languages
  • Introduction to other major query languages (e.g., XPATH, SPARQL)
  • Stored procedures
  <h3>Transaction Processing</h3>
  Transactions
  • Failure and recovery
  • Concurrency control
  • Interaction of transaction management with storage, especially buffering
  <h3>Distributed Databases</h3>
  <h3>Physical Database Design</h3>
  <h3>Data Mining</h3>
  Uses of data mining
  • Data mining algorithms
  • Associative and sequential patterns
  • Data clustering
  • Market basket analysis
  • Data cleaning
  • Data visualization (cross-reference GV/Visualization and CN/Interactive Visualization)
  <h3>Information Storage and Retrieval</h3>
  Documents, electronic publishing, markup, and markup languages
  • Tries, inverted files, PAT trees, signature files, indexing
  • Morphological analysis, stemming, phrases, stop lists
  • Term frequency distributions, uncertainty, fuzziness, weighting
  • Vector space, probabilistic, logical, and advanced models
  • Information needs, relevance, evaluation, effectiveness
  • Thesauri, ontologies, classification and categorization, metadata
  • Bibliographic information, bibliometrics, citations
  • Routing and (community) filtering
  • Multimedia search, information seeking behavior, user modeling, feedback
  • Information summarization and visualization
  • Faceted search (e.g., using citations, keywords, classification schemes)
  • Digital libraries
  • Digitization, storage, interchange, digital objects, composites, and packages
  • Metadata and cataloging
  • Naming, repositories, archives
  • Archiving and preservation, integrity
  • Spaces (conceptual, geographical, 2/3D, VR)
  • Architectures (agents, buses, wrappers/mediators), interoperability
  • Services (searching, linking, browsing, and so forth)
  • Intellectual property rights management, privacy, and protection (watermarking)
  <h3>Multimedia Systems</h3>
  • Input and output devices, device drivers, control signals and protocols, DSPs
  • Standards (e.g., audio, graphics, video)
  • Applications, media editors, authoring systems, and authoring
  • Streams/structures, capture/represent/transform, spaces/domains, compression/coding
  • Content-based analysis, indexing, and retrieval of audio, images, animation, and video
  Presentation, rendering, synchronization, multi-modal integration/interfaces
  • Real-time delivery, quality of service (including performance), capacity planning, audio/video
  conferencing, video-on-demand
  <h2>Intelligent Systems (IS)</h2>
  <h3>Fundamental Issues</h3>
  <h3>Basic Search Strategies</h3>
  <h3>Basic Knowledge Representation and Reasoning</h3>
  Review of propositional and predicate logic (cross-reference DS/Basic Logic)
  • Resolution and theorem proving (propositional logic only)
  • Forward chaining, backward chaining
  • Review of probabilistic reasoning, Bayes theorem (cross-reference with DS/Discrete Probability)
  <h3>Basic Machine Learning</h3>
  <h3>Advanced Search</h3>
  <h3>Advanced Representation and Reasoning</h3>
  <h3>Reasoning Under Uncertainty</h3>
  Review of basic probability (cross-reference DS/Discrete Probability)
  • Random variables and probability distributions
  o Axioms of probability
  o Probabilistic inference
  o Bayes’ Rule
  • Conditional Independence
  • Knowledge representations
  o Bayesian Networks
   Exact inference and its complexity
   Randomized sampling (Monte Carlo) methods (e.g. Gibbs sampling)
  o Markov Networks
  o Relational probability models
  o Hidden Markov Models
  • Decision Theory
  o Preferences and utility functions
  o Maximizing expected utility
  <h3>Agents</h3>
  Definitions of agents
  • Agent architectures (e.g., reactive, layered, cognitive)
  • Agent theory
  • Rationality, game theory
  o Decision-theoretic agents
  o Markov decision processes (MDP)
  • Software agents, personal assistants, and information access
  o Collaborative agents
  o Information-gathering agents
  o Believable agents (synthetic characters, modeling emotions in agents)
  • Learning agents
  • Multi-agent systems
  o Collaborating agents
  o Agent teams
  o Competitive agents (e.g., auctions, voting)
  o Swarm systems and biologically inspired models
  <h3>Natural Language Processing</h3>
  Deterministic and stochastic grammars
  • Parsing algorithms
  o CFGs and chart parsers (e.g. CYK)
  o Probabilistic CFGs and weighted CYK
  • Representing meaning / Semantics
  o Logic-based knowledge representations
  o Semantic roles
  o Temporal representations
  o Beliefs, desires, and intentions
  • Corpus-based methods
  • N-grams and HMMs
  • Smoothing and backoff
  Examples of use: POS tagging and morphology
  • Information retrieval (Cross-reference IM/Information Storage and Retrieval)
  o Vector space model
   TF & IDF
  o Precision and recall
  • Information extraction
  • Language translation
  • Text classification, categorization
  o Bag of words model
  <h3>Advanced Machine Learning</h3>
  Definition and examples of broad variety of machine learning tasks
  • General statistical-based learning, parameter estimation (maximum likelihood)
  • Inductive logic programming (ILP)
  • Supervised learning
  o Learning decision trees
  o Learning neural networks
  o Support vector machines (SVMs)
  • Ensembles
  • Nearest-neighbor algorithms
  • Unsupervised Learning and clustering
  o EM
  o K-means
  o Self-organizing maps
  • Semi-supervised learning
  • Learning graphical models (Cross-reference IS/Reasoning under Uncertainty)
  • Performance evaluation (such as cross-validation, area under ROC curve)
  • Learning theory
  • The problem of overfitting, the curse of dimensionality
  • Reinforcement learning
  o Exploration vs. exploitation trade-off
  o Markov decision processes
  o Value and policy iteration
  • Application of Machine Learning algorithms to Data Mining (cross-reference IM/Data Mining)
  <h3>Robotics</h3>
  Overview: problems and progress
  o State-of-the-art robot systems, including their sensors and an overview of their sensor processing
  o Robot control architectures, e.g., deliberative vs. reactive control and Braitenberg vehicles
  o World modeling and world models
  o Inherent uncertainty in sensing and in control
  • Configuration space and environmental maps
  • Interpreting uncertain sensor data
  • Localizing and mapping
  • Navigation and control
  • Motion planning
  • Multiple-robot coordination
  <h3>Perception and Computer Vision</h3>
  Computer vision
  o Image acquisition, representation, processing and properties
  o Shape representation, object recognition and segmentation
  o Motion analysis
  • Audio and speech recognition
  • Modularity in recognition
  • Approaches to pattern recognition (cross-reference IS/Advanced Machine Learning)
  o Classification algorithms and measures of classification quality
  o Statistical techniques
  <h2>Networking and Communication (NC)</h2>
  <h3>Introduction</h3>
  Organization of the Internet (Internet Service Providers, Content Providers, etc.)
  • Switching techniques (e.g., circuit, packet)
  • Physical pieces of a network, including hosts, routers, switches, ISPs, wireless, LAN, access point, and
  firewalls
  • Layering principles (encapsulation, multiplexing)
  • Roles of the different layers (application, transport, network, datalink, physical)
  <h3>Networked Applications</h3>
  Naming and address schemes (DNS, IP addresses, Uniform Resource Identifiers, etc.)
  • Distributed applications (client/server, peer-to-peer, cloud, etc.)
  • HTTP as an application layer protocol
  • Multiplexing with TCP and UDP
  • Socket APIs
  <h3>Reliable Data Delivery</h3>
  <h3>Routing and Forwarding</h3>
  <h3>Local Area Networks</h3>
  <h3>Resource Allocation</h3>
  <h3>Mobility</h3>
  <h3>Social Networking</h3>
  <h2>Operating Systems (OS)</h2>
  <h3>Overview of Operating Systems</h3>
  <h3>Operating System Principles</h3>
  <h3>Concurrency</h3>
  <h3>Scheduling and Dispatch</h3>
  <h3>Memory Management</h3>
  <h3>Security and Protection</h3>
  <h3>Virtual Machines</h3>
  <h3>Device Management</h3>
  <h3>File Systems</h3>
  <h3>Real Time and Embedded Systems</h3>
  <h3>Fault Tolerance</h3>
  <h3>System Performance Evaluation</h3>
  <h2>Platform-Based Development (PBD)</h2>
  <h3>Introduction</h3>
  <h3>Web Platforms</h3>
  <h3>Mobile Platforms</h3>
  <h3>Industrial Platforms</h3>
  <h3>Game Platforms</h3>
  <h2>Parallel and Distributed Computing (PD)</h2>
  <h3>Parallelism Fundamentals</h3>
  Multiple simultaneous computations
  • Goals of parallelism (e.g., throughput) versus concurrency (e.g., controlling access to shared resources)
  • Parallelism, communication, and coordination
  o Programming constructs for coordinating multiple simultaneous computations
  o Need for synchronization
  • Programming errors not found in sequential programming
  o Data races (simultaneous read/write or write/write of shared state)
  o Higher-level races (interleavings violating program intention, undesired non-determinism)
  o Lack of liveness/progress (deadlock, starvation)
  <h3>Parallel Decomposition</h3>
  <h3>Communication and Coordination</h3>
  <h3>Parallel Algorithms, Analysis, and Programming</h3>
  <h3>Parallel Architecture</h3>
  <h3>Parallel Performance</h3>
  <h3>Distributed Systems</h3>
  <h3>Cloud Computing</h3>
  <h3>Formal Models and Semantics</h3>
  <h2>Programmign Languages (PL)</h2>
  <h3>Object-Oriented Programming</h3>
  <h3>Functional Programming</h3>
  <h3>Event-Driven and Reactive Programming</h3>
  <h3>Basic Type Systems</h3>
  A type as a set of values together with a set of operations
  o Primitive types (e.g., numbers, Booleans)
  o Compound types built from other types (e.g., records, unions, arrays, lists, functions, references)
  • Association of types to variables, arguments, results, and fields
  • Type safety and errors caused by using values inconsistently given their intended types
  • Goals and limitations of static typing
  o Eliminating some classes of errors without running the program
  o Undecidability means static analysis must conservatively approximate program behavior
  <h3>Program Representation</h3>
  Programs that take (other) programs as input such as interpreters, compilers, type-checkers, documentation
  generators
  • Abstract syntax trees; contrast with concrete syntax
  • Data structures to represent code for execution, translation, or transmission
  <h3>Language Translation and Execution</h3>
  <h3>Syntax Analysis</h3>
  <h3>Compiler Semantic Analysis</h3>
  <h3>Code Generation</h3>
  <h3>Runtime Systems</h3>
  <h3>Static Analysis</h3>
  <h3>Advanced Programming Constructs</h3>
  <h3>Concurrency and Parallelism</h3>
  <h3>Type Systems</h3>
  <h3>Formal Semantics</h3>
  <h3>Language Pragmatics</h3>
  <h3>Logic Programming</h3>
  <h2>Software Development Fundamentals (SDF)</h2>
  <h3>Algorithms and Design</h3>
  <h3>Fundamental Programming Concepts</h3>
  Basic syntax and semantics of a higher-level language
  • Variables and primitive data types (e.g., numbers, characters, Booleans)
  • Expressions and assignments
  • Simple I/O including file I/O
  • Conditional and iterative control structures
  • Functions and parameter passing
  • The concept of recursion
  <h3>Fundamental Data Structures</h3>
  Arrays
  • Records/structs (heterogeneous aggregates)
  • Strings and string processing
  • Abstract data types and their implementation
  o Stacks
  o Queues
  o Priority queues
  o Sets
  o Maps
  • References and aliasing
  • Linked lists
  • Strategies for choosing the appropriate data structure
  <h3>Development Methods</h3>
  <h2>Software Engineering (SE)</h2>
  <h3>Software Processes</h3>
  <h3>Software Project Management</h3>
  <h3>Tools and Environments</h3>
  Software configuration management and version control
  • Release management
  • Requirements analysis and design modeling tools
  • Testing tools including static and dynamic analysis tools
  • Programming environments that automate parts of program construction processes (e.g., automated builds)
  o Continuous integration
  • Tool integration concepts and mechanisms
  <h3>Requirements Engineering</h3>
  <h3>Software Design</h3>
  System design principles: levels of abstraction (architectural design and detailed design), separation of
  concerns, information hiding, coupling and cohesion, re-use of standard structures
  • Design Paradigms such as structured design (top-down functional decomposition), object-oriented analysis
  and design, event driven design, component-level design, data-structured centered, aspect oriented,
  function oriented, service oriented
  • Structural and behavioral models of software designs
  • Design patterns
  <h3>Software Construction</h3>
  <h3>Software Verification and Validation</h3>
  <h3>Software Evolution</h3>
  <h3>Software Reliability</h3>
  <h3>Formal Methods</h3>
  <h2>Systems Fundamentals (SF)</h2>
  <h3>Computational Paradigms</h3>
  Basic building blocks and components of a computer (gates, flip-flops, registers, interconnections;
  Datapath + Control + Memory)
  • Hardware as a computational paradigm: Fundamental logic building blocks; Logic expressions,
  minimization, sum of product forms
  • Application-level sequential processing: single thread
  • Simple application-level parallel processing: request level (web services/client-server/distributed), single
  thread per server, multiple threads with multiple servers
  • Basic concept of pipelining, overlapped processing stages
  • Basic concept of scaling: going faster vs. handling larger problems
  <h3>Cross-Layer Communications</h3>
  <h3>State and State Machines</h3>
  <h3>Parallelism</h3>
  Sequential vs. parallel processing
  • Parallel programming vs. concurrent programming
  • Request parallelism vs. Task parallelism
  • Client-Server/Web Services, Thread (Fork-Join), Pipelining
  • Multicore architectures and hardware support for synchronization
  <h3>Evaluation</h3>
  <h3>Resource Allocation and Scheduling</h3>
  Kinds of resources (e.g., processor share, memory, disk, net bandwidth)
  • Kinds of scheduling (e.g., first-come, priority)
  • Advantages of fair scheduling, preemptive scheduling
  <h3>Proximity</h3>
  Speed of light and computers (one foot per nanosecond vs. one GHz clocks)
  • Latencies in computer systems: memory vs. disk latencies vs. across the network memory
  • Caches and the effects of spatial and temporal locality on performance in processors and systems
  • Caches and cache coherency in databases, operating systems, distributed systems, and computer
  architecture
  • Introduction into the processor memory hierarchy and the formula for average memory access time
  <h3>Virtualization and Isolation</h3>
  <h3>Reliability through Reduncancy</h3>
  <h3>Quantitative Evaluation</h3>
  <h2>Social Issues and Professional Practice (SP)</h2>
  <h3>Social Context</h3>
  Social implications of computing in a networked world (cross-reference HCI/Foundations/social models;
  IAS/Fundamental Concepts/social issues)
  • Impact of social media on individualism, collectivism and culture
  Growth and control of the Internet (cross-reference NC/Introduction/organization of the Internet)
  • Often referred to as the digital divide, differences in access to digital technology resources and its resulting
  ramifications for gender, class, ethnicity, geography, and/or underdeveloped countries.
  • Accessibility issues, including legal requirements
  • Context-aware computing (cross-reference HCI/Design for non-mouse interfaces/ ubiquitous and contextaware)
  <h3>Analytical Tools</h3>
  <h3>Professional Ethics</h3>
  <h3>Intellectual Property</h3>
  Philosophical foundations of intellectual property
  • Intellectual property rights (cross-reference IM/Information Storage and Retrieval/intellectual property and
  protection)
  • Intangible digital intellectual property (IDIP)
  • Legal foundations for intellectual property protection
  • Digital rights management
  • Copyrights, patents, trade secrets, trademarks
  • Plagiarism
  <h3>Privacy and Civil Liberties</h3>
  <h3>Professional Communication</h3>
  <h3>Sustainability</h3>
  <h3>History</h3>
  <h3>Economics of Computing</h3>
  <h3>Security Policies, Laws and Computer Crimes</h3>


  <h4>Principal Component Analysis</h4>
  <p>PCA is a dimensionality-reduction method used to reduce the dimensionality of large data sets, by transforming a
    large set of variables into a smaller one that still contains most of the information in the large set. The goal is
    to keep as much accuracy as possible while allowing for simplicity.</p>
  <p>The first step of PCA is standardization, which standardizes the range of continuous initial variables so that each
    one contributes equally to the analysis. If this is not performed, differences in the larger ranges will dominate
    over those with small ranges. This can be done mathematically by finding the z-score:</p>
  $$z=\frac{\text{value}-\text{mean}}{\text{standard deviation}}$$
  <p>The next step is covariance matrix computation. This aims to understand how the variables of the input data set are
    varying from the mean with respect to each other, to see if there is any relationship between them. The covariance
    matrix is a \(p\times p\) symmetric matrix (where p is the number of dimensions) that has as entries the covariances
    associated with all possible pairs of the initial variables. For example, a data set with 3 dimensions (say x, y,
    and z) would have a covariance matrix in this form:</p>
  $$ \left[
  \begin{array}{c}
  Cov(x,x)&Cov(x,y)&Cov(x,z)\\
  Cov(y,x)&Cov(y,y)&Cov(y,z)\\
  Cov(z,x)&Cov(z,y)&Cov(z,z)
  \end{array}
  \right] $$
  <p>Since the covariance of a variable with itself is its variance, the mani diagonal (top left to bottom right) is
    just the variances of each initial variable. And since the covariance is commutative (Cov(a,b,)=Cov(b,a)), the
    entries of the covariance matrix are symmetric with respect to the main diagonal.</p>
  <p>The next step is to compute the eigenvectors and eigenvalues of the covariance matrix to identify the principal
    components. Principal components are new variables that are constructed as linear combinations or mixtures of
    initial variables, but done in a way such that most of the information is compressed into the first components. So,
    10-dimensional data still gives you 10 principal components, but tries to put the maximum possible information into
    the first component, then the maximum remaining information in the second, and so on. Thus, you can discard
    components with low information and consider remaining components as your new variables. Geometrically speaking,
    principal components represent the directions of the data that explain a maximal amount of variance. Simply put,
    think of principal components as new axes that provide the best angle to see and evaluate the data, so that
    differences between observations are better visible. They are lines that maximize the variance (average of squared
    distances from the projected points to the origin).</p>
  <img src="{{url_for('static',filename='img/computer_science/PCA.gif')}}" style="width: 70%" alt="Builtin.com">
  <p>Now let's go back to eigenvectors and eigenvalues. Every eigenvector has an eigenvalue, and their number is equal
    to the number of dimensions of the data. For example, for a 3-dimensional data set, there are 3 variables and thus 3
    eigenvectors with 3 corresponding eigenvalues. The eigenvectors of the Covariance matrix are the directions of the
    axes where there is the most variance and that we call Principal Components. And eigenvalues are simply the
    coefficients attached to eigenvactors, which give the amount of variance carried in each Principal Component.</p>
  <p>Next, we create the feature vector. After we have ranked the principal components in order of significance, we
    choose which components we wish to discard, and form the remaining ones a matrix of vectors that we call the feature
    vector. This makes it the first step in dimensionality reduction, because we have removed principal components.</p>
  <p>Finally, we recast the data along the principal components axes. We use the feature vector to reorient the data
    from the original axes to the one represented by the principal components. This can be done by multiplying the
    transpose of the original data set by the transpose of the feature vector.</p>
  <h4>k-means clustering</h4>
  <p>k-means clustering is a method of vector quantization, originally from signal processing, that aims to partitian n
    observations into k clusters in whcih each observation belongs to the cluster with the nearest mean.</p>
  <h4>Uniform Manifold Approximation and Projection for Dimension Reduction</h4>
  <p>UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension
    reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The
    result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with
    t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time
    performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a
    general purpose dimension reduction technique for machine learning.</p>

  <h3>MongoDB-Express-Angular-NodeJS (MEAN) Stack</h3>
  <h4>Angular</h4>
  <p>Angular is a client-side (browser) framework which allows you to build Single-Page-Applications (SPA). It creates
    "mobile app"-like websites because there is no refreshing of the page.</p>
  <h4>NodeJS</h4>
  <p>NodeJS is a server-side library. It listens to requests and sends responses.</p>
  <h4>Express</h4>
  <p>Express is a Node framework which simplifies writing server-side code and logic.</p>
  <h4>mongoDB</h4>
  <p>mongoDB is a noSQL database which stores "documents" in collections" instead of "records" in "tables" as in SQL. It
    stores application data (users, products, etc.). It is more flexible in terms of structure compared to SQL.</p>
  <p>First you need to download and install NodeJS. Then install the Angular CLI. Then create a new Angular project (ng
    new). 'ng serve' will serve the project.</p>
  <p>Each component needs logic (ts file) and template (html file).</p>
</div>
{% endblock %}